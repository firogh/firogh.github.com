# Links
[1]: http://larmbr.com/2014/01/19/the-evolution-of-4-level-page-talbe-in-linux/
[2]: http://ytliu.info/blog/2016/03/14/linuxnei-cun-chu-shi-hua-assembly/
[3]: https://lwn.net/Articles/253361/
[4]: http://pages.cs.wisc.edu/~remzi/OSTEP/vm-tlbs.pdf
# x86 64
[Linux内核4级页表的演进][1]
[Linux内存初始化][2]
PAE is 3-level page tables: pgd, pmd, pte.
So early_level4_pgt(level4, level3, level2) in startup_64() with 
ENTRY(secondary_startup_64)
  /* Enable PAE mode and PGE */
  movl  $(X86_CR4_PAE | X86_CR4_PGE), %ecx
  movq  %rcx, %cr4

  /* Setup early boot stage 4 level pagetables. */
  addq  phys_base(%rip), %rax
  movq  %rax, %cr3

should be OK.

X86_CR0_PG: enable paging.
x86_64_start_kernel


All processes's page table(task_strcut pgd) was derived form init_mm's swapper_pg_dir which inited in native_pagetable_init(). #FIXME.
# PGTs init 
arch_add_memory: hotplug
init_mem_mapping: normal
setup_arch->init_memory_mapping

# Sparse page tables
8170e6bed465b4b0c7687f93e9948aca4358a33b
x86, 64bit: Use a #PF handler to materialize early mappings on demand

# vmemmap page tables
vmemmap_populate
## hotplug
add_memory
|-add_memory_resource
 |-add_memory_resource
  |-arch_add_memory
   |-__add_pages
    |-__add_section
     |-sparse_add_one_section
      |-kmalloc_section_memmap
       |-sparse_mem_map_populate
        |-vmemmap_populate
# sparse_init
|-sparse_early_mem_map_alloc if !CONFIG_SPARSEMEM_ALLOC_MEM_MAP_TOGETHER
|-sparse_early_mem_maps_alloc_node if CONFIG_SPARSEMEM_ALLOC_MEM_MAP_TOGETHER

# Walk on page tables
ptdump_walk_pgd_level_core
and change page attr
__change_page_attr

# page table
pgd_ctor

remap_pfn_range

##Page table
mk_pte(page, pgprot)    pfn_pte(page_to_pfn(page), (pgprot))
原来低12位里面存了flag啊!
__pte(((phys_addr_t)page_nr << PAGE_SHIFT) | massage_pgprot(pgprot));
For vmalloc(), chechk here vmap_page_range_noflush()
For kmap(), check kmap_init()
[How to emulate the process of translate va to pa?](http://edsionte.com/techblog/archives/1966)


# TLB
[Memory part 3: Virtual Memory][3]
Because the processor does not ensure that the data that it caches are always consistent with the structures in memory, it is important for software developers to understand how and when the processor may cache such data. They should also understand what actions software can take to remove cached
data that may be inconsistent and when it should do so.-- SDM 4.10 CACHING TRANSLATION INFORMATION
4.10.4 Invalidation of TLBs and Paging-Structure Caches
https://www.kernel.org/doc/Documentation/x86/tlb.txt
[Paging: Faster Translations TLBs][4]

## PCID
1.10. Longer-lived TLB Entries with PCID in kernel newbies: 
The relatted commit: x86/mm: Give each mm TLB flush generation a unique ID
f39681ed0f48498b80455095376f11535feea332
x86/mm: Implement PCID based optimization: try to preserve old TLB entries using PCID
10af6235e0d327d42e1bad974385197817923dc1


## Direct mapping area
high_memory (-128UL << 20)
__get_free_pages()
kmalloc()
kmem_cache_alloc()/slab

## Vmalloc
map_vm_area 页表映射
the page in ZONE_NORMAL will not use directly mapping pfn address! It use VMALLOC address! 

### Vmalloc coherence with vfree() after vmalloc_sync_one
在进程的内核页目录中补上的是只是页目录项，而页表对所有进程来说是共用的，不管vfree()多大的内存块，在vmalloc()时新分配的页表不会被释放，当重新vmalloc()时，仍旧使用原来的页表。 page_fault使得进程的内核页目录项与swapper_pg_dir保持同步，swapper_pg_dir的内核页目录项一旦建立就不再被改变，需要改变的只是共享的页表而已。
deatils in vmalloc_sync_one() and vunmap_pte_range()
只释放pte

## Persistent Kernel Mappings
kmap(struct page *)
How kmap works? 
Check kmap_init(), later!

## Temporay Mappings(Fixmaps)
kmap_atomic()
