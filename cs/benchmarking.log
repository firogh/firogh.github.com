
# Benchmarking
See SPATC chapter 12 benchmarking.
Page 67 see above Velocity 2015: Linux Performance Tools
[Active Benchmarking](http://www.brendangregg.com/activebenchmarking)
[reaim aim7 sourceforge](https://sourceforge.net/projects/re-aim-7/)
## https://lwn.net/Articles/736173/
o sparse truncate microbenchmark, tiny
o sparse truncate microbenchmark, large
o reaim-io disk workfile
o dbench4 (modified by mmtests to produce more stable results)
o filebench varmail configuration for small memory size
o bonnie, directory operations, working set size 2*RAM

# Tools
https://github.com/akopytov/sysbench
https://github.com/olafhering/sysbench/blob/pv/mem.1G.on.sh

# Memory
## Memory testing tools
commit e2be15f6c3eecedfbe1550cca8d72c5057abbbd2
Refs: u3.10-3577-ge2be15f6c3ee
Author:     Mel Gorman <mgorman@suse.de>
AuthorDate: Wed Jul 3 15:01:57 2013 -0700
    mm: vmscan: stall page reclaim and writeback pages based on dirty/writepage pages encountered
## microbenchmark - debugfs a convenient place for kernel hackers to play with VM variables.
[mm: create /debug/vm for page reclaim stalls](lore.kernel.org/linux-mm/20120531151816.GA32252@localhost/2-mm-debugfs-vmscan-stalls-0.patch)

# Cases
https://lore.kernel.org/lkml/1471106302-10159-5-git-send-email-brgerst@gmail.com/T/#u
Something like this:
  taskset 1 perf stat -a -e '{instructions,cycles}' --repeat 10 perf bench sched pipe
... will give a very good idea about the general impact of these changes on  
context switch overhead.

[A survey of scheduler benchmarks](https://lwn.net/Articles/725238/)

2.5.18 Micro-Benchmarking

# kernel buddy
commit 6dda9d55bf545013597724bf0cd79d01bd2bd944
Refs: v2.6.34-7312-g6dda9d55bf54
Author:     Corrado Zoccolo <czoccolo@gmail.com>
AuthorDate: Mon May 24 14:31:54 2010 -0700
Commit:     Linus Torvalds <torvalds@linux-foundation.org>
CommitDate: Tue May 25 08:06:56 2010 -0700

    page allocator: reduce fragmentation in buddy allocator by adding buddies that are merging to the tail of the free lists

    In order to reduce fragmentation, this patch classifies freed pages in two
    groups according to their probability of being part of a high order merge.
     Pages belonging to a compound whose next-highest buddy is free are more
    likely to be part of a high order merge in the near future, so they will
    be added at the tail of the freelist.  The remaining pages are put at the
    front of the freelist.

    In this way, the pages that are more likely to cause a big merge are kept
    free longer.  Consequently there is a tendency to aggregate the
    long-living allocations on a subset of the compounds, reducing the
    fragmentation.

    This heuristic was tested on three machines, x86, x86-64 and ppc64 with
    3GB of RAM in each machine.  The tests were kernbench, netperf, sysbench
    and STREAM for performance and a high-order stress test for huge page
    allocations.
