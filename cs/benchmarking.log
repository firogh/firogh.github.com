
# Benchmarking
See SPATC chapter 12 benchmarking.
Page 67 see above Velocity 2015: Linux Performance Tools
[Active Benchmarking](http://www.brendangregg.com/activebenchmarking)
[reaim aim7 sourceforge](https://sourceforge.net/projects/re-aim-7/)
## https://lwn.net/Articles/736173/
o sparse truncate microbenchmark, tiny
o sparse truncate microbenchmark, large
o reaim-io disk workfile
o dbench4 (modified by mmtests to produce more stable results)
o filebench varmail configuration for small memory size
o bonnie, directory operations, working set size 2*RAM

# Tools
https://github.com/akopytov/sysbench
https://github.com/olafhering/sysbench/blob/pv/mem.1G.on.sh


# Cases
https://lore.kernel.org/lkml/1471106302-10159-5-git-send-email-brgerst@gmail.com/T/#u
Something like this:
  taskset 1 perf stat -a -e '{instructions,cycles}' --repeat 10 perf bench sched pipe
... will give a very good idea about the general impact of these changes on  
context switch overhead.

[A survey of scheduler benchmarks](https://lwn.net/Articles/725238/)

2.5.18 Micro-Benchmarking
