# Reference
filesystems/vfs.txt
Documentation/filesystems/locking.rst for writepage and end_page_writeback

# LQO
[Linux内核文件Cache 机制](http://www.ilinuxkernel.com/files/Linux.Kernel.Cache.pdf)
[The future of the page cache](https://lwn.net/Articles/712467/) and [Video](https://www.youtube.com/watch?v=xxWaa-lPR-8)
[Page-based direct I/O](https://prod3.lwn.net/Articles/348719/)
[PeterZ: Concurrent Pagecache](https://www.kernel.org/doc/ols/2007/ols2007v2-pages-311-318.pdf)

# Terminology
commit 906f9cdfc2a0800f13683f9e4ebdfd08c12ee81b
Author: Hugh Dickins <hughd@google.com>
Date:   Fri Nov 30 14:10:13 2018 -0800
    mm/huge_memory: rename freeze_page() to unmap_page()
    The term "freeze" is used in several ways in the kernel, and in mm it
    has the particular meaning of forcing page refcount temporarily to 0.
    freeze_page() is just too confusing a name for a function that unmaps a
    page: rename it unmap_page(), and rename unfreeze_page() remap_page().
Firo: See page_ref_freeze().

# History 
## Buffer cache
[Beefing Up the Buffer Cache](https://drive.google.com/file/d/11sLlREfK_3EnEK_BlqnOxVGFUFnDbQVs/view?usp=sharing) and [UBC](https://drive.google.com/file/d/1ZY2MaoJCb8R317ZjLfGdvxcKq4Jo_k6i/view?usp=sharing)
Starting from stable version 2.4.10, the buffer cache does not really exist anymore. In
fact, for reasons of efficiency, block buffers are no longer allocated individually;
instead, they are stored in dedicated pages called “buffer pages,” which are kept in
the page cache.  -- ULK Chapter 15: Storing Blocks in the Page Cache
Section Storing Blocks in Page Cache is invaluable; 

Block buffers: This descriptor contains all the information needed by the kernel to know how to handle the block;
thus, before operating on each block, the kernel checks its buffer head.

Buffer pages: attach_page_buffers
Block device buffer pages
grow_buffers-> grow_dev_page => find_or_create_page => pagecache_get_page => add_to_page_cache_lru
try_to_release_page
Buffer cache: Inode is stored on the buffer cache; check sync_inode_metadata and __ext2_write_inode

## [Linux pagecache history](https://www.kernel.org/doc/ols/2006/ols2006v2-pages-249-262.pdf)
# Radix tree in kernel
p height_to_maxindex

# Radix tree version pagecache
commit 3d30a6cc3af49ca0b668a2cbbc9d43def619567c
Author:     Andrew Morton <akpm@zip.com.au>
AuthorDate: Tue Apr 9 21:29:24 2002 -0700
Commit:     Linus Torvalds <torvalds@penguin.transmeta.com>
CommitDate: Tue Apr 9 21:29:24 2002 -0700

    [PATCH] Velikov/Hellwig radix-tree pagecache
## spinlock -> rwlock
commit 1eeae0158ecd0535a2bc257a53d3472cc37ceb15
Author:     bill.irwin@oracle.com <bill.irwin@oracle.com>
AuthorDate: Fri Mar 4 17:27:21 2005 -0800
Commit:     Linus Torvalds <torvalds@ppc970.osdl.org>
CommitDate: Fri Mar 4 17:27:21 2005 -0800
    [PATCH] make mapping->tree_lock an rwlock
    Convert mapping->tree_lock to an rwlock

# Lockless pagecache
tig tags/v2.6.27-rc1~154
[A Lockless Pagecache in Linux - Introduction, Progress, Performance](https://www.kernel.org/doc/ols/2006/ols2006v2-pages-249-262.pdf)
[Must-read Bachelor papper Nick Piggin: detailed version: A lockless pagecache in Linux](https://drive.google.com/file/d/1WIxOJaRTVs2gXfQrWKqpFyd0XyYA9Hqq/view?usp=sharing)
[A Lockless Pagecache in Linux - Introduction, Progress, Performance](https://www.kernel.org/doc/ols/2006/ols2006v2-pages-249-262.pdf)
## Page PG_nonewrefs -> page_freeze_refs -> page_ref_freeze
commit e286781d5f2e9c846e012a39653a166e9d31777d
Refs: v2.6.26-7311-ge286781d5f2e
Author:     Nick Piggin <npiggin@suse.de>
AuthorDate: Fri Jul 25 19:45:30 2008 -0700
Commit:     Linus Torvalds <torvalds@linux-foundation.org>
CommitDate: Sat Jul 26 12:00:06 2008 -0700
    mm: speculative page references
	[...]
    Thanks to Hugh for pointing out an improvement to the algorithm setting
    page_count to zero when we have control of all references, in order to
    hold off speculative getters.

commit fe896d1878949ea92ba547587bc3075cc688fb8f
Author: Joonsoo Kim <iamjoonsoo.kim@lge.com>
Date:   Thu Mar 17 14:19:26 2016 -0700
    mm: introduce page reference manipulation functions
page_freeze_refs -> page_ref_freeze; is it much better name?
## reorder
[mm/huge_memory.c: reorder operations in __split_huge_page_tail()](https://marc.info/?l=linux-kernel&m=151844440831709&w=2)
## Lockless pagecache and RCU - Firo: why RCU?
See comment of __page_cache_add_speculative().

# The address space object - address_space
Documentation/filesystems/vfs.rst
[Re: struct address_space](http://lkml.iu.edu/hypermail/linux/kernel/9911.0/0273.html)

> > looks like we started using things called struct address_space a couple
> > of rels back. could someone please explain why the change was made ? there
> > don't seem to have been any postings on it.
> Because we have caches that are not associated with any particular inode.
> (swap, for one). Moreover, we don't actually need to know the inode - just
> a small subset. Said subset makes perfect sense for any sort of page cache
> and switching to that allows to avoid fake inodes. Moreover, it lets us
> use several caches per inode, etc. And makes for cleaner code, IMHO.

[[Q] [VFS] i_mapping vs. i_data ?](https://lkml.org/lkml/2001/5/22/103)

Firo: FIXME: address_space is subpart of as layer in [Virtual Memory Architecture in SunOS](http://kos.enix.org/pub/gingell8.pdf)

[Linux Page Cache in Linux Kernel 2.4 Internals](http://www.tldp.org/LDP/lki/lki.html#toc4)

> While the SVR4 pagecache is only used for filesystem data cache and thus uses the struct vnode and an offset
> into the file as hash parameters, the Linux page cache is designed to be more generic, and therefore uses a
> struct address_space (explained below) as first parameter. Because the Linux pagecache is tightly coupled to
> the notation of address spaces, you will need at least a basic understanding of adress_spaces to understand the
> way the pagecache works. An address_space is some kind of software MMU that maps all pages of one object
> (e.g. inode) to an other concurrency (typically physical disk blocks).

PLKA
To manage the various target objects that can be processed and cached in whole pages, the kernel uses
an abstraction of the ‘‘address space‘‘that associates the pages in memory with a specific block device (or
any other system unit or part of a system unit).
This type of address space must not be confused with the virtual and physical
address spaces provided by the system or processor. It is a separate abstraction of
the Linux kernel that unfortunately bears the same name.


# Radix tree and xarry
Wikipedia: Radix tree looks like a trie. Kernel: Radix tree was more like a page tables or judy array.
[Trees I: Radix trees](https://lwn.net/Articles/175432/)
[Enhancing the Linux Radix Tree](http://events17.linuxfoundation.org/sites/events/files/slides/LinuxConNA2016%20-%20Radix%20Tree.pdf)
[The design and implementation of the XArray](https://www.youtube.com/watch?v=v0C9_Fp-co4)
[A multi-order radix tree](https://lwn.net/Articles/688130/)
[The XArray data structure](https://lwn.net/Articles/745073/)
__radix_tree_create(), radix_tree_extend, radix_tree_lookup_slot, __radix_tree_lookup, radix_tree_extend
## Radix tree shift
commit c12e51b07b3ac4c188fd91a82f96840fdb9cca6f
Refs: v4.6-6714-gc12e51b07b3a
Author:     Matthew Wilcox <willy@infradead.org>
AuthorDate: Fri May 20 17:03:10 2016 -0700
Commit:     Linus Torvalds <torvalds@linux-foundation.org>
CommitDate: Fri May 20 17:58:30 2016 -0700
    radix-tree: replace node->height with node->shift
    node->shift represents the shift necessary for looking in the slots
    array at this level.  It is equal to the old (node->height - 1) *
    RADIX_TREE_MAP_SHIFT.

# Cache coherence

# Page flags
PG_private: check definition
 * The PG_private bitflag is set on pagecache pages if they contain filesystem
 * specific data (which is normally at page->private). It can be used by
 * private allocations for its own usage.

# SUSE page cache limit
Check box/pagecache-limit
https://lore.kernel.org/patchwork/cover/473535/

# Truncation
commit 97a894136f29802da19a15541de3c019e1ca147e
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Tue May 24 17:12:04 2011 -0700
    mm: Remove i_mmap_lock lockbreak
    Hugh says:
     "The only significant loser, I think, would be page reclaim (when
      concurrent with truncation): could spin for a long time waiting for
      the i_mmap_mutex it expects would soon be dropped? "
    Counter points:
     - cpu contention makes the spin stop (need_resched())
     - zap pages should be freeing pages at a higher rate than reclaim
       ever can
    I think the simplification of the truncate code is definitely worth it.
    Effectively reverts: 2aa15890f3c ("mm: prevent concurrent
    unmap_mapping_range() on the same inode") and takes out the code that
    caused its problem.
[A new way to truncate() files](https://lwn.net/Articles/341352/)
[The race: File holes, races, and mmap()](https://lwn.net/Articles/357767/)
[Long-term get_user_pages() and truncate(): solved at last?](https://lwn.net/Articles/796000/)
kernel codes: truncate_pagecache().
[Follow-up for speed up page cache truncation](https://lwn.net/Articles/736173/)

## AOP_TRUNCATED_PAGE
commit 994fc28c7b1e697ac56befe4aecabf23f0689f46
Refs: v2.6.15-2-g994fc28c7b1e
Author:     Zach Brown <zach.brown@oracle.com>
AuthorDate: Thu Dec 15 14:28:17 2005 -0800
Commit:     Joel Becker <joel.becker@oracle.com>
CommitDate: Tue Jan 3 11:45:42 2006 -0800
    [PATCH] add AOP_TRUNCATED_PAGE, prepend AOP_ to WRITEPAGE_ACTIVATE
    readpage(), prepare_write(), and commit_write() callers are updated to
    understand the special return code AOP_TRUNCATED_PAGE in the style of
    writepage() and WRITEPAGE_ACTIVATE.  AOP_TRUNCATED_PAGE tells the caller that
    the callee has unlocked the page and that the operation should be tried again
    with a new page.  OCFS2 uses this to detect and work around a lock inversion in
    its aop methods.  There should be no change in behaviour for methods that don't
    return AOP_TRUNCATED_PAGE.
    WRITEPAGE_ACTIVATE is also prepended with AOP_ for consistency and they are
    made enums so that kerneldoc can be used to document their semantics.

commit 55144768e100b68447f44c5e5c9deb155ad661bd
Refs: v2.6.23-4332-g55144768e100
Author:     Nick Piggin <npiggin@suse.de>
AuthorDate: Tue Oct 16 01:25:26 2007 -0700
Commit:     Linus Torvalds <torvalds@woody.linux-foundation.org>
CommitDate: Tue Oct 16 09:42:58 2007 -0700

    fs: remove some AOP_TRUNCATED_PAGE

    prepare/commit_write no longer returns AOP_TRUNCATED_PAGE since OCFS2 and
    GFS2 were converted to the new aops, so we can make some simplifications
    for that.
All users found for AOP_TRUNCATED_PAGE
grep -nr AOP_TRUNCATED_PAGE fs/
fs/gfs2/aops.c:528:	error = AOP_TRUNCATED_PAGE;
fs/gfs2/aops.c:537:	if (error && error != AOP_TRUNCATED_PAGE)
fs/ocfs2/stack_o2cb.c:17:/* Needed for AOP_TRUNCATED_PAGE in mlog_errno() */
fs/ocfs2/dlmglue.c:2527: * done this we have to return AOP_TRUNCATED_PAGE so the aop method
fs/ocfs2/dlmglue.c:2550:		ret = AOP_TRUNCATED_PAGE;
fs/ocfs2/cluster/masklog.h:179:	    _st != AOP_TRUNCATED_PAGE && _st != -ENOSPC &&		\
fs/ocfs2/aops.c:293:		if (ret == AOP_TRUNCATED_PAGE)
fs/ocfs2/aops.c:304:		ret = AOP_TRUNCATED_PAGE;
## vfs.rst
``readpage``
        called by the VM to read a page from backing store.  The page 
        will be Locked when readpage is called, and should be unlocked
        and marked uptodate once the read completes.  If ->readpage
        discovers that it needs to unlock the page for some reason, it
        can do so, and then return AOP_TRUNCATED_PAGE.  In this case,
        the page will be relocated, relocked and if that all succeeds,
        ->readpage will be called again.

# Locked see locking.rst
## lock_page - for page cache?
History: commit 344971f8de0ecf3fb7ea642e319aad5865b23529
Refs: <2.3.7pre1>
Author:     Linus Torvalds <torvalds@linuxfoundation.org>
AuthorDate: Fri Nov 23 15:25:25 2007 -0500
Commit:     Linus Torvalds <torvalds@linuxfoundation.org>
CommitDate: Fri Nov 23 15:25:25 2007 -0500
    Linux 2.3.7pre1
    I'd like to point out that the current pre-2.3.7 series is fairly
    experimental. As amply demonstrated by the filename (the "dangerous" part
    in the filename hopefully made some people go "Hmm..").
    We're working on re-architecting (or rather, cleaning up so that it works
    like it really was supposed to) the page cache writing, and as a result a
    number of filesystems are probably going to be broken for a while unless
    we get people jumping in to help.
+/*
+ * Get the lock to a page atomically.
+ */
+struct page * __find_lock_page (struct inode * inode,
+                               unsigned long offset, struct page *page)
[...]
+ * Get an exclusive lock on the page..
+ */
+static void lock_page(struct page *page
## lock_page_nosync - (Deleted)
commit db37648cd6ce9b828abd6d49aa3d269926ee7b7d
Refs: v2.6.18-1584-gdb37648cd6ce
Author:     Nick Piggin <npiggin@suse.de>
AuthorDate: Mon Sep 25 23:31:24 2006 -0700
Commit:     Linus Torvalds <torvalds@g5.osdl.org>
CommitDate: Tue Sep 26 08:48:48 2006 -0700
    [PATCH] mm: non syncing lock_page()
    lock_page needs the caller to have a reference on the page->mapping inode
    due to sync_page, ergo set_page_dirty_lock is obviously buggy according to
    its comments.
    Solve it by introducing a new lock_page_nosync which does not do a sync_page.
    akpm: unpleasant solution to an unpleasant problem.  If it goes wrong it could
    cause great slowdowns while the lock_page() caller waits for kblockd to
    perform the unplug.  And if a filesystem has special sync_page() requirements
    (none presently do), permanent hangs are possible.
    otoh, set_page_dirty_lock() is usually (always?) called against userspace
    pages.  They are always up-to-date, so there shouldn't be any pending read I/O
    against these pages.
+/*
+ * lock_page may only be called if we have the page's inode pinned.			# __iget ? So what about PageAnon?
+ */
 static inline void lock_page(struct page *page)
 {
        might_sleep();
        if (TestSetPageLocked(page))
                __lock_page(page);
 }
+
+/*
+ * lock_page_nosync should only be used if we can't pin the page's inode.
+ * Doesn't play quite so well with block device plugging.
+ */
+static inline void lock_page_nosync(struct page *page)
+{
+       might_sleep();
+       if (TestSetPageLocked(page))
+               __lock_page_nosync(page);
+}
[...]
+/*
+ * Variant of lock_page that does not require the caller to hold a reference
+ * on the page's mapping.
+ */
+void fastcall __lock_page_nosync(struct page *page)
+{
+       DEFINE_WAIT_BIT(wait, &page->flags, PG_locked);
+       __wait_on_bit_lock(page_waitqueue(page), &wait, __sleep_on_page_lock,
+                                                       TASK_UNINTERRUPTIBLE);
+}
commit 7eaceaccab5f40bbfda044629a6298616aeaed50
Author: Jens Axboe <jaxboe@fusionio.com>
Date:   Thu Mar 10 08:52:07 2011 +0100
    block: remove per-queue plugging
    Code has been converted over to the new explicit on-stack plugging,
    and delay users have been converted to use the new API for that.
    So lets kill off the old plugging along with aops->sync_page().


# Readahead
[Linux readahead: less tricks for more](https://www.kernel.org/doc/ols/2007/ols2007v2-pages-273-284.pdf)
[Adaptive file readahead](https://lwn.net/Articles/155510/)
[Improving readahead](https://lwn.net/Articles/372384/)
## First design - Firo: see this commit for reason for why put_page in read_pages()
tglx: commit 8fa498462272fec2c16a92a9a7f67d005225b640	# first design
Author:     Andrew Morton <akpm@zip.com.au>
AuthorDate: Tue Apr 9 21:29:32 2002 -0700
Commit:     Linus Torvalds <torvalds@penguin.transmeta.com>
CommitDate: Tue Apr 9 21:29:32 2002 -0700
    [PATCH] readahead
    I'd like to be able to claim amazing speedups, but
    the best benchmark I could find was diffing two
    256 megabyte files, which is about 10% quicker.  And
    that is probably due to the window size being effectively
    50% larger.
commit 029e332ea717810172e965ec50f942755ad0c58a
Refs: v2.6.19-rc4-152-g029e332ea717
Author:     OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
AuthorDate: Thu Nov 2 22:07:06 2006 -0800
Commit:     Linus Torvalds <torvalds@g5.osdl.org>
CommitDate: Fri Nov 3 12:27:56 2006 -0800
    [PATCH] Cleanup read_pages()
    Current read_pages() assume ->readpages() frees the passed pages.
    This patch free the pages in ->read_pages(), if those were remaining in the
    pages_list.  So, readpages() just can ignore the remaining pages in
    pages_list.
+++ b/mm/readahead.c
@@ -173,6 +173,8 @@ static int read_pages(struct address_space *mapping, struct file *filp,
        if (mapping->a_ops->readpages) {
                ret = mapping->a_ops->readpages(filp, mapping, pages, nr_pages);
+               /* Clean up the remaining pages */
+               put_pages_list(pages);

## pagevec_move_fn or pagevec_move_tail
commit 902aaed0d983dfd459fcb2b678608d4584782200
Refs: v2.6.23-4285-g902aaed0d983
Author:     Hisashi Hifumi <hifumi.hisashi@oss.ntt.co.jp>
AuthorDate: Tue Oct 16 01:24:52 2007 -0700
Commit:     Linus Torvalds <torvalds@woody.linux-foundation.org>
CommitDate: Tue Oct 16 09:42:54 2007 -0700
    mm: use pagevec to rotate reclaimable page
