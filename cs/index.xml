<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Cs on f(x) </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://firoyang.org/cs/</link>
    <language>en-us</language>
    <author>Firo Yang</author>
    
    <updated>Sat, 08 Jun 2019 00:00:00 UTC</updated>
    
    <item>
      <title>Linux kernel page allocation</title>
      <link>http://firoyang.org/cs/page_allocator/</link>
      <pubDate>Sat, 08 Jun 2019 00:00:00 UTC</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/page_allocator/</guid>
      <description>

&lt;h1 id=&#34;track-buddy-memory-system-1963-1965&#34;&gt;track: buddy memory system 1963 ~ 1965&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://sci-hub.tw/https://dl.acm.org/citation.cfm?doid=365628.365655&#34;&gt;buddy system 1965 a fast storage allocator.&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Buddy_memory_allocation&#34;&gt;Buddy memory allocation&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=359626&#34;&gt;buddy system variants 1977&lt;/a&gt;&lt;br /&gt;
The following cited from above 1965 paper.&lt;br /&gt;
The oporations involved in obtaining blocks from and retm&amp;rsquo;ning thom to the free&lt;br /&gt;
storage lists aro vory fast, making this scheme particularly appropriate for list structure operations and for other&lt;br /&gt;
situations involving many sizes of blocks which are fixed in size and location. This is in fact tho storago bookkeeping&lt;br /&gt;
mothod used in tho Boll Telephone Laboratories Low-Level List Language&amp;rsquo;&lt;/p&gt;

&lt;p&gt;OSIDP&lt;br /&gt;
Both fixed and dynamic partitioning schemes have drawbacks. A fixed partitioning&lt;br /&gt;
scheme limits the number of active processes and may use space inefficiently if there is&lt;br /&gt;
a poor match between available partition sizes and process sizes. A dynamic partition-&lt;br /&gt;
ing scheme is more complex to maintain and includes the overhead of compaction. An&lt;br /&gt;
interesting compromise is the buddy system&lt;/p&gt;

&lt;h2 id=&#34;related-code&#34;&gt;Related code&lt;/h2&gt;

&lt;p&gt;free_area; page_is_buddy; PageBuddy(buddy) &amp;amp;&amp;amp; page_order(buddy)&lt;br /&gt;
setup_arch-&amp;gt;x86_init.paging.pagetable_init = native_pagetable_init = paging_init -&amp;gt;&lt;br /&gt;
        sparse_init &amp;hellip;-&amp;gt; vmemmap_populate      # vmemmap&lt;br /&gt;
        zone_sizes_init-&amp;gt;free_area_init_nodes -&amp;gt; free_area_init_node-&amp;gt; free_area_init_core&lt;br /&gt;
                zone_pcp_init # init percpu pageset with boot_pageset&lt;br /&gt;
                init_currently_empty_zone(zone, zone_start_pfn, size); # free_area.free_list&lt;br /&gt;
                memmap_init_zone # Memory map a) Set all page to reserved. MIGRATE_MOVABLE? b) Set node, zone to page-&amp;gt;flags; set_page_links&lt;/p&gt;

&lt;p&gt;start_kernel-&amp;gt;mm_init&lt;br /&gt;
        mem_init-&amp;gt; memblock_free_all or free_all_bootmem # /* this will put all low memory onto the freelists */&lt;/p&gt;

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;[Driver porting: low-level memory allocation]&lt;a href=&#34;https://lwn.net/Articles/22909/)&#34;&gt;https://lwn.net/Articles/22909/)&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;formal-causes&#34;&gt;Formal causes&lt;/h1&gt;

&lt;h2 id=&#34;hot-and-cold-pages&#34;&gt;Hot and cold pages&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/14768/&#34;&gt;Hot and cold pages&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://patchwork.kernel.org/patch/10013971/&#34;&gt;mm, Remove cold parameter from free_hot_cold_page*&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;gfp-flags&#34;&gt;GFP flags&lt;/h1&gt;

&lt;p&gt;__GFP_THISNODE: 9b819d204cf602eab1a53a9ec4b8d2ca51e02a1d - Add __GFP_THISNODE to avoid fallback to other nodes and ignore cpuset/memory policy restrictions&lt;br /&gt;
__GFP_HIGHMEM in __alloc_zeroed_user_highpage??&lt;/p&gt;

&lt;h1 id=&#34;free&#34;&gt;Free&lt;/h1&gt;

&lt;h2 id=&#34;page-state&#34;&gt;page state&lt;/h2&gt;

&lt;p&gt;page_expected_state and check_new_page, page_mapcount_reset&lt;/p&gt;

&lt;h1 id=&#34;do-anonymous-page-zero-page&#34;&gt;Do anonymous page, zero page&lt;/h1&gt;

&lt;p&gt;tglx: commit 382a7dec462a90ad6ae01227f1e8758ae721f6ed&lt;br /&gt;
Author: Christoph Lameter &lt;a href=&#34;mailto:clameter@sgi.com&#34;&gt;clameter@sgi.com&lt;/a&gt;&lt;br /&gt;
Date:   Tue Feb 1 16:34:17 2005 -0800&lt;br /&gt;
    [PATCH] alloc_zeroed_user_highpage() to fix the clear_user_highpage issue&lt;br /&gt;
Lost tracks&lt;br /&gt;
commit 6fbaac38b85e4bd3936b882392e3a9b45e8acb46&lt;br /&gt;
Author: Linus Torvalds &lt;a href=&#34;mailto:torvalds@athlon.transmeta.com&#34;&gt;torvalds@athlon.transmeta.com&lt;/a&gt;&lt;br /&gt;
Date:   Mon Feb 4 19:14:54 2002 -0800&lt;br /&gt;
    v2.4.7 -&amp;gt; v2.4.7.1&lt;/p&gt;

&lt;h1 id=&#34;obselete-feature-fair-zone-allocation&#34;&gt;Obselete feature - Fair-zone allocation&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lore.kernel.org/patchwork/patch/691300/&#34;&gt;mm, page_alloc: Remove fair zone allocation policy&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/576778/&#34;&gt;Configurable fair allocation zone policy&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;watermarks&#34;&gt;Watermarks&lt;/h1&gt;

&lt;p&gt;totalreserve_pages is wmark high; check calculate_totalreserve_pages and Documentation/sysctl/vm.txt&lt;/p&gt;

&lt;p&gt;Check Documentation/sysctl/vm.txt for min_free_kbytes&lt;br /&gt;
min_free_kbytes_sysctl_handler or watermark_scale_factor_sysctl_handler or&lt;br /&gt;
core_initcall(init_per_zone_wmark_min) -&amp;gt;&lt;br /&gt;
        setup_per_zone_wmarks-&amp;gt; __setup_per_zone_wmarks&lt;br /&gt;
{&lt;br /&gt;
        firo@linux-6qg8:~&amp;gt; grep managed /proc/zoneinfo&lt;br /&gt;
                managed  3973&lt;br /&gt;
                managed  464142&lt;br /&gt;
                managed  7726451&lt;br /&gt;
        &amp;gt;&amp;gt;&amp;gt; 3973 + 464142 + 7726451&lt;br /&gt;
        8194566&lt;br /&gt;
        firo@linux-6qg8:~&amp;gt; cat /proc/sys/vm/min_free_kbytes&lt;br /&gt;
        67584&lt;br /&gt;
        &amp;gt;&amp;gt;&amp;gt; 67584 / 4 * 3973 / 8194566&lt;br /&gt;
        8&lt;br /&gt;
        # Unit of watermark is Page.&lt;br /&gt;
        WMARK_MIN = page_no(min_free_kbytes) * (zone.managed_pages / \Sum of zone.managed_pages)&lt;br /&gt;
        WMARK_LOW = 1.25 * min or min + &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;1000&lt;/sub&gt; * zone.managed_pages&lt;br /&gt;
        WMARK_HIGH = 1.5 * min or min + &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;1000&lt;/sub&gt; * zone.managed_pages&lt;br /&gt;
}&lt;br /&gt;
if min_free_kbytes &amp;gt; &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;250&lt;/sub&gt;*total mamanged_pages, we use 1.25 min or 1.5 min&lt;/p&gt;

&lt;h1 id=&#34;zone&#34;&gt;Zone&lt;/h1&gt;

&lt;h2 id=&#34;low-memory-reserved&#34;&gt;Low memory reserved&lt;/h2&gt;

&lt;p&gt;Check Documentation/sysctl/vm.txt for lowmem_reserve_ratio&lt;br /&gt;
lowmem_reserve_ratio_sysctl_handler or core_initcall(init_per_zone_wmark_min) -&amp;gt;&lt;br /&gt;
        setup_per_zone_lowmem_reserve&lt;br /&gt;
firo@linux-6qg8:~&amp;gt; cat /proc/zoneinfo | grep protection&lt;br /&gt;
        protection: (0, 1813, 31994, 31994, 31994)&lt;br /&gt;
        protection: (0, 0, 30181, 30181, 30181)&lt;br /&gt;
        protection: (0, 0, 0, 0, 0)&lt;br /&gt;
        protection: (0, 0, 0, 0, 0)&lt;br /&gt;
        protection: (0, 0, 0, 0, 0)&lt;br /&gt;
Check __alloc_pages_nodemask(), lowmem_reserve is used for checking if there is enough pages in current zone to which allcation fallbacks from a prefered zone.&lt;br /&gt;
lowmem_reserv is used for fallback allcations from a perfered zone in the zonelist.&lt;br /&gt;
The index of lowmme_reserv is the prefered zoneref.zone_idx&lt;/p&gt;

&lt;h2 id=&#34;zone-lists&#34;&gt;Zone lists&lt;/h2&gt;

&lt;p&gt;struct zonelist node_zonelists[MAX_ZONELISTS];&lt;br /&gt;
 * [0]  : Zonelist with fallback&lt;br /&gt;
 * [1]  : No fallback (__GFP_THISNODE)&lt;br /&gt;
start_kernel-&amp;gt;&lt;br /&gt;
        build_all_zonelists&lt;br /&gt;
or hotpulg or /proc/sys/vm/numa_zonelist_order: numa_zonelist_order_handler&lt;br /&gt;
  node_zonelists = {{&lt;br /&gt;
      _zonerefs = {{&lt;br /&gt;
          zone = 0xffff88107ffd5d80, # node 0&lt;br /&gt;
          zone_idx = 2&lt;br /&gt;
          zone = 0xffff88107ffd56c0, # node 0&lt;br /&gt;
          zone_idx = 1&lt;br /&gt;
          zone = 0xffff88107ffd5000, # node 0&lt;br /&gt;
          zone_idx = 0&lt;br /&gt;
          zone = 0xffff88207ffd2d80, # Node 1; fallback.&lt;br /&gt;
          zone_idx = 2&lt;br /&gt;
          zone = 0x0,&lt;br /&gt;
          zone_idx = 0&lt;/p&gt;

&lt;h1 id=&#34;oom&#34;&gt;OOM&lt;/h1&gt;

&lt;p&gt;dump_header(), show_mem(), dump_tasks&lt;/p&gt;

&lt;h1 id=&#34;fsm&#34;&gt;FSM&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;                            |===============================================================================|
                            v                                                                               |
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Physical memory ===(free)=&amp;gt; buddy pages ==(page allocator)===&amp;gt; slab objects                                     |&lt;br /&gt;
                        |                                                                                       |&lt;br /&gt;
                        |===(page fault)======== PAS =========&amp;gt; Private page ====|      |===(OOM Kill)===&amp;gt;|     |&lt;br /&gt;
                                                |                                |      |                 |     |&lt;br /&gt;
                                                |                                | ===&amp;gt; |===(PFRA) ======&amp;gt;|     |&lt;br /&gt;
                                                |===============&amp;gt; Shared page====|      |                 | ====|&lt;br /&gt;
                                                                                        |===(do_unmap) ==&amp;gt;|&lt;br /&gt;
                                                                                        |                 |&lt;br /&gt;
                                                                                        |===(exit_mmap) =&amp;gt;|&lt;/p&gt;

&lt;h1 id=&#34;material&#34;&gt;Material&lt;/h1&gt;

&lt;h2 id=&#34;refcount&#34;&gt;_refcount&lt;/h2&gt;

&lt;p&gt;after __alloc_pages_nodemask _refcount=0,&lt;br /&gt;
post_alloc_hook: init should be 0.&lt;br /&gt;
but set_page_refcounted -&amp;gt; set_page_count(page, 1);&lt;br /&gt;
and Check put_page&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>memory mapping</title>
      <link>http://firoyang.org/cs/mem_map/</link>
      <pubDate>Wed, 22 Aug 2018 21:39:41 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/mem_map/</guid>
      <description>

&lt;p&gt;This article is talking about user space Memory mmapping; it&amp;rsquo;s not limitted to mmap(2) system call.&lt;br /&gt;
&lt;a href=&#34;https://www.ibm.com/support/knowledgecenter/en/ssw_aix_72/com.ibm.aix.genprogc/understanding_mem_mapping.htm&#34;&gt;Understanding memory mapping&lt;/a&gt;&lt;br /&gt;
TLPI:chapter 49 and LSP: Chapter 8&lt;/p&gt;

&lt;h1 id=&#34;history&#34;&gt;History&lt;/h1&gt;

&lt;p&gt;BSD 4.2&lt;br /&gt;
1990 SunOS 4.1&lt;br /&gt;
&lt;a href=&#34;http://bitsavers.trailing-edge.com/pdf/sun/sunos/4.1/800-3846-10A_System_Services_Overview_199003.pdf&#34;&gt;A Must-read: The applications programmer gains access to the facilities of the VM system through several sets of system calls.&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;formal-causes&#34;&gt;Formal causes&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://landley.net/writing/memory-faq.txt&#34;&gt;What are memory mappings? - Landley&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A memory mapping is a set of page table entries describing the properties&lt;br /&gt;
of a consecutive virtual address range.  Each memory mapping has a&lt;br /&gt;
start address and length, permissions (such as whether the program can&lt;br /&gt;
read, write, or execute from that memory), and associated resources (such&lt;br /&gt;
as physical pages, swap pages, file contents, and so on).&lt;br /&gt;
Firo:  mmap, page fault, PFRA.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;vma&#34;&gt;VMA&lt;/h1&gt;

&lt;p&gt;vma&amp;rsquo;s unit is PAGE_SIZE; (vm_end - vm_start) % 0x1000 == 0 is True.&lt;/p&gt;

&lt;h2 id=&#34;split-vma&#34;&gt;split_vma&lt;/h2&gt;

&lt;p&gt;new_below&lt;br /&gt;
commit 5846fc6c31162234e88bdfd91548b1cf0d2cebbd&lt;br /&gt;
Author: Andrew Morton &lt;a href=&#34;mailto:akpm@digeo.com&#34;&gt;akpm@digeo.com&lt;/a&gt;&lt;br /&gt;
Date:   Tue Sep 17 06:35:47 2002 -0700&lt;br /&gt;
    [PATCH] consolidate the VMA splitting code&lt;br /&gt;
new_below means the place where the old vma go to! Bad naming!&lt;br /&gt;
0 means the old will save the head part. 1 means tail part.&lt;/p&gt;

&lt;h2 id=&#34;file&#34;&gt;File&lt;/h2&gt;

&lt;h3 id=&#34;pas&#34;&gt;PAS&lt;/h3&gt;

&lt;p&gt;Protection, Shared, Private.&lt;br /&gt;
vm_page_prot, vm_flags&lt;br /&gt;
remove_mapping&lt;/p&gt;

&lt;h3 id=&#34;backing-dev&#34;&gt;Backing dev&lt;/h3&gt;

&lt;p&gt;vm_file, vm_pgoff&lt;/p&gt;

&lt;h2 id=&#34;private-anonymouse-mappings&#34;&gt;Private anonymouse mappings&lt;/h2&gt;

&lt;p&gt;Heap - malloc mmap&lt;br /&gt;
Anonymous Memory Mappings, LSP chapter 9&lt;/p&gt;

&lt;h2 id=&#34;file-private-mappings&#34;&gt;File private mappings&lt;/h2&gt;

&lt;p&gt;Program: execve text,data,bss&lt;br /&gt;
Libraries&lt;br /&gt;
openat(AT_FDCWD, &amp;ldquo;/lib64/libc.so.6&amp;rdquo;, O_RDONLY|O_CLOEXEC) = 3&lt;br /&gt;
mmap(NULL, 1857568, PROT_READ, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f27cbb02000&lt;br /&gt;
* onset - mmap&lt;br /&gt;
do_mmap -&amp;gt; mmap_region&lt;br /&gt;
ext2: generic_file_mmap -&amp;gt; vma-&amp;gt;vm_ops = generic_file_vm_ops&lt;br /&gt;
ext4: ext4_file_mmap -&amp;gt; vma-&amp;gt;vm_ops = ext4_file_vm_ops&lt;br /&gt;
both: filemap_fault&lt;br /&gt;
* nuclus&lt;br /&gt;
Write - do_cow_page&lt;br /&gt;
Read - do_read_page&lt;br /&gt;
Read &amp;amp; write - do_wp_page&lt;/p&gt;

&lt;h1 id=&#34;shared-memory-mapping&#34;&gt;Shared memory mapping&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/gorman/html/understand/understand015.html&#34;&gt;Chapter 12  Shared Memory Virtual Filesystem:&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This is a very clean interface that is conceptually easy to understand but it does not help anonymous pages as there is no file backing. To keep this nice interface, Linux creates an artifical file-backing for anonymous pages using a RAM-based filesystem where each VMA is backed by a “file” in this filesystem. Every inode in the filesystem is placed on a linked list called shmem_inodes so that they may always be easily located. This allows the same file-based interface to be used without treating anonymous pages as a special case.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Firo: every time you create a shared memory via mmap(2), you create a inode with same name dev/zero in the hidden shm_mnt fs;&lt;br /&gt;
The name dev/zero is only a name. It has nothing related to /dev/zero in drivers/char/mem.c. And /dev/shm is only a tmpfs; it has nothing related shmemfs, but POSIX&amp;rsquo;s shm_open uses /dev/shm.&lt;/p&gt;

&lt;h2 id=&#34;shared-anonymouse-mappings&#34;&gt;Shared anonymouse mappings&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lore.kernel.org/patchwork/patch/174306/&#34;&gt;vmscan: limit VM_EXEC protection to file pages&lt;/a&gt;&lt;br /&gt;
If someone may take advange of reclaimation code by mmap(&amp;hellip;, VM_EXEC, SHRED|ANON), OOM may occur since the old code protect it from reclaiming by add it back to the active list. Great patch. However, program running in tmpfs will also penalized.&lt;br /&gt;
page_is_file_cache &amp;lt; !PageAnon&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/452035/&#34;&gt;ashmem&lt;/a&gt;&lt;br /&gt;
* onset - mmap&lt;br /&gt;
do_mmap -&amp;gt; mmap_region -&amp;gt; vma_link -&amp;gt; (__shmem_file_setup) &amp;amp;&amp;amp; __vma_link_file: into i_mmap interval_tree.&lt;br /&gt;
* nuclus - share fault&lt;br /&gt;
Read: do_read_fault&lt;br /&gt;
Write: do_shared_fault -&amp;gt; shmem_getpage_gfp shmem_add_to_page_cache&lt;br /&gt;
WP: do_wp_page -&amp;gt; wp_page_shared or wp_page_reuse&lt;br /&gt;
b)IPC using a shared file mapping&lt;/p&gt;

&lt;h2 id=&#34;file-shared-mappings-a-memory-mapped-i-o&#34;&gt;File shared mappings - a) Memory-mapped I/O&lt;/h2&gt;

&lt;h2 id=&#34;history-1&#34;&gt;History&lt;/h2&gt;

&lt;p&gt;late 70s - IPC: see TLPI: Chapter 45 INTRODUCTION TO SYSTEM V IPC&lt;br /&gt;
they first appear together in Columbus UNIX, a Bell UNIX for database and efficient transaction processing&lt;br /&gt;
1983 - IPC See TLPI or wikipedia shared mmeory.&lt;br /&gt;
they land together in System V that made them popular in mainstream UNIX-es, hence the name&lt;/p&gt;

&lt;p&gt;1983 - BSD mmap with shared vs private memory mapping&lt;br /&gt;
BSD 4.2: The system supports sharing of data between processes by allowing pages to be mapped into memory. These mapped pages may be shared with other processes or private to the process.&lt;/p&gt;

&lt;p&gt;1984 Jan - BSD mmap with file memory mapping support by SunOS&lt;br /&gt;
The mmap seems firstly implemented by &lt;a href=&#34;http://bitsavers.trailing-edge.com/pdf/sun/sunos/1.1/800-1108-01E_System_Interface_Manual_for_the_Sun_Workstation_Jan84.pdf&#34;&gt;SunOS 1.1&lt;/a&gt;&lt;br /&gt;
N.B. This call is not completely implemented In 4.2(BSD).&lt;br /&gt;
More sunos docs: &lt;a href=&#34;http://bitsavers.trailing-edge.com/pdf/sun/sunos/&#34;&gt;http://bitsavers.trailing-edge.com/pdf/sun/sunos/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;1988&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Memory-mapped_file#History&#34;&gt;SunOS 4[4] introduced Unix&amp;rsquo;s mmap, which permitted programs &amp;ldquo;to map files into memory.&amp;rdquo;&lt;/a&gt;&lt;br /&gt;
1989&lt;br /&gt;
One paper found in OSTEP: &lt;a href=&#34;https://courses.cs.washington.edu/courses/cse551/09sp/papers/memory_coherence.pdf&#34;&gt;Memory Coherence in Shared Virtual Memory Systems&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;mmap&#34;&gt;mmap&lt;/h1&gt;

&lt;h2 id=&#34;map-sync&#34;&gt;MAP_SYNC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/731706/&#34;&gt;Two more approaches to persistent-memory writes&lt;/a&gt;&lt;br /&gt;
dax_iomap_pte_fault&lt;/p&gt;

&lt;h1 id=&#34;madvise&#34;&gt;madvise&lt;/h1&gt;

&lt;h2 id=&#34;madv-sequential-and-reclaim&#34;&gt;MADV_SEQUENTIAL and reclaim&lt;/h2&gt;

&lt;p&gt;mm: more likely reclaim MADV_SEQUENTIAL mappings - 4917e5d0499b5ae7b26b56fccaefddf9aec9369c&lt;/p&gt;

&lt;h2 id=&#34;madv-free&#34;&gt;MADV_FREE&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/590991/&#34;&gt;Volatile ranges and MADV_FREE&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://bugs.python.org/issue26601&#34;&gt;Use new madvise()&amp;rsquo;s MADV_FREE on the private heap&lt;/a&gt;&lt;br /&gt;
commit 854e9ed09dedf0c19ac8640e91bcc74bc3f9e5c9&lt;br /&gt;
Author: Minchan Kim &lt;a href=&#34;mailto:minchan@kernel.org&#34;&gt;minchan@kernel.org&lt;/a&gt;&lt;br /&gt;
Date:   Fri Jan 15 16:54:53 2016 -0800&lt;br /&gt;
    mm: support madvise(MADV_FREE)&lt;br /&gt;
commit 10853a039208c4afaa322a7d802456c8dca222f4&lt;br /&gt;
Author: Minchan Kim &lt;a href=&#34;mailto:minchan@kernel.org&#34;&gt;minchan@kernel.org&lt;/a&gt;&lt;br /&gt;
Date:   Fri Jan 15 16:55:11 2016 -0800&lt;br /&gt;
    mm: move lazily freed pages to inactive list&lt;/p&gt;

&lt;p&gt;commit f7ad2a6cb9f7c4040004bedee84a70a9b985583e&lt;br /&gt;
Author: Shaohua Li &lt;a href=&#34;mailto:shli@fb.com&#34;&gt;shli@fb.com&lt;/a&gt;&lt;br /&gt;
Date:   Wed May 3 14:52:29 2017 -0700&lt;br /&gt;
    mm: move MADV_FREE pages into LRU_INACTIVE_FILE list&lt;/p&gt;

&lt;h1 id=&#34;mprotect&#34;&gt;mprotect&lt;/h1&gt;

&lt;h2 id=&#34;prot-none&#34;&gt;PROT_NONE&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.greenend.org.uk/rjk/tech/dataseg.html#summary&#34;&gt;&amp;mdash;p PROT_NOME mapping&lt;/a&gt;&lt;br /&gt;
show_vma_header_prefix&lt;br /&gt;
cat /proc/self/maps&lt;br /&gt;
7ffff7a17000-7ffff7bcc000 r-xp 00000000 08:03 1188168                    /usr/lib64/libc-2.27.so ============&amp;gt; text&lt;br /&gt;
7ffff7bcc000-7ffff7dcc000 &amp;mdash;p 001b5000 08:03 1188168                    /usr/lib64/libc-2.27.so ============&amp;gt; PROT_NONE&lt;br /&gt;
7ffff7dcc000-7ffff7dd0000 r&amp;ndash;p 001b5000 08:03 1188168                    /usr/lib64/libc-2.27.so ============&amp;gt; read only data&lt;br /&gt;
7ffff7dd0000-7ffff7dd2000 rw-p 001b9000 08:03 1188168                    /usr/lib64/libc-2.27.so ============&amp;gt; initialized&lt;br /&gt;
7ffff7dd2000-7ffff7dd6000 rw-p 00000000 00:00 0&lt;br /&gt;
strace -e mmap,mprotect cat /dev/null&lt;br /&gt;
mmap(NULL, 3926752, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7ffff7a17000       ===&amp;gt; text&lt;br /&gt;
mprotect(0x7ffff7bcc000, 2097152, PROT_NONE) = 0                                ======================&amp;gt; PROT_NONE&lt;br /&gt;
mmap(0x7ffff7dcc000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1b5000) = 0x7ffff7dcc000&lt;br /&gt;
mmap(0x7ffff7dd2000, 15072, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7ffff7dd2000&lt;br /&gt;
mprotect(0x7ffff7dcc000, 16384, PROT_READ) = 0                                          ========&amp;gt; read only data&lt;br /&gt;
/* If _PAGE_BIT_PRESENT is clear, we use these: &lt;em&gt;/&lt;br /&gt;
/&lt;/em&gt; - if the user mapped it with PROT_NONE; pte_present gives true */&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/gorman/html/understand/understand006.html&#34;&gt;A MUST READ: Mel on PAGE_PROTNONE&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://volatility-labs.blogspot.com/2015/05/using-mprotect-protnone-on-linux.html&#34;&gt;Using mprotect(.., .., PROT_NONE) on Linux&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lkml.org/lkml/1998/9/21/55&#34;&gt;Linus on _PAGE_PROTNONE&lt;/a&gt;&lt;br /&gt;
 define _PAGE_BIT_PROTNONE      _PAGE_BIT_GLOBAL&lt;br /&gt;
tglx: commit 06d9f6ff137579551a2ee18661847915fe2bb812 (tag: 0.97.5)&lt;br /&gt;
Author: Linus Torvalds &lt;a href=&#34;mailto:torvalds@linuxfoundation.org&#34;&gt;torvalds@linuxfoundation.org&lt;/a&gt;&lt;br /&gt;
Date:   Fri Nov 23 15:09:05 2007 -0500&lt;br /&gt;
    [PATCH] Linux-0.97.5 (September 12, 1992)&lt;br /&gt;
There isn&amp;rsquo;t too much useful information.&lt;br /&gt;
&lt;a href=&#34;https://www.spinics.net/lists/newbies/msg08579.html&#34;&gt;https://www.spinics.net/lists/newbies/msg08579.html&lt;/a&gt;&lt;br /&gt;
man mprotect, PROT_NONE&lt;br /&gt;
userspace addr is associated with non-GLOBAL pte, so the 8th G is reused by PROT_NONE.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Memory consistency model</title>
      <link>http://firoyang.org/cs/consistency_model/</link>
      <pubDate>Sat, 16 Dec 2017 15:46:12 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/consistency_model/</guid>
      <description>

&lt;p&gt;When we are talking on memory model, we are refering memory consistency model or memory ordering model.&lt;/p&gt;

&lt;h1 id=&#34;hisotry&#34;&gt;Hisotry&lt;/h1&gt;

&lt;p&gt;1979&lt;br /&gt;
&lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2016/12/How-to-Make-a-Multiprocessor-Computer-That-Correctly-Executes-Multiprocess-Programs.pdf&#34;&gt;How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Progranm&lt;/a&gt;&lt;br /&gt;
1987 ~ 1990&lt;br /&gt;
&lt;a href=&#34;https://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf&#34;&gt;Linearizability: A Correctness Condition for Concurrent Objects&lt;/a&gt;&lt;br /&gt;
1989&lt;br /&gt;
&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.3766&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;processor consistency: CACHE CONSISTENCY AND SEQUENTIAL CONSISTENCY&lt;/a&gt;&lt;br /&gt;
1990&lt;br /&gt;
&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=325102&#34;&gt;Release consistency: Memory consistency and event ordering in scalable shared-memory multiprocessors&lt;/a&gt;&lt;br /&gt;
1991&lt;br /&gt;
&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=113406&#34;&gt;Proving sequential consistency of high-performance shared memories&lt;/a&gt;&lt;br /&gt;
1992&lt;br /&gt;
&lt;a href=&#34;https://www.gaisler.com/doc/sparcv8.pdf&#34;&gt;TSO Sparc v8: A standard memory model called Total Store Ordering (TSO) is defined for SPARC&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-1-4615-3604-8_2&#34;&gt;Formal Specification of Memory Models: and two store ordered models TSO and PSO defined by the Sun Microsystem&amp;rsquo;s SPARC architecture.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2001 ~ Present&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=WUfvvFD5tAA&#34;&gt;IA64 memory ordering&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;purposes&#34;&gt;Purposes&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/lectures/14_relaxedReview.pdf&#34;&gt;Motivation: hiding latency&lt;/a&gt;&lt;br /&gt;
▪ Why are we interested in relaxing ordering requirements?&lt;br /&gt;
- Performance&lt;br /&gt;
- Speci!cally, hiding memory latency: overlap memory accesses with other operations&lt;br /&gt;
- Remember, memory access in a cache coherent system may entail much more then&lt;br /&gt;
simply reading bits from memory (!nding data, sending invalidations, etc.)&lt;/p&gt;

&lt;h2 id=&#34;why-tso-it-s-because-that-write-buffer-or-store-buffer-is-not-invisible-any-more-for-multiprocessor-https-www-cis-upenn-edu-devietti-classes-cis601-spring2016-sc-tso-pdf&#34;&gt;Why TSO? &lt;a href=&#34;https://www.cis.upenn.edu/~devietti/classes/cis601-spring2016/sc_tso.pdf&#34;&gt;It&amp;rsquo;s because that write buffer or Store buffer is not invisible any more for multiprocessor&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;To abandon SC; to Allow use of a FIFO write buffer.&lt;br /&gt;
&lt;a href=&#34;https://www.cs.utexas.edu/~bornholt/post/memory-models.html&#34;&gt;An example: There’s no reason why performing event (2) (a read from B) needs to wait until event (1) (a write to A) completes. They don’t interfere with each other at all, and so should be allowed to run in parallel. See Memory Consistency Models: A Primer&lt;/a&gt;&lt;br /&gt;
Hide the write latency by putting the data in the store buffer.&lt;/p&gt;

&lt;h3 id=&#34;why-not-read-write-reordering&#34;&gt;Why not read-write reordering?&lt;/h3&gt;

&lt;p&gt;reordering read-write is non-sense.&lt;/p&gt;

&lt;h1 id=&#34;formal-cause&#34;&gt;Formal cause&lt;/h1&gt;

&lt;p&gt;Shared memory&lt;br /&gt;
Multiprocessor&lt;br /&gt;
Memory access&lt;br /&gt;
program order&lt;br /&gt;
&lt;a href=&#34;https://www.hpl.hp.com/techreports/Compaq-DEC/WRL-95-7.pdf&#34;&gt;Recommened by CAAQA: Observity in SC, TSO, PC: Paragraph Relaxing the Write to Read Program Order in Shared Memory Consistency Models: A Tutorial&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf&#34;&gt;Memory Barriers: a Hardware View for Software Hackers - must read&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://15418.courses.cs.cmu.edu/spring2013/article/41&#34;&gt;&amp;lsquo;A Summary of Relaxed Consistency&amp;rsquo; CMU&lt;/a&gt;&lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/lectures/14_relaxedReview.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;sc&#34;&gt;SC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2016/12/How-to-Make-a-Multiprocessor-Computer-That-Correctly-Executes-Multiprocess-Programs.pdf&#34;&gt;sequential consistency&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://jepsen.io/consistency/models/sequential#formally&#34;&gt;Formal of Sequential Consistency by Jepsen&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;tso&#34;&gt;TSO&lt;/h2&gt;

&lt;p&gt;Total Store Ordering in Appendix k Sparc v8.&lt;/p&gt;

&lt;h3 id=&#34;tso-in-x86&#34;&gt;TSO in x86&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cl.cam.ac.uk/~pes20/weakmemory/x86tso-paper.tphols.pdf&#34;&gt;A Better x86 Memory Model: x86-TSO&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/27595595/when-are-x86-lfence-sfence-and-mfence-instructions-required&#34;&gt;When are x86 LFENCE, SFENCE and MFENCE instructions required?&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;tso-vs-pc&#34;&gt;TSO vs PC:&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://15418.courses.cs.cmu.edu/spring2013/article/41&#34;&gt;&amp;lsquo;A Summary of Relaxed Consistency&amp;rsquo; CMU&lt;/a&gt;&lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/lectures/14_relaxedReview.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;tso-and-peterson-s-algorithm&#34;&gt;TSO and Peterson&amp;rsquo;s algorithm&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://bartoszmilewski.com/2008/11/05/who-ordered-memory-fences-on-an-x86/&#34;&gt;Who ordered memory fences on an x86?&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cnblogs.com/caidi/p/6708789.html&#34;&gt;共同进入与饥饿&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;pc&#34;&gt;PC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.3766&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;processor consistency: CACHE CONSISTENCY AND SEQUENTIAL CONSISTENCY&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;wc&#34;&gt;WC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~kubitron/cs252/handouts/oldquiz/p434-dubois.pdf&#34;&gt;weak consistency: Memory access buffering in multiprocessors&lt;/a&gt;&lt;br /&gt;
They distinguish between ordinary shared accesses and synchronization accesses, where the latter are used to control concurrency&lt;br /&gt;
between several processes and to maintain the integrity of ordinary shared data.&lt;/p&gt;

&lt;h2 id=&#34;rc&#34;&gt;RC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=325102&#34;&gt;Firo: a must-read: Release consistency: Memory consistency and event ordering in scalable shared-memory multiprocessors&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/dxtecharts/lockless-programming?redirectedfrom=MSDN#read-acquire-and-write-release-barriers&#34;&gt;Must-read: Lockless Programming Considerations for Xbox 360 and Microsoft Windows&lt;/a&gt;&lt;br /&gt;
At right top of page 6&lt;br /&gt;
Condition 3.1: Conditions for Release Consistency&lt;br /&gt;
(A) before an ordinary load or store access is allowed to perform with respect to any other processor,&lt;br /&gt;
all previous acquire accesses must be performed, and&lt;br /&gt;
(B) before a release access is allowed to perform with&lt;br /&gt;
respect to any other processor, all previous ordinary&lt;br /&gt;
load and store accesses must be performed, and&lt;br /&gt;
&amp;copy; special accesses are processor consistent with respect to one another.&lt;br /&gt;
&lt;a href=&#34;https://preshing.com/20120913/acquire-and-release-semantics/&#34;&gt;Acquire and Release Semantics&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://marc.info/?l=linux-kernel&amp;amp;m=151844394031510&amp;amp;w=2&#34;&gt;mm/page_ref: use atomic_set_release in page_ref_unfreeze&lt;/a&gt;&lt;br /&gt;
commit 7088efa9137a15d7d21e3abce73e40c9c8a18d68&lt;br /&gt;
Refs: v4.15-rc1-4-g7088efa9137a&lt;br /&gt;
Author:     Paul E. McKenney &lt;a href=&#34;mailto:paulmck@linux.vnet.ibm.com&#34;&gt;paulmck@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
AuthorDate: Mon Oct 9 10:04:27 2017 -0700&lt;br /&gt;
Commit:     Paul E. McKenney &lt;a href=&#34;mailto:paulmck@linux.vnet.ibm.com&#34;&gt;paulmck@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
CommitDate: Mon Dec 4 10:52:52 2017 -0800&lt;br /&gt;
    fs/dcache: Use release-acquire for name/length update&lt;/p&gt;

&lt;h2 id=&#34;kernel&#34;&gt;Kernel&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/memory-barriers.txt&#34;&gt;Why do we need mb for SLEEP AND WAKE-UP FUNCTIONS?&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/718628/&#34;&gt;A formal kernel memory-ordering model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/720550/&#34;&gt;A formal kernel memory-ordering model (part 2)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4374.html&#34;&gt;Linux-Kernel Memory Model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0124r4.html&#34;&gt;Linux-Kernel Memory Model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0124r6.html&#34;&gt;Linux-Kernel Memory Model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://events.linuxfoundation.org/sites/events/files/slides/LinuxMM.2016.09.19a.LCE_.pdf&#34;&gt;Linux-Kernel Memory Ordering: Help Arrives At Last!&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/watch?v=ULFytshTvIY&#34;&gt;Talk on youtube on this!&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;compiler&#34;&gt;Compiler&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://preshing.com/20120625/memory-ordering-at-compile-time/&#34;&gt;Memory Ordering at Compile Time&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://blog.regehr.org/archives/232&#34;&gt;A Guide to Undefined Behavior in C and C++, Part 3&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;other-architectures&#34;&gt;Other architectures&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cl.cam.ac.uk/~pes20/weakmemory/&#34;&gt;Relaxed-Memory Concurrency&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;c11-library-memory-model&#34;&gt;C11(library) memory model&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://en.cppreference.com/w/c/atomic/memory_order&#34;&gt;C memory order&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cl.cam.ac.uk/~pes20/cpp/notes42.html&#34;&gt;Don&amp;rsquo;t read: The Thin-air Problem&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42967.pdf&#34;&gt;Outlawing Ghosts: Avoiding Out-of-Thin-Air Results&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4375.html&#34;&gt;Out-of-Thin-Air Execution is Vacuous&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;material&#34;&gt;Material&lt;/h1&gt;

&lt;h2 id=&#34;practices&#34;&gt;Practices&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://preshing.com/20120515/memory-reordering-caught-in-the-act/&#34;&gt;Memory Reordering Caught in the Act&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;lqo&#34;&gt;LQO&lt;/h2&gt;

&lt;p&gt;134 static void sysrq_handle_crash(int key)&lt;br /&gt;
 135 {&lt;br /&gt;
 136         char &lt;em&gt;killer = NULL;&lt;br /&gt;
 137&lt;br /&gt;
 138         /&lt;/em&gt; we need to release the RCU read lock here,&lt;br /&gt;
 139          * otherwise we get an annoying&lt;br /&gt;
 140          * &amp;lsquo;BUG: sleeping function called from invalid context&amp;rsquo;&lt;br /&gt;
 141          * complaint from the kernel before the panic.&lt;br /&gt;
 142          &lt;em&gt;/&lt;br /&gt;
 143         rcu_read_unlock();&lt;br /&gt;
 144         panic_on_oops = 1;      /&lt;/em&gt; force panic */&lt;br /&gt;
 145         wmb();&lt;br /&gt;
 146         *killer = 1;&lt;br /&gt;
 147 }&lt;/p&gt;

&lt;h1 id=&#34;memory-barrier&#34;&gt;Memory barrier&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/memory-barriers.txt&#34;&gt;https://www.kernel.org/doc/Documentation/memory-barriers.txt&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://en.wikipedia.org/wiki/Memory_barrier&#34;&gt;http://en.wikipedia.org/wiki/Memory_barrier&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://yarchive.net/comp/linux/compiler_barriers.html&#34;&gt;http://yarchive.net/comp/linux/compiler_barriers.html&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://preshing.com/20120710/memory-barriers-are-like-source-control-operations/&#34;&gt;Memory Barriers Are Like Source Control Operations&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/pub/linux/kernel/people/paulmck/Answers/SMP/lwsync.html&#34;&gt;Are All Linux Kernel Memory Barriers Transitive?&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://events.linuxfoundation.org/sites/events/files/slides/dbueso-elc2016-membarriers-final.pdf&#34;&gt;Memory Barriers in the Linux Kernel Semantics and Practices&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When a program runs on a single-CPU machine, the hardware performs the necessary bookkeeping to ensure that the program executes as if all memory operations were performed in the order specified by the programmer (program order), so memory barriers are not necessary. However, when the memory is shared with multiple devices, such as other CPUs in a multiprocessor system, or memory mapped peripherals, out-of-order access may affect program behavior. For example, a second CPU may see memory changes made by the first CPU in a sequence which differs from program order.&lt;br /&gt;
Compiler and cpu do the same optimization: reorder of instructions&lt;/p&gt;

&lt;h2 id=&#34;the-linux-kernel-has-a-variety-of-different-barriers-that-act-at-different-levels&#34;&gt;The Linux kernel has a variety of different barriers that act at different levels:&lt;/h2&gt;

&lt;p&gt;(&lt;em&gt;) Compiler barrier.&lt;br /&gt;
  (&lt;/em&gt;) CPU memory barriers.&lt;br /&gt;
  (*) MMIO write barrier.&lt;/p&gt;

&lt;h2 id=&#34;access-once&#34;&gt;ACCESS_ONCE&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Does it work cast a variable to volatile?&lt;br /&gt;
No, there is no efects on cast a variable to volatile.&lt;br /&gt;
Because, access variable is before volatile cast! That means you&lt;br /&gt;
still get a register value. What you do is just conversion a temporary variable&lt;br /&gt;
Rationale for International Standard&amp;ndash;Programming Languages&amp;ndash;C&lt;br /&gt;
&lt;a href=&#34;http://www.geeksforgeeks.org/understanding-volatile-qualifier-in-c/&#34;&gt;Understanding “volatile” qualifier in C&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The definitive guide to Linux x86 entries</title>
      <link>http://firoyang.org/cs/entry/</link>
      <pubDate>Wed, 26 Apr 2017 21:39:41 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/entry/</guid>
      <description>

&lt;h1 id=&#34;all-entries&#34;&gt;All entries&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/x86/entry_64.txt&#34;&gt;Documentation/x86/entry_64.txt&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;entry-irq&#34;&gt;Entry irq&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.lenky.info/archives/2013/03/2245&#34;&gt;对Linux x86-64架构上硬中断的重新认识&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;steps-to-handle-intterrupt&#34;&gt;Steps to handle intterrupt&lt;/h2&gt;

&lt;p&gt;For logical address to linear address, see intel SDM v3a 3.4 LOGICAL AND LINEAR ADDRESSES.&lt;br /&gt;
For stack switching during escalate the CPL, see SDM v3a 5.8.5 stack switching. The processor will automatically chose the espCPL stack to use during changing in privilege level.&lt;br /&gt;
For more details on stack switching, please check the Figure 5-13. Stack Switching During an Interprivilege-Level Call&lt;br /&gt;
For fast system call, check 3a 5.8.7 Performing Fast Calls to System Procedures&lt;br /&gt;
For TSS and TR, check 3a 7.2&lt;br /&gt;
For Linux hanld irq processes, check ULK 3rd Chapter 4: Hardware Handling of Interrupts and Exceptions&lt;/p&gt;

&lt;h1 id=&#34;entry-exception&#34;&gt;Entry exception&lt;/h1&gt;

&lt;h2 id=&#34;paranoid-entry&#34;&gt;paranoid_entry&lt;/h2&gt;

&lt;p&gt;Check Documentation/x86/entry_64.txt&lt;/p&gt;

&lt;h2 id=&#34;error-entry&#34;&gt;error_entry&lt;/h2&gt;

&lt;p&gt;tglx: commit 0457d99a336be658cea1a5bdb689de5adb3b382d&lt;br /&gt;
Author:     Andi Kleen &lt;a href=&#34;mailto:ak@muc.de&#34;&gt;ak@muc.de&lt;/a&gt;&lt;br /&gt;
AuthorDate: Tue Feb 12 20:17:35 2002 -0800&lt;br /&gt;
Commit:     Linus Torvalds &lt;a href=&#34;mailto:torvalds@home.transmeta.com&#34;&gt;torvalds@home.transmeta.com&lt;/a&gt;&lt;br /&gt;
CommitDate: Tue Feb 12 20:17:35 2002 -0800&lt;br /&gt;
    [PATCH] x86_64 merge: arch + asm&lt;/p&gt;

&lt;h1 id=&#34;entry-system-calls&#34;&gt;Entry system calls&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/&#34;&gt;The Definitive Guide to Linux System Calls&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;fast-path&#34;&gt;Fast path&lt;/h2&gt;

&lt;p&gt;commit 21d375b6b34ff511a507de27bf316b3dde6938d9&lt;br /&gt;
Author: Andy Lutomirski &lt;a href=&#34;mailto:luto@kernel.org&#34;&gt;luto@kernel.org&lt;/a&gt;&lt;br /&gt;
Date:   Sun Jan 28 10:38:49 2018 -0800&lt;br /&gt;
    x86/entry/64: Remove the SYSCALL64 fast path&lt;/p&gt;

&lt;h2 id=&#34;sysenter-vs-syscall&#34;&gt;sysenter vs syscall&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://groups.google.com/forum/#!topic/comp.arch/CjDs4MJCBow%5B1-25%5D&#34;&gt;SYSENTER/SYSEXIT vs.SYSCALL/SYSRET&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://arkanis.de/weblog/2017-01-05-measurements-of-system-call-performance-and-overhead&#34;&gt;Measurements of system call performance and overhead&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://reverseengineering.stackexchange.com/a/16511/16996&#34;&gt;AMD vs Intel and syscall vs sysenter&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.codeguru.com/cpp/misc/misc/system/article.php/c8223/System-Call-Optimization-with-the-SYSENTER-Instruction.htm&#34;&gt;System Call Optimization with the SYSENTER Instruction&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://articles.manugarg.com/systemcallinlinux2_6.html&#34;&gt;Sysenter Based System Call Mechanism in Linux 2.6&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;system-call-restart-mechanism-and-orig-eax&#34;&gt;system call restart mechanism and ORIG_EAX&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/17744/&#34;&gt;A new system call restart mechanism&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lkml.org/lkml/2006/8/29/350&#34;&gt;Why set ORIG_EAX(%esp) to -1 in arch/i386/kernel/entry.S:error_code?&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;kernel-implementations&#34;&gt;kernel implementations&lt;/h2&gt;

&lt;p&gt;arch/x86/include/asm/proto.h&lt;br /&gt;
64-bit long mode: syscall; check syscall_init&lt;br /&gt;
64-bit compatible kernel: sysenter, syscall, or int 0x80; check __kernel_vsyscall and def_idts&lt;br /&gt;
32-bit kernel: int 0x80, sysenter;&lt;/p&gt;

&lt;h3 id=&#34;64-bit-without-compat-32-compatible-kernel-support&#34;&gt;64-bit without COMPAT_32/compatible kernel support&lt;/h3&gt;

&lt;p&gt;./int80&lt;br /&gt;
[  730.583700] traps: int80[1697] general protection ip:4000c4 sp:7ffd84b59730 error:402 in int80[400000+1000]&lt;br /&gt;
Segmentation fault (core dumped)&lt;/p&gt;

&lt;h2 id=&#34;x86-64-rcx-and-r10&#34;&gt;x86_64 rcx and r10&lt;/h2&gt;

&lt;p&gt;Check x86_64 ABI: Linux conventions and  according to &lt;a href=&#34;https://www.felixcloutier.com/x86/syscall&#34;&gt;x86 syscall instruction&lt;/a&gt;, rcx is used to passing next rip.&lt;br /&gt;
According to entry_SYSCALL_64, rcx is rip before it is pushed on the kernel stack. So r10 is right 4th args passed from userspace.&lt;br /&gt;
According to do_syscall_64, regs-&amp;gt;ax = sys_call_table&lt;a href=&#34;regs-&amp;gt;di, regs-&amp;gt;si, regs-&amp;gt;dx, regs-&amp;gt;r10, regs-&amp;gt;r8, regs-&amp;gt;r9&#34;&gt;nr&lt;/a&gt;;&lt;/p&gt;

&lt;h2 id=&#34;x86-32-asmlinkage&#34;&gt;x86_32 asmlinkage&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://qr.ae/Ti5MJJ&#34;&gt;By default gcc passes parameters on the stack for x86-32 arch, so what is it needed for? It&amp;rsquo;s because linux kernel uses -mregparm=3 option which overrides the default behaviour&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/67175/&#34;&gt;enbaled -mregparm=3 Shrinking the kernel with gcc&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://kernelnewbies.org/FAQ/asmlinkage&#34;&gt;What is asmlinkage?&lt;/a&gt;&lt;br /&gt;
However, for C functions invoked from assembly code, we should explicitly declare the function&amp;rsquo;s calling convention, because the parameter passing code in assembly side has been fixed. Show all predefined macros for your compiler&lt;/p&gt;

&lt;h2 id=&#34;hacking&#34;&gt;Hacking&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.exploit-db.com/papers/13146&#34;&gt;Obtain sys_call_table on amd64(x86_64)&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;vdso&#34;&gt;vDSO&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.linuxjournal.com/content/creating-vdso-colonels-other-chicken?page=0,0&#34;&gt;Creating a vDSO: the Colonel&amp;rsquo;s Other Chicken&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.trilithium.com/johan/2005/08/linux-gate/&#34;&gt;What is linux-gate.so.1&lt;/a&gt;&lt;br /&gt;
glibc -&amp;gt; AT_SYSINFO-&amp;gt; __kernel_vsyscall -&amp;gt; sysenter/syscall/in0x80&lt;br /&gt;
just for vDSO syscalls&lt;br /&gt;
glibc -&amp;gt; AT_SYSINFO_EHDR-&amp;gt; vDSO elf&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/446528/&#34;&gt;On vsyscalls and the vDSO&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://blog.tinola.com/?e=5&#34;&gt;linux syscalls on x86 64&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Softirq of Linux Kernel</title>
      <link>http://firoyang.org/cs/softirq/</link>
      <pubDate>Mon, 03 Apr 2017 13:09:05 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/softirq/</guid>
      <description>

&lt;h1 id=&#34;the-old-bottom-half&#34;&gt;The old bottom half&lt;/h1&gt;

&lt;p&gt;ULK 1st: 4.6.6 Bottom Half&lt;br /&gt;
History: commit ad09492558ffa7c67f2b58d23d04dce9ffb9b9dd (tag: 0.99)&lt;br /&gt;
Author: Linus Torvalds &lt;a href=&#34;mailto:torvalds@linuxfoundation.org&#34;&gt;torvalds@linuxfoundation.org&lt;/a&gt;&lt;br /&gt;
Date:   Fri Nov 23 15:09:07 2007 -0500&lt;br /&gt;
    [PATCH] Linux-0.99 (December 13, 1992)&lt;br /&gt;
Firo: There isn&amp;rsquo;t to much useful comment. But the code is very simple. Search bh_base.&lt;/p&gt;

&lt;h1 id=&#34;task-queue&#34;&gt;task queue&lt;/h1&gt;

&lt;p&gt;history: commit 98606bddf430f0a60d21fba93806f4e3c736b170 (tag: 1.1.13)&lt;br /&gt;
Author: Linus Torvalds &lt;a href=&#34;mailto:torvalds@linuxfoundation.org&#34;&gt;torvalds@linuxfoundation.org&lt;/a&gt;&lt;br /&gt;
Date:   Fri Nov 23 15:09:30 2007 -0500&lt;br /&gt;
    Import 1.1.13&lt;br /&gt;
+ * New proposed &amp;ldquo;bottom half&amp;rdquo; handlers:&lt;br /&gt;
+ * &amp;copy; 1994 Kai Petzke, wpp@marie.physik.tu-berlin.de&lt;br /&gt;
+ * Advantages:&lt;br /&gt;
+ * - Bottom halfs are implemented as a linked list.  You can have as many&lt;br /&gt;
+ *   of them, as you want.&lt;br /&gt;
+ * - No more scanning of a bit field is required upon call of a bottom half.&lt;br /&gt;
+ * - Support for chained bottom half lists.  The run_task_queue() function can be&lt;br /&gt;
+ *   used as a bottom half handler.  This is for example usefull for bottom&lt;br /&gt;
+ *   halfs, which want to be delayed until the next clock tick.&lt;br /&gt;
+ * Problems:&lt;br /&gt;
+ * - The queue_task_irq() inline function is only atomic with respect to itself.&lt;br /&gt;
+ *   Problems can occur, when queue_task_irq() is called from a normal system&lt;br /&gt;
+ *   call, and an interrupt comes in.  No problems occur, when queue_task_irq()&lt;br /&gt;
+ *   is called from an interrupt or bottom half, and interrupted, as run_task_queue()&lt;br /&gt;
+ *   will not be executed/continued before the last interrupt returns.  If in&lt;br /&gt;
+ *   doubt, use queue_task(), not queue_task_irq().&lt;br /&gt;
+ * - Bottom halfs are called in the reverse order that they were linked into&lt;br /&gt;
+ *   the list.&lt;br /&gt;
+struct tq_struct {&lt;br /&gt;
Check ULK2nd 4.7.3.1 Extending a bottom half for task queues, especially tq_context and keventd&lt;br /&gt;
The Old Task Queue Mechanism in LKD3rd. Cition from it below.&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/11351/&#34;&gt;The end of task queues&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;softirq&#34;&gt;Softirq&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cs.unca.edu/brock/classes/Spring2013/csci331/notes/paper-1130.pdf&#34;&gt;I’ll Do It Later: Softirqs, Tasklets, Bottom Halves, Task Queues, Work Queues and Timers&lt;/a&gt;&lt;br /&gt;
* not allow execute nest but can recusive lock:local_bh_disable&lt;br /&gt;
current-&amp;gt;preemt_count + SOFIRQ_OFFSET also disable preempt current process.&lt;br /&gt;
* hardirq on, can&amp;rsquo;t sleep&lt;br /&gt;
* not percpu&lt;/p&gt;

&lt;h1 id=&#34;occassions-of-softirq&#34;&gt;Occassions of Softirq&lt;/h1&gt;

&lt;p&gt;irq_exit()&lt;br /&gt;
re-enables softirq, local_bh_enable/spin_unlock_bh(); explicity checks executes, netstack/blockIO.&lt;br /&gt;
ksoftirqd&lt;/p&gt;

&lt;h1 id=&#34;tasklet&#34;&gt;Tasklet&lt;/h1&gt;

&lt;p&gt;History: commit 6cc120a8e71a8d124bf6411fc6e730a884b82701 (tag: 2.3.43pre7)&lt;br /&gt;
Author: Linus Torvalds &lt;a href=&#34;mailto:torvalds@linuxfoundation.org&#34;&gt;torvalds@linuxfoundation.org&lt;/a&gt;&lt;br /&gt;
Date:   Fri Nov 23 15:30:52 2007 -0500&lt;br /&gt;
    Import 2.3.43pre7&lt;br /&gt;
+ Tasklets &amp;mdash; multithreaded analogue of BHs.&lt;br /&gt;
+   Main feature differing them of generic softirqs: tasklet&lt;br /&gt;
+   is running only on one CPU simultaneously.&lt;br /&gt;
+   Main feature differing them of BHs: different tasklets&lt;br /&gt;
+   may be run simultaneously on different CPUs.&lt;br /&gt;
+   Properties:&lt;br /&gt;
+   * If tasklet_schedule() is called, then tasklet is guaranteed&lt;br /&gt;
+     to be executed on some cpu at least once after this.&lt;br /&gt;
+   * If the tasklet is already scheduled, but its excecution is still not&lt;br /&gt;
+     started, it will be executed only once.&lt;br /&gt;
+   * If this tasklet is already running on another CPU (or schedule is called&lt;br /&gt;
+     from tasklet itself), it is rescheduled for later.&lt;br /&gt;
+   * Tasklet is strictly serialized wrt itself, but not&lt;br /&gt;
+     wrt another tasklets. If client needs some intertask synchronization,&lt;br /&gt;
+     he makes it with spinlocks.&lt;/p&gt;

&lt;h1 id=&#34;timer&#34;&gt;Timer&lt;/h1&gt;

&lt;h2 id=&#34;irqsafe-timer&#34;&gt;irqsafe timer&lt;/h2&gt;

&lt;p&gt;__run_timers&lt;br /&gt;
irqsafe = timer-&amp;gt;flags &amp;amp; TIMER_IRQSAFE&lt;br /&gt;
check del_timer_sync&lt;br /&gt;
and definition of TIMER_IRQSAFE&lt;br /&gt;
&lt;a href=&#34;https://patchwork.kernel.org/patch/10811995/&#34;&gt;https://patchwork.kernel.org/patch/10811995/&lt;/a&gt;&lt;br /&gt;
Is timer pending&lt;/p&gt;

&lt;h1 id=&#34;lqo&#34;&gt;LQO&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://thread.gmane.org/gmane.linux.kernel/1152658&#34;&gt;Deal PF_MEMALLOC in softirq&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>x86 interrupt and exception</title>
      <link>http://firoyang.org/cs/event/</link>
      <pubDate>Mon, 03 Apr 2017 13:02:12 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/event/</guid>
      <description>

&lt;h1 id=&#34;events&#34;&gt;Events&lt;/h1&gt;

&lt;p&gt;Interrupts: asynonymous(passively received), external&lt;br /&gt;
Exception: synonymous(actively detected), internal&lt;br /&gt;
Software interrupts: is a trap. int/int3, into, bound.&lt;br /&gt;
IPI&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=-pehAzaP1eg&#34;&gt;IRQs: the Hard, the Soft, the Threaded and the Preemptible&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=YE8cRHVIM4E&#34;&gt;How Dealing with Modern Interrupt Architectures can Affect Your Sanity&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;stack-management&#34;&gt;stack management&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/html/latest/x86/kernel-stacks.html&#34;&gt;x86_64 IST Stacks in kernel&lt;/a&gt;&lt;br /&gt;
6.14.4 Stack Switching in IA-32e Mode&lt;br /&gt;
irq_stack_union&lt;/p&gt;

&lt;h2 id=&#34;backtrace&#34;&gt;backtrace&lt;/h2&gt;

&lt;p&gt;commit a2bbe75089d5eb9a3a46d50dd5c215e213790288&lt;br /&gt;
x86: Don&amp;rsquo;t use frame pointer to save old stack on irq entry&lt;br /&gt;
       /* Save previous stack value &lt;em&gt;/&lt;br /&gt;
       movq %rsp, %rsi&lt;br /&gt;
&amp;hellip;&lt;br /&gt;
2:     /&lt;/em&gt; Store previous stack value */&lt;br /&gt;
       pushq %rsi&lt;br /&gt;
&lt;a href=&#34;https://lore.kernel.org/patchwork/patch/736894/&#34;&gt;Firo: end of EOI; x86/dumpstack: make stack name tags more comprehensible&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;concurrency-nested&#34;&gt;Concurrency, nested?&lt;/h1&gt;

&lt;h2 id=&#34;mask-exception&#34;&gt;Mask exception&lt;/h2&gt;

&lt;p&gt;RF in EFLAGS for masking #DB&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/a/1581729/1025001&#34;&gt;Does sti/cli affect software interrupt&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;irq-nested&#34;&gt;irq nested?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://lwn.net/Articles/380937/&#34;&gt;Prevent nested interrupts when the IRQ stack is near overflowing v2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.lenky.info/archives/2013/03/2245&#34;&gt;对Linux x86-64架构上硬中断的重新认识&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;firo-clear-the-flags-for-pf-through-interrupt-gate&#34;&gt;Firo: clear the flags for PF through interrupt gate&lt;/h3&gt;

&lt;p&gt;v3a: 6.12.1 Exception- or Interrupt-Handler Procedures&lt;br /&gt;
6.12.1.2 Flag Usage By Exception- or Interrupt-Handler Procedure&lt;/p&gt;

&lt;h2 id=&#34;synchronization&#34;&gt;synchronization&lt;/h2&gt;

&lt;p&gt;local_irq_disable() used in the code path that never disabled interrupts.&lt;br /&gt;
local_irq_save(flags) used in the code path that already disabled interrupts.&lt;/p&gt;

&lt;h2 id=&#34;in-interrupt&#34;&gt;in_interrupt&lt;/h2&gt;

&lt;p&gt;383 static inline void tick_irq_exit(void)&lt;br /&gt;
384 {&lt;br /&gt;
385 #ifdef CONFIG_NO_HZ_COMMON&lt;br /&gt;
386         int cpu = smp_processor_id();&lt;br /&gt;
387&lt;br /&gt;
388         /* Make sure that timer wheel updates are propagated &lt;em&gt;/&lt;br /&gt;
389         if ((idle_cpu(cpu) &amp;amp;&amp;amp; !need_resched()) || tick_nohz_full_cpu(cpu)) {&lt;br /&gt;
390                 if (!in_interrupt())&lt;br /&gt;
391                         tick_nohz_irq_exit();&lt;br /&gt;
392         }&lt;br /&gt;
393 #endif&lt;br /&gt;
394 }&lt;br /&gt;
395&lt;br /&gt;
396 /&lt;/em&gt;&lt;br /&gt;
397  * Exit an interrupt context. Process softirqs if needed and possible:&lt;br /&gt;
398  */&lt;br /&gt;
399 void irq_exit(void)&lt;br /&gt;
400 {&lt;br /&gt;
401 #ifndef __ARCH_IRQ_EXIT_IRQS_DISABLED&lt;br /&gt;
402         local_irq_disable();&lt;br /&gt;
403 #else&lt;br /&gt;
404         lockdep_assert_irqs_disabled();&lt;br /&gt;
405 #endif&lt;br /&gt;
406         account_irq_exit_time(current);&lt;br /&gt;
407         preempt_count_sub(HARDIRQ_OFFSET);&lt;br /&gt;
408         if (!in_interrupt() &amp;amp;&amp;amp; local_softirq_pending())&lt;br /&gt;
409                 invoke_softirq();&lt;br /&gt;
410&lt;br /&gt;
411         tick_irq_exit();&lt;/p&gt;

&lt;h1 id=&#34;exceptions&#34;&gt;Exceptions&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://wiki.osdev.org/Exceptions&#34;&gt;Exceptions&lt;/a&gt;&lt;br /&gt;
related code:&lt;br /&gt;
do_nmi do_int3 debug_stack_usage_inc, debug_idt_descr, debug_idt_table,&lt;/p&gt;

&lt;h2 id=&#34;faults-a-fault-is-an-exception-that-can-generally-be-corrected-and-that-once-corrected-allows-the-program&#34;&gt;Faults — A fault is an exception that can generally be corrected and that, once corrected, allows the program&lt;/h2&gt;

&lt;p&gt;to be restarted with no loss of continuity. When a fault is reported, the processor restores the machine state to&lt;br /&gt;
the state prior to the beginning of execution of the faulting instruction. The return address (saved contents of&lt;br /&gt;
the CS and EIP registers) for the fault handler points to the faulting instruction, rather than to the instruction&lt;br /&gt;
following the faulting instruction.&lt;/p&gt;

&lt;h2 id=&#34;traps-a-trap-is-an-exception-that-is-reported-immediately-following-the-execution-of-the-trapping-instruction&#34;&gt;Traps — A trap is an exception that is reported immediately following the execution of the trapping instruction.&lt;/h2&gt;

&lt;p&gt;Traps allow execution of a program or task to be continued without loss of program continuity. The return&lt;br /&gt;
address for the trap handler points to the instruction to be executed after the trapping instruction.&lt;/p&gt;

&lt;h2 id=&#34;aborts-an-abort-is-an-exception-that-does-not-always-report-the-precise-location-of-the-instruction-causing&#34;&gt;Aborts — An abort is an exception that does not always report the precise location of the instruction causing&lt;/h2&gt;

&lt;p&gt;the exception and does not allow a restart of the program or task that caused the exception. Aborts are used to&lt;br /&gt;
report severe errors, such as hardware errors and inconsistent or illegal values in system tables.&lt;/p&gt;

&lt;h2 id=&#34;triggering-a-gp-exception&#34;&gt;Triggering a #GP exception&lt;/h2&gt;

&lt;p&gt;exception_GP_trigger.S&lt;/p&gt;

&lt;h2 id=&#34;exeception-init&#34;&gt;Exeception init&lt;/h2&gt;

&lt;p&gt;Rleated code:&lt;br /&gt;
idt_setup_early_traps           #===&amp;gt; idt_table: ist=0; DB, BP&lt;br /&gt;
idt_setup_early_pf              #===&amp;gt; idt_table: PF ist=0;&lt;br /&gt;
trap_init, idt_setup_traps                 #===&amp;gt; idt_table: ist=0; DE, 0x80 &amp;hellip; etc.&lt;br /&gt;
trap_init-&amp;gt;cpu_init, idt_setup_ist_traps             #===&amp;gt; idt_table: ist=1; DB, NMI, BP, DF, MC;&lt;br /&gt;
x86_init.irqs.trap_init         #===&amp;gt; if !KVM, noop&lt;br /&gt;
idt_setup_debugidt_traps        #===&amp;gt; debug_idt_table, check debug stack; INTG; #DB debug; #BP int; check arch/x86/entry/entry_64.S&lt;/p&gt;

&lt;h1 id=&#34;interrupt&#34;&gt;Interrupt&lt;/h1&gt;

&lt;p&gt;If interrupt occured in user mode, then cpu will context swith for potential reschedule.&lt;br /&gt;
The Interrupt Descriptor Table (IDT) is a data structure used by the x86 architecture to implement an interrupt vector table.&lt;/p&gt;

&lt;h2 id=&#34;hardware-interrupts&#34;&gt;Hardware interrupts&lt;/h2&gt;

&lt;p&gt;are used by devices to communicate that they require attention from the operating system.&lt;br /&gt;
more details in init_IRQ() or set_irq() in driver.&lt;/p&gt;

&lt;h2 id=&#34;software-interrupt&#34;&gt;software interrupt&lt;/h2&gt;

&lt;p&gt;more details in trap_init().&lt;br /&gt;
* exception or trap&lt;br /&gt;
is caused either by an exceptional condition in the processor itself,&lt;br /&gt;
divide zero painc?&lt;br /&gt;
* special instruction, for example INT 0x80&lt;br /&gt;
or a special instruction in the instruction set which causes an interrupt when it is executed.&lt;/p&gt;

&lt;h2 id=&#34;irq-line-number-vs-interrupt-vector&#34;&gt;IRQ line number vs interrupt vector&lt;/h2&gt;

&lt;p&gt;cat /proc/interrupts&lt;br /&gt;
            CPU0       CPU1       CPU2       CPU3&lt;br /&gt;
   0:         21          0          0          0  IR-IO-APIC    2-edge      timer&lt;br /&gt;
v3a Chapter 6 and Check ULK3 Chapter 4 Interrupt vectors&lt;br /&gt;
the 0 in /proc/interrupts is a IRQ line number&lt;br /&gt;
The 0 for Divide error is a interrupt vector.&lt;/p&gt;

&lt;h2 id=&#34;interrupt-init&#34;&gt;Interrupt init&lt;/h2&gt;

&lt;p&gt;early_irq_init = alloc NR_IRQS_LEGACY irq_desc; - 16    #===&amp;gt; [    0.000000] NR_IRQS: 65792, nr_irqs: 1024, preallocated irqs: 16&lt;br /&gt;
init_IRQ()-&amp;gt;x86_init.irqs.intr_init=native_init_IRQ     #===&amp;gt; external interrupt init;&lt;br /&gt;
    pre_vector_init = init_ISA_irqs #===&amp;gt; 1) legacy_pic-&amp;gt;init(0); init 8259a; 2) link irq_desc in irq_desc_tree with flow handle and chip.&lt;br /&gt;
    idt_setup_apic_and_irq_gates    #===&amp;gt; apic normal(from 32) and system interrupts;&lt;/p&gt;

&lt;h1 id=&#34;ipi&#34;&gt;IPI&lt;/h1&gt;

&lt;p&gt;commit 52aec3308db85f4e9f5c8b9f5dc4fbd0138c6fa4&lt;br /&gt;
Author: Alex Shi &lt;a href=&#34;mailto:alex.shi@intel.com&#34;&gt;alex.shi@intel.com&lt;/a&gt;&lt;br /&gt;
Date:   Thu Jun 28 09:02:23 2012 +0800&lt;br /&gt;
    x86/tlb: replace INVALIDATE_TLB_VECTOR by CALL_FUNCTION_VECTOR&lt;br /&gt;
ERROR_APIC_VECTOR               0xfe&lt;br /&gt;
RESCHEDULE_VECTOR               0xfd&lt;br /&gt;
CALL_FUNCTION_VECTOR            0xfc&lt;br /&gt;
CALL_FUNCTION_SINGLE_VECTOR     0xfb&lt;br /&gt;
THERMAL_APIC_VECTOR             0xfa&lt;br /&gt;
THRESHOLD_APIC_VECTOR           0xf9&lt;br /&gt;
REBOOT_VECTOR                   0xf8&lt;/p&gt;

&lt;h1 id=&#34;history&#34;&gt;History&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://people.cs.clemson.edu/~mark/interrupts.html&#34;&gt;history of interrupts&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://virtualirfan.com/history-of-interrupts&#34;&gt;Another History of interrupts with video&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scheduling in operating system</title>
      <link>http://firoyang.org/cs/scheduling/</link>
      <pubDate>Wed, 29 Mar 2017 10:49:04 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/scheduling/</guid>
      <description>

&lt;h1 id=&#34;scheduling&#34;&gt;scheduling&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Scheduling_(computing)&#34;&gt;Scheduling (computing)&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;context-switch&#34;&gt;Context switch&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.maizure.org/projects/evolution_x86_context_switch_linux/index.html&#34;&gt;Evolution of the x86 context switch in Linux&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/520227/&#34;&gt;Al Viro&amp;rsquo;s new execve/kernel_thread design&lt;/a&gt;&lt;br /&gt;
commit 0100301bfdf56a2a370c7157b5ab0fbf9313e1cd&lt;br /&gt;
Author: Brian Gerst &lt;a href=&#34;mailto:brgerst@gmail.com&#34;&gt;brgerst@gmail.com&lt;/a&gt;&lt;br /&gt;
Date:   Sat Aug 13 12:38:19 2016 -0400&lt;br /&gt;
    sched/x86: Rewrite the switch_to() code&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/15019986/why-does-switch-to-use-pushjmpret-to-change-eip-instead-of-jmp-directly/15024312&#34;&gt;Why does switch_to use push+jmp+ret to change EIP, instead of jmp directly?&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;preemption&#34;&gt;Preemption&lt;/h1&gt;

&lt;h2 id=&#34;voluntary-kernel-preemption-2-6-12-rc4-mm2-https-lwn-net-articles-137259&#34;&gt;&lt;a href=&#34;https://lwn.net/Articles/137259/&#34;&gt;Voluntary Kernel Preemption, 2.6.12-rc4-mm2&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Voluntary preemption works by adding a cond_resched()&lt;br /&gt;
(reschedule-if-needed) call to every might_sleep() check. It is lighter&lt;br /&gt;
than CONFIG_PREEMPT - at the cost of not having as tight latencies. It&lt;br /&gt;
represents a different latency/complexity/overhead tradeoff.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com/questions/5174955/what-is-voluntary-preemption&#34;&gt;voluntary preemption&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/563185/&#34;&gt;Optimizing preemption&lt;/a&gt;&lt;br /&gt;
commit 41719b03091911028116155deddc5eedf8c45e37&lt;br /&gt;
Refs: v2.6.29-rc1-226-g41719b030919&lt;br /&gt;
Author:     Peter Zijlstra &lt;a href=&#34;mailto:a.p.zijlstra@chello.nl&#34;&gt;a.p.zijlstra@chello.nl&lt;/a&gt;&lt;br /&gt;
AuthorDate: Wed Jan 14 15:36:26 2009 +0100&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
CommitDate: Wed Jan 14 18:09:00 2009 +0100&lt;br /&gt;
    mutex: preemption fixes&lt;br /&gt;
    The problem is that dropping the spinlock right before schedule is a voluntary&lt;br /&gt;
    preemption point and can cause a schedule, right after which we schedule again.&lt;br /&gt;
    Fix this inefficiency by keeping preemption disabled until we schedule, do this&lt;br /&gt;
    by explicity disabling preemption and providing a schedule() variant that&lt;br /&gt;
    assumes preemption is already disabled.&lt;br /&gt;
Firo: spin_unlock_mutex&lt;/p&gt;

&lt;h2 id=&#34;user-preemption-linux-kernel-user-mode-is-always-user-preemption&#34;&gt;User preemption - Linux kernel user mode is always User preemption.&lt;/h2&gt;

&lt;p&gt;system call returns mode . syscall_return_slowpath&lt;br /&gt;
interrupt hander returns user mode .retint_user-&amp;gt;prepare_exit_to_usermode&lt;/p&gt;

&lt;h2 id=&#34;linux-kernel-kernel-mode-is-coppertive-when-config-preempt-is-not-set&#34;&gt;Linux kernel kernel mode is coppertive when CONFIG_PREEMPT is not set.&lt;/h2&gt;

&lt;p&gt;bloked (which results in a call to schedule())&lt;br /&gt;
If a task in the kernel explicitly calls schedule() it&amp;rsquo;s involuntary!!!&lt;/p&gt;

&lt;h2 id=&#34;linux-kernel-kernel-mode-is-coppertive-preemptive-when-config-preempt-is-set&#34;&gt;Linux kernel kernel mode is coppertive + preemptive when CONFIG_PREEMPT is set.&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;When an interrupt handler exits, before returning to kernel-space.&lt;br /&gt;
retint_kernel-&amp;gt;preempt_schedule_irq-&amp;gt;cond_resched&lt;br /&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;__local_bh_enable_ip -&amp;gt; preempt_check_resched&lt;/p&gt;

&lt;h2 id=&#34;the-following-also-t-relates-to-preemption-it-s-preempt-voluntary&#34;&gt;The following also t relates to preemption; it&amp;rsquo;s PREEMPT_VOLUNTARY.&lt;/h2&gt;

&lt;p&gt;For example, in might_resched(). The task willingly yeilds the CPU, but it should stay on rq.&lt;br /&gt;
config PREEMPT_VOLUNTARY&lt;br /&gt;
    bool &amp;ldquo;Voluntary Kernel Preemption (Desktop)&amp;rdquo;&lt;br /&gt;
    help&lt;br /&gt;
      This option reduces the latency of the kernel by adding more&lt;br /&gt;
      &amp;ldquo;explicit preemption points&amp;rdquo; to the kernel code. These new&lt;br /&gt;
      preemption points have been selected to reduce the maximum&lt;br /&gt;
      latency of rescheduling, providing faster application reactions,&lt;br /&gt;
      at the cost of slightly lower throughput.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;need_resched - When kernel code becomes preemptible again.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;set_tsk_need_resched() in resched_curr&lt;br /&gt;
tick: check_preempt_tick or entity_tick&lt;br /&gt;
fork: wake_up_new_task-&amp;gt;check_preempt_curr-&amp;gt;check_preempt_wakeup&lt;br /&gt;
wakeup: check_preempt_wakeup&lt;br /&gt;
&amp;hellip;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;if (need_resched()) cond_resched();&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;lqo&#34;&gt;LQO&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;if (!preempt &amp;amp;&amp;amp; prev-&amp;gt;state)in __schedule; why prev-&amp;gt;state?&lt;br /&gt;
prev-&amp;gt;state means deactivate.&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;Process scheduling in Linux &amp;ndash; Volker Seeker from University of Edinburgh&lt;br /&gt;
&lt;a href=&#34;https://tampub.uta.fi/bitstream/handle/10024/96864/GRADU-1428493916.pdf&#34;&gt;A complete guide to Linux process scheduling&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt&#34;&gt;https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://helix979.github.io/jkoo/post/os-scheduler/&#34;&gt;JINKYU KOO&amp;rsquo;s Linux kernel scheduler&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.joelfernandes.org/linuxinternals/2016/03/20/tif-need-resched-why-is-it-needed.html&#34;&gt;TIF_NEED_RESCHED: why is it needed&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;general-runqueues&#34;&gt;General runqueues&lt;/h1&gt;

&lt;p&gt;static DEFINE_PER_CPU_SHARED_ALIGNED(struct rq, runqueues);&lt;br /&gt;
activate_task - move a task to the runqueue.&lt;br /&gt;
wake_up_new_task&lt;br /&gt;
ttwu_do_activate&lt;/p&gt;

&lt;h1 id=&#34;latency&#34;&gt;Latency&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/404993/&#34;&gt;Improving scheduler latency&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;cfs-runqueues&#34;&gt;CFS runqueues&lt;/h1&gt;

&lt;p&gt;cfa_rq&lt;br /&gt;
on_list&lt;br /&gt;
sched_entity-&amp;gt;on_rq, check enqueue_entity&lt;/p&gt;

&lt;h2 id=&#34;cfs-runqueue-and-sched-entity&#34;&gt;CFS runqueue and sched entity&lt;/h2&gt;

&lt;p&gt;set_task_rq&lt;/p&gt;

&lt;h2 id=&#34;on-rq&#34;&gt;on_rq&lt;/h2&gt;

&lt;p&gt;on_rq should be same as task-&amp;gt;on_rq. It doesn&amp;rsquo;t mean sched_entity is on cfs_rq, but rq.&lt;br /&gt;
commit fd2f4419b4cbe8fe90796df9617c355762afd6a4&lt;br /&gt;
Author: Peter Zijlstra &lt;a href=&#34;mailto:a.p.zijlstra@chello.nl&#34;&gt;a.p.zijlstra@chello.nl&lt;/a&gt;&lt;br /&gt;
Date:   Tue Apr 5 17:23:44 2011 +0200&lt;br /&gt;
    sched: Provide p-&amp;gt;on_rq&lt;br /&gt;
p-&amp;gt;on_rq on any rq.&lt;br /&gt;
se-&amp;gt;on_rq on specific rq.&lt;/p&gt;

&lt;h2 id=&#34;cfs-runqueue-and-task-group&#34;&gt;CFS runqueue and task group&lt;/h2&gt;

&lt;p&gt;sched_create_group -&amp;gt; alloc_fair_sched_group -&amp;gt; init_tg_cfs_entry&lt;/p&gt;

&lt;h1 id=&#34;cfs-core-codes&#34;&gt;CFS core codes&lt;/h1&gt;

&lt;p&gt;git log 20b8a59f2461e&lt;/p&gt;

&lt;h1 id=&#34;group-scheduling&#34;&gt;Group scheduling&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt&#34;&gt;GROUP SCHEDULER EXTENSIONS TO CFS&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.wowotech.net/process_management/449.html&#34;&gt;CFS调度器（3）-组调度&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://oenhan.com/task-group-sched&#34;&gt;Linux进程组调度机制分析&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;two-trees&#34;&gt;Two trees&lt;/h2&gt;

&lt;p&gt;task_group-&amp;gt;parent; task_group-&amp;gt;css.cgroup&lt;br /&gt;
cgroup-&amp;gt;parent and cgroup_tg: container_of(cgroup_subsys_state(cgrp, cpu_cgroup_subsys_id), struct task_group, css);&lt;/p&gt;

&lt;h2 id=&#34;task-group-and-cgroup-is-1-1&#34;&gt;Task group and cgroup is 1:1&lt;/h2&gt;

&lt;h2 id=&#34;system-bootup&#34;&gt;System bootup&lt;/h2&gt;

&lt;p&gt;struct task_group root_task_group; and cpu_cgroup_create;&lt;/p&gt;

&lt;h2 id=&#34;creating-task-group&#34;&gt;Creating task_group&lt;/h2&gt;

&lt;p&gt;sched_create_group&lt;br /&gt;
task_group 1 : cpu &amp;lsquo;group sched_entity&amp;rsquo;&lt;br /&gt;
group sched_entity 1 : 1 greoup cfs_rq&lt;br /&gt;
gse_CPUx&amp;rsquo;s load = grq_CPUx&amp;rsquo;s all se&amp;rsquo;s load * task_group-&amp;gt;shares / grq_CPU&lt;em&gt;&amp;rsquo;s all se&amp;rsquo;s load&lt;br /&gt;
        /&lt;/em&gt; rq on which this entity is (to be) queued: */&lt;br /&gt;
        struct cfs_rq           &lt;em&gt;cfs_rq;&lt;br /&gt;
        /&lt;/em&gt; rq &amp;ldquo;owned&amp;rdquo; by this entity/group: */&lt;br /&gt;
        struct cfs_rq           *my_q;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/240474/&#34;&gt;CFS group scheduling&lt;/a&gt;&lt;br /&gt;
commit 29f59db3a74b0bdf78a1f5b53ef773caa82692dc&lt;br /&gt;
Author: Srivatsa Vaddagiri &lt;a href=&#34;mailto:vatsa@linux.vnet.ibm.com&#34;&gt;vatsa@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
Date:   Mon Oct 15 17:00:07 2007 +0200&lt;br /&gt;
    sched: group-scheduler core&lt;/p&gt;

&lt;h2 id=&#34;why-double-for-each-sched-entity&#34;&gt;Why double for_each_sched_entity&lt;/h2&gt;

&lt;p&gt;commit 2069dd75c7d0f49355939e5586daf5a9ab216db7&lt;br /&gt;
Author: Peter Zijlstra &lt;a href=&#34;mailto:a.p.zijlstra@chello.nl&#34;&gt;a.p.zijlstra@chello.nl&lt;/a&gt;&lt;br /&gt;
Date:   Mon Nov 15 15:47:00 2010 -0800&lt;br /&gt;
    sched: Rewrite tg_shares_up)&lt;/p&gt;

&lt;p&gt;371fd7e7a56a5 (Peter Zijlstra       2010-03-24 16:38:48 +0100 1129) enqueue_task_fair(struct rq *rq, struct task_struct *p, int flags)&lt;br /&gt;
bf0f6f24a1ece (Ingo Molnar          2007-07-09 18:51:58 +0200 1134)     for_each_sched_entity(se) {&lt;br /&gt;
62fb185130e4d (Peter Zijlstra       2008-02-25 17:34:02 +0100 1135)             if (se-&amp;gt;on_rq)&lt;br /&gt;
bf0f6f24a1ece (Ingo Molnar          2007-07-09 18:51:58 +0200 1136)                     break;&lt;br /&gt;
bf0f6f24a1ece (Ingo Molnar          2007-07-09 18:51:58 +0200 1137)             cfs_rq = cfs_rq_of(se);&lt;br /&gt;
88ec22d3edb72 (Peter Zijlstra       2009-12-16 18:04:41 +0100 1138)             enqueue_entity(cfs_rq, se, flags);&lt;br /&gt;
88ec22d3edb72 (Peter Zijlstra       2009-12-16 18:04:41 +0100 1139)             flags = ENQUEUE_WAKEUP;&lt;br /&gt;
bf0f6f24a1ece (Ingo Molnar          2007-07-09 18:51:58 +0200 1140)     }&lt;br /&gt;
8f4d37ec073c1 (Peter Zijlstra       2008-01-25 21:08:29 +0100 1141)&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1142)     for_each_sched_entity(se) {&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1143)             struct cfs_rq *cfs_rq = cfs_rq_of(se);&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1144)&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1145)             update_cfs_load(cfs_rq);&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1146)             update_cfs_shares(cfs_rq);&lt;/p&gt;

&lt;h1 id=&#34;wake-up&#34;&gt;Wake up&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lkml.org/lkml/2015/4/19/111&#34;&gt;sched: lockless wake-queues&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=-8c47dHuGIY&#34;&gt;Futex Scaling for Multi-core Systems&lt;/a&gt;&lt;a href=&#34;https://www.slideshare.net/davidlohr/futex-scaling-for-multicore-systems&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;program-order-guarantees&#34;&gt;Program-Order guarantees&lt;/h1&gt;

&lt;p&gt;commit 8643cda549ca49a403160892db68504569ac9052&lt;br /&gt;
Author: Peter Zijlstra &lt;a href=&#34;mailto:peterz@infradead.org&#34;&gt;peterz@infradead.org&lt;/a&gt;&lt;br /&gt;
Date:   Tue Nov 17 19:01:11 2015 +0100&lt;br /&gt;
    sched/core, locking: Document Program-Order guarantees&lt;/p&gt;

&lt;h2 id=&#34;lkml-discussions&#34;&gt;LKML discussions&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lkml.org/lkml/2015/11/2/311&#34;&gt;scheduler ordering bits&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lkml.org/lkml/2015/12/3/323&#34;&gt;scheduler ordering bits -v2&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;pi-lock&#34;&gt;pi_lock&lt;/h2&gt;

&lt;p&gt;commit b29739f902ee76a05493fb7d2303490fc75364f4&lt;br /&gt;
Author: Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
Date:   Tue Jun 27 02:54:51 2006 -0700&lt;br /&gt;
    [PATCH] pi-futex: scheduler support for pi&lt;br /&gt;
    Add framework to boost/unboost the priority of RT tasks.&lt;/p&gt;

&lt;h1 id=&#34;rq-lock-in-schedule-and-context-switch&#34;&gt;rq-&amp;gt;lock in schedule() and context_switch()&lt;/h1&gt;

&lt;p&gt;commit 3a5f5e488ceee9e08df3dff3f01b12fafc9e7e68&lt;br /&gt;
Author: Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
Date:   Fri Jul 14 00:24:27 2006 -0700&lt;br /&gt;
    [PATCH] lockdep: core, fix rq-lock handling on __ARCH_WANT_UNLOCKED_CTXSW&lt;br /&gt;
+        * Since the runqueue lock will be released by the next&lt;br /&gt;
+        * task&lt;/p&gt;

&lt;h1 id=&#34;running-time&#34;&gt;Running time&lt;/h1&gt;

&lt;p&gt;proc_sched_show_task&lt;/p&gt;

&lt;h1 id=&#34;problems&#34;&gt;Problems&lt;/h1&gt;

&lt;h2 id=&#34;why-scheduling&#34;&gt;Why scheduling?&lt;/h2&gt;

&lt;p&gt;Customers demand multitasking/concurrent&lt;br /&gt;
Processes are blocked&lt;/p&gt;

&lt;h2 id=&#34;fairness&#34;&gt;Fairness&lt;/h2&gt;

&lt;p&gt;Unit: /proc/sys/kernel/sched_min_granularity_ns&lt;/p&gt;

&lt;h1 id=&#34;conceptions&#34;&gt;Conceptions&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://android.googlesource.com/kernel/msm/+/android-msm-bullhead-3.10-marshmallow-dr/Documentation/scheduler/sched-hmp.txt&#34;&gt;Cpu capacity&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;running-compensator-records-the-running-process&#34;&gt;Running Compensator records the running process&lt;/h1&gt;

&lt;p&gt;scheduler_tick&lt;br /&gt;
{&lt;br /&gt;
    update_rq_clock&lt;br /&gt;
    task_tick_fair -&amp;gt; entity_tick&lt;br /&gt;
    {&lt;br /&gt;
        update_curr&lt;br /&gt;
        {&lt;br /&gt;
            sum_exec_runtime - total runtime&lt;br /&gt;
            cfs_rq-&amp;gt;exec_clock - cfs_rq runtime&lt;br /&gt;
            vruntime    - inverse proportion to the weight or priority&lt;br /&gt;
            update_min_vruntime&lt;br /&gt;
            {&lt;br /&gt;
                cfs_rq-&amp;gt;curr, leftmost, min_vruntime, who is min?&lt;br /&gt;
            }&lt;br /&gt;
            cpuacct - cpu sys/user time&lt;br /&gt;
        }&lt;br /&gt;
    }&lt;br /&gt;
}&lt;/p&gt;

&lt;h1 id=&#34;next-pick-next-task-fair&#34;&gt;Next -&amp;gt; pick_next_task_fair&lt;/h1&gt;

&lt;p&gt;put_prev_entity: update_curr; insert into rb-tree;&lt;br /&gt;
pick_next_entity: left most of rb-tree.&lt;br /&gt;
set_next_entity: remove next from tree since it will disturb inserting and deleting when it is being updated.&lt;/p&gt;

&lt;h1 id=&#34;unrunnable&#34;&gt;Unrunnable&lt;/h1&gt;

&lt;p&gt;dequeue_task&lt;/p&gt;

&lt;h1 id=&#34;resuming&#34;&gt;Resuming&lt;/h1&gt;

&lt;p&gt;try_to_wake_up-&amp;gt;ttwu_queue-&amp;gt;ttwu_do_activate-&amp;gt; or local wakeup: schedule-&amp;gt;try_to_wake_up_local-&amp;gt;&lt;br /&gt;
{&lt;br /&gt;
    ttwu_activate               #=== speical compensation and enqueue rq&lt;br /&gt;
    {&lt;br /&gt;
        activate_task&lt;br /&gt;
        p-&amp;gt;on_rq = TASK_ON_RQ_QUEUED    #=== 1) rq for task; 2)&lt;br /&gt;
    }&lt;br /&gt;
    ttwu_do_wakeup              #=== normal compensation&lt;br /&gt;
    {&lt;br /&gt;
        check_preempt_curr&lt;br /&gt;
        p-&amp;gt;state = TASK_RUNNING;&lt;br /&gt;
    }&lt;br /&gt;
}&lt;/p&gt;

&lt;p&gt;enqueue_task-&amp;gt; place_entity compensation for wakeup process&lt;/p&gt;

&lt;h2 id=&#34;wake-up-a-sleep-task&#34;&gt;wake up a sleep task&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;se-&amp;gt;on_rq &amp;amp; TASK_ON_RQ_QUEUED; deactivate_task set on_rq to 0;
enqueue_task_fair handles group stuff
enqueue_entity deals with sched_entity - uptodate the vruntime, load average, account load numa perfering,
sysctl_sched_latency: the cfs pledge to the pre-existing tasks that they have 6ms to run before new task to run.
try_to_wake_up_local for local task
try_to_wake_up for any task
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;new-task&#34;&gt;New task&lt;/h1&gt;

&lt;p&gt;speical debit compensation: sched_fork-&amp;gt;task_fork_fair-&amp;gt;place_entity - compensation for new process&lt;br /&gt;
normal compensation: wake_up_new_task&lt;br /&gt;
{&lt;br /&gt;
    activate_task               #=== speical compensation&lt;br /&gt;
    check_preempt_curr          #=== normal compensation&lt;br /&gt;
}&lt;/p&gt;

&lt;h1 id=&#34;priority&#34;&gt;Priority&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;weight&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;priority&lt;br /&gt;
DEFAULT_PRIO&lt;br /&gt;
fs/proc/array.c&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;latency-1&#34;&gt;Latency&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;sched_nr_latency= /proc/sys/kernel/sched_latency_ns / /proc/sys/kernel/sched_min_granularity_ns&lt;br /&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;if running process &amp;gt; sched_nr_latency, latency cannot be ensured. just focus on min granularity&lt;/p&gt;

&lt;h2 id=&#34;lqo-1&#34;&gt;LQO&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;is the difference of leftmost and rightmost smaller than sched_min_granularity_ns??&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;sched_slice&lt;/p&gt;

&lt;h1 id=&#34;energy&#34;&gt;Energy&lt;/h1&gt;

&lt;p&gt;blocked &amp;amp; schedule&lt;br /&gt;
check preempt &amp;amp; schedule&lt;br /&gt;
check_preempt_tick              # new preempts curr&lt;br /&gt;
{&lt;br /&gt;
curr running time &amp;gt; sched_slice     # enough time to yield.&lt;br /&gt;
curr - leftmost &amp;gt; sched_slice       # nice to others.&lt;br /&gt;
}&lt;br /&gt;
check_preempt_wakeup                # the wakeuped preempts curr&lt;br /&gt;
{&lt;br /&gt;
curr - wakeuped &amp;gt; sysctl_sched_wakeup_granularity;  # pass the wakeup-preempt-delay&lt;br /&gt;
}&lt;/p&gt;

&lt;h1 id=&#34;io-wait&#34;&gt;io wait&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/342378/&#34;&gt;https://lwn.net/Articles/342378/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;load-avg&#34;&gt;Load avg&lt;/h1&gt;

&lt;p&gt;update_load&lt;em&gt;avg&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Load&#34;&gt;https://en.wikipedia.org/wiki/Load&lt;/a&gt;&lt;/em&gt;(computing)&lt;br /&gt;
Check External links&lt;br /&gt;
calc_load_fold_active&lt;br /&gt;
Etymology of avenrun: &lt;a href=&#34;https://elixir.bootlin.com/linux/v4.1/source/arch/s390/appldata/appldata_os.c&#34;&gt;average nr. of running processes during&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;lqo-2&#34;&gt;LQO&lt;/h1&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;h_nr_running and throttled&lt;br /&gt;
sched: Implement hierarchical task accounting for SCHED_OTHER - 953bfcd10e6f3697233e8e5128c611d275da39c1&lt;br /&gt;
&lt;a href=&#34;https://groups.google.com/forum/#!topic/linux.kernel/gRzxHclMy50&#34;&gt;https://groups.google.com/forum/#!topic/linux.kernel/gRzxHclMy50&lt;/a&gt;&lt;br /&gt;
&amp;lsquo;root&amp;rsquo;&lt;br /&gt;
\&lt;br /&gt;
&amp;lsquo;A&amp;rsquo;&lt;br /&gt;
/ \&lt;br /&gt;
t1 t2&lt;br /&gt;
root.nr_running := 2&lt;br /&gt;
root.h_nr_running := 2&lt;br /&gt;
Check enqueue_task_fair()&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;idle&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/scheduler/sched-arch.txt&#34;&gt;https://www.kernel.org/doc/Documentation/scheduler/sched-arch.txt&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/136065/&#34;&gt;improve SMP reschedule and idle routines&lt;/a&gt;&lt;br /&gt;
TIF_POLLING_NRFLAG -&amp;gt; Need-Resched-Flag?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;process migration&lt;br /&gt;
e761b7725234276a802322549cee5255305a0930&lt;br /&gt;
Introduce cpu_active_map and redo sched domain managment&lt;br /&gt;
When to migration&lt;br /&gt;
    sched_setaffinity __set_cpus_allowed_ptr manuly&lt;br /&gt;
    Selecting a new CPU during wak up a sleeper&lt;br /&gt;
    For balancing, selecting CPU during  wake up new process in _do_fork&lt;br /&gt;
    execve&amp;rsquo;s sched_exec&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;shceduler clock&lt;br /&gt;
rq-&amp;gt;clock is nano seconds?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;clock_task and wraps&lt;br /&gt;
fe44d62122829959e960bc699318d58966922a69&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;START_DEBIT&lt;br /&gt;
no standalone commit&lt;br /&gt;
bf0f6f24a1ece8988b243aefe84ee613099a9245&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;why ahead?&lt;br /&gt;
8 /*&lt;br /&gt;
9  * Place new tasks ahead so that they do not starve already running&lt;br /&gt;
10  * tasks&lt;br /&gt;
11  */&lt;br /&gt;
12 SCHED_FEAT(START_DEBIT, true)&lt;br /&gt;
the tree is named timeline&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lwn.net/Articles/404993/&#34;&gt;Improving scheduler latency &lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;skip next last buddy&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;git-log&#34;&gt;Git log&lt;/h1&gt;

&lt;p&gt;e9c8431185d6c406887190519f6dbdd112641686&lt;br /&gt;
TASK_WAKING; see migrate_task_rq_fair and try_to_wake_up&lt;br /&gt;
88ec22d3edb72b261f8628226cd543589a6d5e1b&lt;br /&gt;
In order to remove the cfs_rq dependency from set_task_cpu() we need to ensure the task is cfs_rq invariant for all callsites.&lt;br /&gt;
2f950354e6d535b892f133d20bd6a8b09430424c&lt;br /&gt;
sched/fair: Fix fairness issue on migration&lt;br /&gt;
&lt;a href=&#34;http://linux.kernel.narkive.com/p15Wmn0i/migrated-cfs-task-getting-an-unfair-advantage&#34;&gt;Migrated CFS task getting an unfair advantage&lt;/a&gt;&lt;br /&gt;
30cfdcfc5f180fc21a3dad6ae3b7b2a9ee112186&lt;br /&gt;
curr was not kept in rb-tree&lt;/p&gt;

&lt;h1 id=&#34;load-balancing&#34;&gt;Load balancing&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/80911/&#34;&gt;Scheduling domains&lt;/a&gt;&lt;br /&gt;
set sd&lt;br /&gt;
kernel_init_freeable-&amp;gt;&lt;br /&gt;
sched_init_smp-&amp;gt;&lt;br /&gt;
init_sched_domains-&amp;gt;build_sched_domains:-&amp;gt;&lt;br /&gt;
&lt;strong&gt;visit_domain_allocation_hell()-&amp;gt;&lt;/strong&gt;sdt_alloc() alloc the sdd-&amp;gt;sg which is used by build groups&lt;br /&gt;
and sg = kzalloc_node(sizeof(struct sched_group) + cpumask_size(); it covered the size of cpumask&lt;br /&gt;
/* Build the groups for the domains */&lt;br /&gt;
detach_destroy_domains&lt;br /&gt;
cpu_attach_domain&lt;/p&gt;

&lt;p&gt;CONFIG_SCHED_MC=y&lt;br /&gt;
static noinline struct sched_domain *                                   &lt;br /&gt;
sd&lt;em&gt;init&lt;/em&gt;##type(struct sched_domain_topology_level *tl, int cpu)         &lt;br /&gt;
{                                                                       &lt;br /&gt;
        struct sched_domain *sd = *per_cpu&lt;em&gt;ptr(tl-&amp;gt;data.sd, cpu);       &lt;br /&gt;
        *sd = SD&lt;/em&gt;##type##_INIT;                                         &lt;br /&gt;
        SD_INIT_NAME(sd, type);                                         &lt;br /&gt;
        sd-&amp;gt;private = &amp;amp;tl-&amp;gt;data;                                        &lt;br /&gt;
        return sd;                                                      &lt;br /&gt;
}&lt;br /&gt;
tl-&amp;gt;mask(cpu)&lt;br /&gt;
static struct sched_domain_topology_level default_topology[] = {&lt;br /&gt;
#ifdef CONFIG_SCHED_SMT&lt;br /&gt;
        { sd_init_SIBLING, cpu_smt_mask, },&lt;br /&gt;
#endif&lt;br /&gt;
#ifdef CONFIG_SCHED_MC&lt;br /&gt;
        { sd_init_MC, cpu_coregroup_mask, },&lt;br /&gt;
#endif&lt;br /&gt;
#ifdef CONFIG_SCHED_BOOK&lt;br /&gt;
        { sd_init_BOOK, cpu_book_mask, },&lt;br /&gt;
#endif&lt;br /&gt;
        { sd_init_CPU, cpu_cpu_mask, },&lt;br /&gt;
        { NULL, },&lt;br /&gt;
};&lt;/p&gt;

&lt;h2 id=&#34;leaf-cfs-runqueues-leaf-cfs-rq&#34;&gt;Leaf CFS runqueues leaf_cfs_rq&lt;/h2&gt;

&lt;h3 id=&#34;first&#34;&gt;First&lt;/h3&gt;

&lt;p&gt;commit 6aa645ea5f7a246702e07f29edc7075d487ae4a3&lt;br /&gt;
Refs: v2.6.22-14-g6aa645ea5f7a&lt;br /&gt;
Author:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
AuthorDate: Mon Jul 9 18:51:58 2007 +0200&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
CommitDate: Mon Jul 9 18:51:58 2007 +0200&lt;br /&gt;
    sched: cfs rq data types&lt;br /&gt;
 * leaf cfs_rqs are those that hold tasks (lowest schedulable entity in&lt;br /&gt;
 * a hierarchy). Non-leaf lrqs hold other higher schedulable entities&lt;br /&gt;
 * (like users, containers etc.)&lt;br /&gt;
 * leaf_cfs_rq_list ties together list of leaf cfs_rq&amp;rsquo;s in a cpu. This&lt;br /&gt;
 * list is used during load balance.&lt;br /&gt;
Head of list: rq-&amp;gt;leaf_cfs_rq_list&lt;/p&gt;

&lt;h3 id=&#34;core-load-balance-fair&#34;&gt;Core load_balance_fair&lt;/h3&gt;

&lt;p&gt;commit bf0f6f24a1ece8988b243aefe84ee613099a9245&lt;br /&gt;
Refs: v2.6.22-10-gbf0f6f24a1ec&lt;br /&gt;
Author:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
AuthorDate: Mon Jul 9 18:51:58 2007 +0200&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
CommitDate: Mon Jul 9 18:51:58 2007 +0200&lt;br /&gt;
    sched: cfs core, kernel/sched_fair.c&lt;br /&gt;
    add kernel/sched_fair.c - which implements the bulk of CFS&amp;rsquo;s&lt;br /&gt;
    behavioral changes for SCHED_OTHER tasks.&lt;br /&gt;
+load_balance_fair(struct rq *this_rq, int this_cpu, struct rq *busiest,&lt;br /&gt;
+       for_each_leaf_cfs_rq(busiest, busy_cfs_rq) {&lt;/p&gt;

&lt;h3 id=&#34;make-parent-appear-after-us&#34;&gt;make parent appear after us.&lt;/h3&gt;

&lt;p&gt;commit 67e86250f8ea7b8f7da53ac25ea73c6bd71f5cd9&lt;br /&gt;
Author: Paul Turner &lt;a href=&#34;mailto:pjt@google.com&#34;&gt;pjt@google.com&lt;/a&gt;&lt;br /&gt;
Date:   Mon Nov 15 15:47:05 2010 -0800&lt;br /&gt;
    sched: Introduce hierarchal order on shares update list&lt;br /&gt;
    Avoid duplicate shares update calls by ensuring children always appear before                 # leaf&amp;rsquo;s meaning is changed&lt;br /&gt;
    parents in rq-&amp;gt;leaf_cfs_rq_list.&lt;br /&gt;
    This allows us to do a single in-order traversal for update_shares().&lt;br /&gt;
    Since we always enqueue in bottom-up order this reduces to 2 cases:&lt;br /&gt;
    1) Our parent is already in the list, e.g.&lt;br /&gt;
       root&lt;br /&gt;
         &lt;br /&gt;
          b&lt;br /&gt;
          /&lt;br /&gt;
          c d* (root-&amp;gt;b-&amp;gt;c already enqueued)&lt;br /&gt;
    Since d&amp;rsquo;s parent is enqueued we push it to the head of the list, implicitly ahead of b.&lt;br /&gt;
    2) Our parent does not appear in the list (or we have no parent)&lt;br /&gt;
    In this case we enqueue to the tail of the list, if our parent is subsequently enqueued&lt;br /&gt;
    (bottom-up) it will appear to our right by the same rule.&lt;/p&gt;

&lt;h3 id=&#34;tmp-alone-branch&#34;&gt;tmp_alone_branch&lt;/h3&gt;

&lt;p&gt;commit 9c2791f936ef5fd04a118b5c284f2c9a95f4a647&lt;br /&gt;
Refs: v4.9-rc5-195-g9c2791f936ef&lt;br /&gt;
Author:     Vincent Guittot &lt;a href=&#34;mailto:vincent.guittot@linaro.org&#34;&gt;vincent.guittot@linaro.org&lt;/a&gt;&lt;br /&gt;
AuthorDate: Tue Nov 8 10:53:43 2016 +0100&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@kernel.org&#34;&gt;mingo@kernel.org&lt;/a&gt;&lt;br /&gt;
CommitDate: Wed Nov 16 10:29:08 2016 +0100&lt;br /&gt;
    sched/fair: Fix hierarchical order in rq-&amp;gt;leaf_cfs_rq_list&lt;br /&gt;
    Fix the insertion of cfs_rq in rq-&amp;gt;leaf_cfs_rq_list to ensure that a&lt;br /&gt;
    child will always be called before its parent.&lt;br /&gt;
    The hierarchical order in shares update list has been introduced by&lt;br /&gt;
    commit:&lt;br /&gt;
      67e86250f8ea (&amp;ldquo;sched: Introduce hierarchal order on shares update list&amp;rdquo;)&lt;/p&gt;

&lt;p&gt;commit 5d299eabea5a251fbf66e8277704b874bbba92dc&lt;br /&gt;
Author: Peter Zijlstra &lt;a href=&#34;mailto:peterz@infradead.org&#34;&gt;peterz@infradead.org&lt;/a&gt;&lt;br /&gt;
Date:   Wed Jan 30 14:41:04 2019 +0100&lt;br /&gt;
    sched/fair: Add tmp_alone_branch assertion&lt;br /&gt;
    The magic in list_add_leaf_cfs_rq() requires that at the end of&lt;br /&gt;
    enqueue_task_fair():&lt;br /&gt;
      rq-&amp;gt;tmp_alone_branch == &amp;amp;rq-&amp;gt;lead_cfs_rq_list&lt;/p&gt;

&lt;h3 id=&#34;load-balance-fair-removed&#34;&gt;load_balance_fair - removed&lt;/h3&gt;

&lt;p&gt;commit 9763b67fb9f3050c6da739105888327587c30c4d&lt;br /&gt;
Refs: v3.0-rc7-197-g9763b67fb9f3&lt;br /&gt;
Author:     Peter Zijlstra &lt;a href=&#34;mailto:a.p.zijlstra@chello.nl&#34;&gt;a.p.zijlstra@chello.nl&lt;/a&gt;&lt;br /&gt;
AuthorDate: Wed Jul 13 13:09:25 2011 +0200&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
CommitDate: Thu Jul 21 18:01:46 2011 +0200&lt;br /&gt;
    sched, cgroup: Optimize load_balance_fair()&lt;br /&gt;
    Use for_each_leaf_cfs_rq() instead of list_for_each_entry_rcu(), this&lt;br /&gt;
    achieves that load_balance_fair() only iterates those task_groups that&lt;br /&gt;
    actually have tasks on busiest, and that we iterate bottom-up, trying to&lt;br /&gt;
    move light groups before the heavier ones.&lt;/p&gt;

&lt;h1 id=&#34;throttling-entities&#34;&gt;Throttling entities&lt;/h1&gt;

&lt;p&gt;commit 85dac906bec3bb41bfaa7ccaa65c4706de5cfdf8&lt;br /&gt;
Author: Paul Turner &lt;a href=&#34;mailto:pjt@google.com&#34;&gt;pjt@google.com&lt;/a&gt;&lt;br /&gt;
Date:   Thu Jul 21 09:43:33 2011 -0700&lt;br /&gt;
    sched: Add support for throttling group entities&lt;br /&gt;
    Now that consumption is tracked (via update_curr()) we add support to throttle&lt;br /&gt;
    group entities (and their corresponding cfs_rqs) in the case where this is no&lt;br /&gt;
    run-time remaining.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>System booting</title>
      <link>http://firoyang.org/cs/boot/</link>
      <pubDate>Thu, 12 Nov 2015 00:00:00 UTC</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/boot/</guid>
      <description>

&lt;h1 id=&#34;smp-boot&#34;&gt;SMP boot&lt;/h1&gt;

&lt;p&gt;Check SDM v3 BSP and AP Processors&lt;br /&gt;
BSP - boot strap processor； AP - application processor&lt;/p&gt;

&lt;h2 id=&#34;core-commit&#34;&gt;Core commit&lt;/h2&gt;

&lt;p&gt;setup_real_mode-&amp;gt; trampoline_header-&amp;gt;start = (u64) secondary_startup_64;&lt;br /&gt;
commit f37240f16bec91f15ce564515f70a6ca9715ce96&lt;br /&gt;
Author: Jarkko Sakkinen &lt;a href=&#34;mailto:jarkko.sakkinen@intel.com&#34;&gt;jarkko.sakkinen@intel.com&lt;/a&gt;&lt;br /&gt;
Date:   Tue May 8 21:22:43 2012 +0300&lt;br /&gt;
    x86, realmode: header for trampoline code&lt;/p&gt;

&lt;h2 id=&#34;bsp&#34;&gt;BSP&lt;/h2&gt;

&lt;h3 id=&#34;build-time-for-real-mode-header-in-arch-x86-realmode-rm-header-s&#34;&gt;Build time for real_mode_header in arch/x86/realmode/rm/header.S&lt;/h3&gt;

&lt;p&gt;In pasyms.h, git gud!&lt;br /&gt;
pa_trampoline_header = trampoline_header;&lt;br /&gt;
pa_trampoline_start = trampoline_start;&lt;br /&gt;
pa_startup_32 = startup_32;&lt;br /&gt;
pa_startup_64 = startup_64;&lt;/p&gt;

&lt;h3 id=&#34;early-init&#34;&gt;Early init&lt;/h3&gt;

&lt;p&gt;setup_real_mode-&amp;gt; trampoline_header-&amp;gt;start = (u64) secondary_startup_64;  # tr_start&lt;/p&gt;

&lt;h3 id=&#34;start-kernel&#34;&gt;start_kernel&lt;/h3&gt;

&lt;p&gt;kernel_init-&amp;gt;smp_init-&amp;gt;cpu_up-&amp;gt;do_cpu_up-&amp;gt;_cpu_up-&amp;gt;&lt;br /&gt;
ap hp threadfn -&amp;gt; bringup_cpu -&amp;gt; __cpu_up -&amp;gt; smp_ops.cpu_up(cpu, tidle) is native_cpu_up&lt;br /&gt;
        do_boot_cpu is the core function. It set up the code for APs to run and check cpu_callin_mask.&lt;br /&gt;
        start_eip = real_mode_header-&amp;gt;trampoline_start;&lt;br /&gt;
        initial_code = (unsigned long)start_secondary                   # initial_code&lt;/p&gt;

&lt;h2 id=&#34;ap&#34;&gt;AP&lt;/h2&gt;

&lt;p&gt;trampoline_start -&amp;gt; &amp;hellip; -&amp;gt; startup_64 -&amp;gt; tr_start(%rip) is secondary_startup_64 -&amp;gt; initial_code(%rip) is start_secondary&lt;br /&gt;
-&amp;gt; cpu_init&lt;/p&gt;

&lt;h1 id=&#34;initrd&#34;&gt;initrd&lt;/h1&gt;

&lt;p&gt;related code:&lt;br /&gt;
reserve_initrd&lt;br /&gt;
subsys_initcall(genhd_device_init);-&amp;gt;kobj_map_init{bdev_map.probe.get = base_probe}&lt;br /&gt;
subsys_initcall(init_scsi);4-&amp;gt;scsi_sysfs_register{autoprobe = 1;}&lt;br /&gt;
rootfs_initcall(populate_rootfs);-&amp;gt;{unpack_to_rootfs; 解压initramfs到rootfs}&lt;br /&gt;
module_initinit_sd;6-&amp;gt;scsi_register_driver -&amp;gt;driver_register-&amp;gt;bus_add_driver -&amp;gt;driver_attach -&amp;gt;driver_probe_device-&amp;gt; drv-&amp;gt;probe(dev)=sd_probe_async-&amp;gt;add_disk -&amp;gt; register_disk -&amp;gt; get_gendisk -&amp;gt; kobj_lookup { bdev_map.probe.get()=base_probe(){request_module}}&lt;/p&gt;

&lt;h1 id=&#34;vs-initramfs&#34;&gt;vs initramfs&lt;/h1&gt;

&lt;p&gt;initrd is image with specific fs type, like ext2, need driver built-in kernel.&lt;br /&gt;
initramfs is a cpio, like tar only simpler, populated to rootfs in kernel, with fs type rootfs&lt;/p&gt;

&lt;h1 id=&#34;root-device&#34;&gt;root device&lt;/h1&gt;

&lt;p&gt;Related code:&lt;br /&gt;
root= name_to_dev_t, mount_root in prepare_namespace&lt;/p&gt;

&lt;h1 id=&#34;kernel-boot-process&#34;&gt;kernel boot process&lt;/h1&gt;

&lt;p&gt;Documentation/x86/boot.txt&lt;br /&gt;
&lt;a href=&#34;https://manybutfinite.com/post/kernel-boot-process/&#34;&gt;The Kernel Boot Process&lt;/a&gt;&lt;br /&gt;
arch/x86/boot/header.S::start_of_setup&lt;br /&gt;
arch/x86/boot/main.c::main()&lt;br /&gt;
    arch/x86/boot/memory.c::detect_memory()&lt;br /&gt;
    arch/x86/boot/memory.c::detect_memory_e820() = boot_params.e820_entries&lt;br /&gt;
    arch/x86/boot/pm.c::go_to_protected_mode()&lt;br /&gt;
arch/x86/boot/pmjump.S::protected_mode_jump&lt;br /&gt;
arch/x86/kernel/compressed/head_64.S::startup_32&lt;br /&gt;
arch/x86/kernel/compressed/head_64.S::startup_64&lt;br /&gt;
arch/x86/kernel/head_64.S::startup_64&lt;br /&gt;
kernel/main.c::start_kernel()&lt;/p&gt;

&lt;h2 id=&#34;reloctaion-for-decompress&#34;&gt;Reloctaion for decompress&lt;/h2&gt;

&lt;p&gt;974f221c84b05b1dc2f5ea50dc16d2a9d1e95eda&lt;br /&gt;
x86/boot: Move compressed kernel to the end of the decompression buffer&lt;/p&gt;

&lt;h2 id=&#34;horrable-commit-description-on-phys-base&#34;&gt;Horrable commit description on phys_base&lt;/h2&gt;

&lt;p&gt;commit 1ab60e0f72f71ec54831e525a3e1154f1c092408&lt;br /&gt;
Author: Vivek Goyal &lt;a href=&#34;mailto:vgoyal@in.ibm.com&#34;&gt;vgoyal@in.ibm.com&lt;/a&gt;&lt;br /&gt;
Date:   Wed May 2 19:27:07 2007 +0200&lt;br /&gt;
    [PATCH] x86-64: Relocatable Kernel Support&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Computer architecture</title>
      <link>http://firoyang.org/cs/arch/</link>
      <pubDate>Tue, 13 Oct 2015 00:00:00 UTC</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/arch/</guid>
      <description>

&lt;h1 id=&#34;computer-architecture&#34;&gt;Computer architecture&lt;/h1&gt;

&lt;p&gt;[Who are the Computer Architects?]&lt;a href=&#34;https://people.cs.clemson.edu/~mark/architects.html&#34;&gt;https://people.cs.clemson.edu/~mark/architects.html&lt;/a&gt;&lt;br /&gt;
The Mathematical Theory of Communication&lt;br /&gt;
Given a symbol level, the architecture is the description of the system in  whatever system-description scheme exists next below the symbol level. - Newell, 1990, p. 81&lt;br /&gt;
Digital Design and Computer Architecture 2nd Edition&lt;br /&gt;
Computer Organization and Design 5th Edition&lt;br /&gt;
Structured Computer Organization 6th Edition&lt;br /&gt;
Write Great Code: Volume 1: Understanding the Machine&lt;/p&gt;

&lt;h2 id=&#34;subfields&#34;&gt;Subfields&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Architectural_state&#34;&gt;Architectural state&lt;/a&gt;&lt;br /&gt;
Microarchitectural state, such as information stored in TLBs and caches&lt;/p&gt;

&lt;h1 id=&#34;circuits&#34;&gt;Circuits&lt;/h1&gt;

&lt;p&gt;A Symbolic Analysis of Relay and Switching Circuits&lt;/p&gt;

&lt;h1 id=&#34;memory-hierarchy&#34;&gt;Memory hierarchy&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html&#34;&gt;Latency Numbers Every Programmer Should Know&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;cpu&#34;&gt;CPU&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://youtu.be/cNN_tTXABUA&#34;&gt;How a CPU Works&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;isa&#34;&gt;ISA&lt;/h2&gt;

&lt;p&gt;ISA: memory model, registers, data types, instructions, word size(?).&lt;br /&gt;
Memory model: unit of address resolution, word, aligment, address space, addressing mode, memory barrier/memory order primitive&amp;rsquo;s semantics.&lt;/p&gt;

&lt;h1 id=&#34;i-o&#34;&gt;I/O&lt;/h1&gt;

&lt;p&gt;serial communication: UART(16550) + RS-232&lt;br /&gt;
parallel communication: SCSI, ISA, ATA, PCI, FSB&lt;/p&gt;

&lt;h2 id=&#34;data-struct-alignment&#34;&gt;Data struct alignment&lt;/h2&gt;

&lt;p&gt;struct foo { char c; int i;};&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/unaligned-memory-access.txt&#34;&gt;UNALIGNED MEMORY ACCESSES&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://pzemtsov.github.io/2016/11/06/bug-story-alignment-on-x86.html&#34;&gt;A bug story: data alignment on x86&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.catb.org/esr/structure-packing/&#34;&gt;The Lost Art of C Structure Packing&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://en.wikipedia.org/wiki/Data_structure_alignment#Typical_alignment_of_C_structs_on_x86&#34;&gt;Typical alignment of C structs on x86&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;reasons-for-not-alignment&#34;&gt;Reasons for not alignment&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Casting variables to types of different lengths, e.g. char * to int *&lt;br /&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pointer arithmetic followed by access to at least 2 bytes of data , 不太理解.&lt;/p&gt;

&lt;h3 id=&#34;programming-skills&#34;&gt;Programming skills&lt;/h3&gt;

&lt;p&gt;Reorder members of struct;&lt;br /&gt;
get/put_unaligned to avoid analigned access.&lt;br /&gt;
attribute aligned&lt;/p&gt;

&lt;h3 id=&#34;calculate-the-sizeof-of-aligned-c-struct&#34;&gt;Calculate the sizeof of aligned c struct&lt;/h3&gt;

&lt;p&gt;Data alignment means putting the data at a memory address equal to some multiple of the word size, which increases the system&amp;rsquo;s performance due to the way the CPU handles memory.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;find the widest scalar member and attribute( aligned(x)) to determin alignment.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;fill the member to alignement without wrap&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pading to alignment&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;endianess-and-bitfield&#34;&gt;Endianess and bitfield&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gcc.gnu.org/onlinedocs/gcc/Structures-unions-enumerations-and-bit-fields-implementation.html&#34;&gt;The order of allocation of bit-fields within a unit&lt;/a&gt;&lt;br /&gt;
It&amp;rsquo;s Determined by ABI not Gcc. Check comments on &lt;a href=&#34;https://stackoverflow.com/questions/47600584/bitfield-endianness-in-gcc&#34;&gt;Bitfield endianness in gcc&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;how-endianness-effects-bitfield-packing-http-mjfrazer-org-mjfrazer-bitfields&#34;&gt;&lt;a href=&#34;http://mjfrazer.org/mjfrazer/bitfields/&#34;&gt;How Endianness Effects Bitfield Packing&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;if defined(__LITTLE_ENDIAN_BITFIELD)&lt;br /&gt;
    __u8    ihl:4,&lt;br /&gt;
        version:4;  # MSB, check wikipeida ipv4 header&lt;/p&gt;

&lt;h3 id=&#34;gcc-bug-on-bitfield&#34;&gt;GCC bug on bitfield&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/478657/&#34;&gt;Betrayed by a bitfield&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;dma&#34;&gt;DMA&lt;/h1&gt;

&lt;p&gt;Check books COD, COA and ULK 3rd&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux time subsystem</title>
      <link>http://firoyang.org/cs/time/</link>
      <pubDate>Tue, 22 Sep 2015 00:00:00 UTC</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/time/</guid>
      <description>

&lt;h1 id=&#34;formal-causes&#34;&gt;Formal causes&lt;/h1&gt;

&lt;h1 id=&#34;tsc&#34;&gt;TSC&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://oliveryang.net/2015/09/pitfalls-of-TSC-usage/&#34;&gt;Pitfalls of TSC usage&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/388188/&#34;&gt;The trouble with the TSC&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;genus-differentia-definition&#34;&gt;Genus-differentia definition&lt;/h2&gt;

&lt;p&gt;interrupt, clock event,  clock source, tick, timer, timekeeping, gettimeofday.&lt;/p&gt;

&lt;h2 id=&#34;unites&#34;&gt;unites&lt;/h2&gt;

&lt;p&gt;cputime = jiffies under HZ (FIXME)&lt;br /&gt;
sum_exec_runtime nanoseconds&lt;br /&gt;
clockt = jiffies but under USER_HZ&lt;/p&gt;

&lt;h2 id=&#34;功用定义&#34;&gt;功用定义&lt;/h2&gt;

&lt;p&gt;获取时间&lt;br /&gt;
timer&lt;br /&gt;
sleep ?&lt;br /&gt;
update sched info&lt;/p&gt;

&lt;h2 id=&#34;发生定义-设计-etymology-history-operational-definition&#34;&gt;发生定义/设计   etymology, history Operational definition&lt;/h2&gt;

&lt;p&gt;timekeeping/计时:时刻．&lt;br /&gt;
clock source: 时间之源, 表针之力.&lt;br /&gt;
clock event: 闹铃之力, 经过tick展现能力.&lt;br /&gt;
tick: timer的中断事件叫tick, tick device产生tick, 可以说tick决定了clock_event event_handler进而决定了, clock_event行为.&lt;br /&gt;
tickless:&lt;br /&gt;
for timer: use HW timer one shot, set next.&lt;br /&gt;
for update time: in above HW timer, not good&lt;br /&gt;
for sched: for priority distributed in time slice, use timer.&lt;br /&gt;
dynamic tick/no HZ:&lt;br /&gt;
No HZ in idle&lt;br /&gt;
No HZ while only 1 process running for HPC.&lt;br /&gt;
tick devies 就是clock event包了层虎皮.&lt;br /&gt;
tick broadcast framework:  based on tick device&lt;br /&gt;
clock: 可记录时间, 表盘.利用timekeeping&lt;br /&gt;
timer: use clock. what about timer_list?&lt;br /&gt;
timer_list: do in softirq&lt;br /&gt;
* timekeeping aspect&lt;br /&gt;
onset: start_kernel -&amp;gt; timekeeping_init &amp;amp; time_init &amp;amp;(rest_init-&amp;gt; kernel_init-&amp;gt; &lt;br /&gt;
kernel_init_freeable-&amp;gt;do_basic_setup-&amp;gt;do_initcalls&amp;ndash;device_initcall(init_clocksource_sysfs))&lt;br /&gt;
nucleus:used by clock see init_posix_timers and update_wall_time and sys_time&lt;br /&gt;
coda:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;clock source aspect&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;tick device layer aspect&lt;br /&gt;
per_cpu(tick_cpu_device, cpu)&lt;br /&gt;
onset: time_init-&amp;gt;mach-&amp;gt;init_time-&amp;gt;&amp;hellip;clockevents_register_device-&amp;gt;tick_check_new_device&lt;br /&gt;
nucleus: a38x_timer_interrupt-&amp;gt;a38x_clkevt.event_handler&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;tick broadcast framework&lt;br /&gt;
onset:&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;clock aspect&lt;br /&gt;
k_clock&lt;br /&gt;
onset:init_posix_timers &amp;amp; init_posix_cpu_timers&lt;br /&gt;
nucleus: 用户-&amp;gt; posix_clock-&amp;gt;timepkeeping-&amp;gt;clock_socurce&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;timer aspect&lt;br /&gt;
onset: open_softirq(HRTIMER_SOFTIRQ, run_hrtimer_softirq);&lt;br /&gt;
nucleus: common_timer_set&lt;br /&gt;
hrtimer_interrupt | (tick_handle_periodic-&amp;gt; tick_periodic-&amp;gt; update_process_times-&amp;gt;run_local_timers-&amp;gt;hrtimer_run_queues)-&amp;gt;__run_hrtimer-&amp;gt;timer.function = posix_timer_fn;(set in common_timer_set)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;计算机概念&lt;br /&gt;
system clock CLOCK_REALTIME CLOCK_MONOTONIC&lt;br /&gt;
time.h time_t=tm=timeval=timespec calendar time  clock_t&lt;/p&gt;

&lt;p&gt;clock event -&amp;gt; tick device-&amp;gt; handle function&lt;br /&gt;
clock event 相较于timer更为抽象, timer 是一种用途,timer 通过clock event来实现功能,&lt;br /&gt;
clock event 通过timer来体现自己, timer面向使用者的onset,&lt;br /&gt;
而clock event 则是偏向于nucleus and coda.&lt;br /&gt;
timer: 标记不能立即执行的变化.&lt;br /&gt;
clock source: 用一些整型抽象一个过程, 对于时间来说, 简直是完美的抽象.&lt;br /&gt;
* kernel requirement&lt;br /&gt;
linux的时间子系统要求硬件timer提供下面两种能力：&lt;br /&gt;
一是free running的counter，此外需要能够在指定的counter值上产生中断的能力。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Algorithms and data structues</title>
      <link>http://firoyang.org/cs/algorithm/</link>
      <pubDate>Wed, 27 May 2015 12:42:12 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/algorithm/</guid>
      <description>

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://cstheory.stackexchange.com/questions/19759/core-algorithms-deployed#&#34;&gt;Core algorithms deployed&lt;/a&gt;&lt;br /&gt;
Algorithms: Design Techniques and Analysis&lt;br /&gt;
The Algorithm Design Manual 2nd Edition&lt;/p&gt;

&lt;h1 id=&#34;leetcode&#34;&gt;Leetcode&lt;/h1&gt;

&lt;h2 id=&#34;http-joshuablog-herokuapp-com-leetcode-e6-80-bb-e7-bb-93-html-e5-a5-97-e8-b7-af&#34;&gt;&lt;a href=&#34;http://joshuablog.herokuapp.com/Leetcode-%E6%80%BB%E7%BB%93.html#%E5%A5%97%E8%B7%AF&#34;&gt;http://joshuablog.herokuapp.com/Leetcode-%E6%80%BB%E7%BB%93.html#%E5%A5%97%E8%B7%AF&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;如果问最短，最少，BFS&lt;br /&gt;
如果问连通性，静态就是 DFS,BFS，动态就 UF&lt;br /&gt;
如果问依赖性就 topo sort&lt;br /&gt;
DAG 的问题就 dfs+memo&lt;br /&gt;
矩阵和 Array 通常都是 DP&lt;br /&gt;
问数量的通常都是 DP&lt;br /&gt;
问是否可以，也很有可能 DP&lt;br /&gt;
求所有解的，基本 backtracking&lt;br /&gt;
排序总是可以想一想的&lt;br /&gt;
万事总可以想HashMap&lt;br /&gt;
找规律试试Stack&lt;/p&gt;

&lt;h2 id=&#34;漫谈leetcode解题思路-https-sophiesongge-github-io-leetcode-2017-01-19-get-random-html&#34;&gt;&lt;a href=&#34;https://sophiesongge.github.io/leetcode/2017/01/19/get-random.html&#34;&gt;漫谈LeetCode解题思路&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;1p3c&#34;&gt;1p3c&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.1point3acres.com/bbs/thread-270312-1-1.html&#34;&gt;http://www.1point3acres.com/bbs/thread-270312-1-1.html&lt;/a&gt;&lt;br /&gt;
最终我觉得像word search12， word break12，word ladder12，LIS，sort color，LRU，insert &amp;amp; delete in O1，rob house123，234sum这种题要达到闭眼秒杀的程度，min/max heap，bucket sort，topological sort，binary pre/in/post/level 遍历，combination/permutation这种东西要做梦都梦到&lt;br /&gt;
最后祝lz好运，加油~&lt;/p&gt;

&lt;h2 id=&#34;why-do-we-have-to-solve-leetcode-problems&#34;&gt;Why do we have to solve leetcode problems?&lt;/h2&gt;

&lt;p&gt;尤其是在北美，Google，Facebook，Microsoft，Amazon 等等大公司，无一不考刷题，以算法面试为主。而无论是北美留学生，还是工作几年的上班族，想进大公司，唯一的出路就是刷题。&lt;br /&gt;
&lt;a href=&#34;https://cspiration.com/leetcodeClassification&#34;&gt;Leetcode 分类顺序表第二版&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;computational-complexity-theory&#34;&gt;Computational complexity theory&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://bigocheatsheet.com/&#34;&gt;http://bigocheatsheet.com/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;core-conceptions&#34;&gt;Core conceptions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;representations&lt;br /&gt;
&lt;a href=&#34;https://www.geeksforgeeks.org/binary-tree-array-implementation/&#34;&gt;Linked vs sequential&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;ADT vs data structure&lt;br /&gt;
ADT is a data type defined by its behavior.&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Data_type#Abstract_data_types&#34;&gt;Any type that does not specify an implementation is an abstract data type.&lt;/a&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;linked-list&#34;&gt;Linked list&lt;/h1&gt;

&lt;h2 id=&#34;static-linked-list&#34;&gt;Static linked list&lt;/h2&gt;

&lt;p&gt;Reprented in an array.&lt;/p&gt;

&lt;h2 id=&#34;internal-vs-external-liked&#34;&gt;Internal vs external liked&lt;/h2&gt;

&lt;p&gt;Sometimes, SLUB put freelist in object&lt;/p&gt;

&lt;h2 id=&#34;kernel-doubly-linked-list-operations&#34;&gt;kernel doubly linked list operations&lt;/h2&gt;

&lt;h3 id=&#34;add&#34;&gt;add&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;kernel version&lt;br /&gt;
next-&amp;gt;prev = new;&lt;br /&gt;
new-&amp;gt;next = next;&lt;br /&gt;
new-&amp;gt;prev = prev;&lt;br /&gt;
prev-&amp;gt;next = new;&lt;/p&gt;

&lt;h3 id=&#34;delete&#34;&gt;delete&lt;/h3&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kernel version&lt;br /&gt;
next-&amp;gt;prev = prev;&lt;br /&gt;
WRITE_ONCE(prev-&amp;gt;next, next);&lt;br /&gt;
entry-&amp;gt;next = LIST_POISON1;&lt;br /&gt;
entry-&amp;gt;prev = LIST_POISON2;&lt;/p&gt;

&lt;h1 id=&#34;bl-list&#34;&gt;BL list&lt;/h1&gt;

&lt;p&gt;kernel: add bl_list - 4e35e6070b1ceed89c3bba2af4216c286fb1dafd&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;double-linked-list&#34;&gt;Double linked list&lt;/h1&gt;

&lt;h1 id=&#34;associative-array&#34;&gt;Associative array&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=qTZJLJ3Gm6Q&#34;&gt;Essentials: Brian Kernighan on Associative Arrays - Computerphile&lt;/a&gt;&lt;br /&gt;
vs indexed array&lt;/p&gt;

&lt;h2 id=&#34;associativity&#34;&gt;Associativity&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;trade-off&lt;br /&gt;
a) Checking more places takes more power and chip area,&lt;br /&gt;
b) and potentially more time. On the other hand, caches with more associativity suffer fewer misses&lt;br /&gt;
fully associative - the best miss rates, but practical only for a small number of entries&lt;br /&gt;
N-way set associative cache: 8 is a common choice for later implementations&lt;br /&gt;
direct-mapped cache - if two locations map to the same entry, they may continually knock each other out. anti-fragmantion worsens this case.&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;judy-array&#34;&gt;Judy array&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://judy.sourceforge.net/&#34;&gt;http://judy.sourceforge.net/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;hashtable&#34;&gt;Hashtable&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/510202/&#34;&gt;A generic hash table&lt;/a&gt;&lt;br /&gt;
hash function&lt;/p&gt;

&lt;h1 id=&#34;bst&#34;&gt;BST&lt;/h1&gt;

&lt;p&gt;Pre-order&lt;br /&gt;
In-order traversal&lt;br /&gt;
Post-order&lt;br /&gt;
postfix and prefix and sort&lt;/p&gt;

&lt;h1 id=&#34;graph&#34;&gt;Graph&lt;/h1&gt;

&lt;h1 id=&#34;depth-first-sarch&#34;&gt;Depth first sarch&lt;/h1&gt;

&lt;p&gt;DAG&lt;/p&gt;

&lt;h1 id=&#34;interval-tree-in-kernel&#34;&gt;Interval tree in kernel&lt;/h1&gt;

&lt;p&gt;anonymous page: anon_vma_interval_tree_insert&lt;/p&gt;

&lt;h1 id=&#34;trie&#34;&gt;Trie&lt;/h1&gt;

&lt;p&gt;Trie is prefix tree.&lt;br /&gt;
Trees only store keys.&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=AXjmTQ8LEoI&#34;&gt;Trie Data Structure&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=MC-iQHFdEDI&#34;&gt;Trie with numeric key&lt;/a&gt;&lt;br /&gt;
* terms very confused&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/14708134/what-is-the-difference-between-trie-and-radix-trie-data-structures&#34;&gt;Radix tree vs Trie, check radix meaning&lt;/a&gt;&lt;br /&gt;
Patricia is compact trie or Patricia is radix = 2 trie?&lt;/p&gt;

&lt;h1 id=&#34;radix-tree-in-kernel-not-wikipedia&#34;&gt;Radix tree in kernel not wikipedia&lt;/h1&gt;

&lt;p&gt;page cache: page_cache_tree_insert&lt;br /&gt;
Wikipedia: Radix tree looks like a compact trie.&lt;br /&gt;
Kernel: Radix tree was more like a Multi-level index associative arrya or judy array.&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/175432/&#34;&gt;Trees I: Radix trees&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://events17.linuxfoundation.org/sites/events/files/slides/LinuxConNA2016%20-%20Radix%20Tree.pdf&#34;&gt;Enhancing the Linux Radix Tree&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=v0C9_Fp-co4&#34;&gt;The design and implementation of the XArray&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/688130/&#34;&gt;A multi-order radix tree&lt;/a&gt;&lt;br /&gt;
radix_tree_init_maxnodes(): height is 11 in kernel?&lt;br /&gt;
&lt;strong&gt;radix_tree_create() add one page&lt;/strong&gt;&lt;br /&gt;
radix_tree_lookup_slot: find one page&lt;/p&gt;

&lt;h1 id=&#34;search&#34;&gt;Search&lt;/h1&gt;

&lt;p&gt;Data property: unique key, indexed&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Search_data_structure&#34;&gt;Search data structure&lt;/a&gt;&lt;br /&gt;
Sequencial array: binary search&lt;br /&gt;
Associative array&lt;br /&gt;
BST&lt;br /&gt;
Hashtable&lt;/p&gt;

&lt;h2 id=&#34;which-algorithm&#34;&gt;Which algorithm?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.geeksforgeeks.org/advantages-of-bst-over-hash-table/&#34;&gt;Advantages of BST over Hash Table&lt;/a&gt;&lt;br /&gt;
1. Can get all keys in sorted order  by just doing in-order traversal of BST&lt;br /&gt;
2. Doing order statistics, finding closest lower and greater elements, doing range  queries  are easy to do with BSTs.&lt;br /&gt;
3. BSTs are easy to implement compared to hashing.&lt;br /&gt;
4. With Self Balancing BSTs, all operations are guarnateed to work in O(logN) time.&lt;/p&gt;

&lt;h1 id=&#34;replacement-polices&#34;&gt;Replacement polices&lt;/h1&gt;

&lt;p&gt;Pseudo-LRU&lt;/p&gt;

&lt;h1 id=&#34;lru&#34;&gt;LRU&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://leetcode.com/problems/lru-cache/description/&#34;&gt;Leetcode 146 LRU cache&lt;/a&gt;&lt;br /&gt;
Order items by access times&lt;/p&gt;

&lt;h2 id=&#34;pseudo-lru-2-second-chance-and-queue&#34;&gt;Pseudo LRU/2 - Second chance and queue&lt;/h2&gt;

&lt;p&gt;type: Reclaim&lt;br /&gt;
Order items by enqueueing sequence&lt;br /&gt;
dcache&lt;/p&gt;

&lt;h2 id=&#34;second-chance-and-2q-https-pdfs-semanticscholar-org-d62d-e5f995164fff50f5ce61c0113f6bc9f04225-pdf&#34;&gt;Second chance and &lt;a href=&#34;https://pdfs.semanticscholar.org/d62d/e5f995164fff50f5ce61c0113f6bc9f04225.pdf&#34;&gt;2Q&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Page reclaim algorithm&lt;br /&gt;
type: Reclaim&lt;/p&gt;

&lt;h1 id=&#34;ring-buffer-or-circular-buffer&#34;&gt;Ring buffer or Circular buffer&lt;/h1&gt;

&lt;h1 id=&#34;redblack-tree&#34;&gt;Redblack tree&lt;/h1&gt;

&lt;p&gt;gap between linar node can be optimized by argument rb tree. O(n) -&amp;gt; O(log n)&lt;br /&gt;
mm: augment vma rbtree with rb_subtree_gap d37371870ceb1d2165397dc36114725b6dca946c&lt;br /&gt;
&lt;a href=&#34;http://sidsen.azurewebsites.net//papers/rb-trees-talg.pdf&#34;&gt;Rank-Balanced Trees&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://leetcode.com/problems/count-of-smaller-numbers-after-self/description/&#34;&gt;https://leetcode.com/problems/count-of-smaller-numbers-after-self/description/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://yuex.in/post/2017/08/red-black-tree-in-action.html&#34;&gt;http://yuex.in/post/2017/08/red-black-tree-in-action.html&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cs.princeton.edu/~rs/talks/LLRB/08Dagstuhl/RedBlack.pdf&#34;&gt;Left-Leaning Red-Black Trees&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;history&#34;&gt;History&lt;/h2&gt;

&lt;p&gt;AVL tree, B-tree, symmetric binary B-tree or 2–3–4 tree, red–black tree&lt;br /&gt;
&lt;a href=&#34;https://www.cs.purdue.edu/homes/ayg/CS251/slides/chap13b.pdf&#34;&gt;2-3-4 Trees and RedBlack Trees&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Journey to RCU</title>
      <link>http://firoyang.org/cs/rcu/</link>
      <pubDate>Sun, 24 May 2015 09:52:12 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/rcu/</guid>
      <description>

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cnhalo.net/2016/06/13/linux-rcu/&#34;&gt;http://www.cnhalo.net/2016/06/13/linux-rcu/&lt;/a&gt; linux 4.9内核rcu实现&lt;/p&gt;

&lt;h1 id=&#34;network-rx-path&#34;&gt;Network RX  path&lt;/h1&gt;

&lt;p&gt;commit 2d331915a04144dad738e725769d8fac06ef6155&lt;br /&gt;
Author: Eric Dumazet &lt;a href=&#34;mailto:edumazet@google.com&#34;&gt;edumazet@google.com&lt;/a&gt;&lt;br /&gt;
Date:   Fri Apr 1 08:52:15 2016 -0700&lt;br /&gt;
    tcp/dccp: use rcu locking in inet_diag_find_one_icsk()&lt;br /&gt;
    RX packet processing holds rcu_read_lock(), so we can remove&lt;br /&gt;
    pairs of rcu_read_lock()/rcu_read_unlock() in lookup functions&lt;br /&gt;
    if inet_diag also holds rcu before calling them.&lt;br /&gt;
    This is needed anyway as __inet_lookup_listener() and&lt;br /&gt;
    inet6_lookup_listener() will soon no longer increment&lt;br /&gt;
    refcount on the found listener.&lt;br /&gt;
    Signed-off-by: Eric Dumazet &lt;a href=&#34;mailto:edumazet@google.com&#34;&gt;edumazet@google.com&lt;/a&gt;&lt;br /&gt;
    Signed-off-by: David S. Miller &lt;a href=&#34;mailto:davem@davemloft.net&#34;&gt;davem@davemloft.net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;5142 static int process_backlog(struct napi_struct *napi, int quota)&lt;br /&gt;
&amp;hellip;&lt;br /&gt;
5160                 while ((skb = __skb_dequeue(&amp;amp;sd-&amp;gt;process_queue))) {&lt;br /&gt;
5161                         rcu_read_lock();&lt;br /&gt;
5162                         __netif_receive_skb(skb);&lt;br /&gt;
5163                         rcu_read_unlock();&lt;br /&gt;
Refs: v4.1-12249-g2c17d27c36dc&lt;br /&gt;
Author:     Julian Anastasov &lt;a href=&#34;mailto:ja@ssi.bg&#34;&gt;ja@ssi.bg&lt;/a&gt;&lt;br /&gt;
AuthorDate: Thu Jul 9 09:59:10 2015 +0300&lt;br /&gt;
Commit:     David S. Miller &lt;a href=&#34;mailto:davem@davemloft.net&#34;&gt;davem@davemloft.net&lt;/a&gt;&lt;br /&gt;
CommitDate: Fri Jul 10 18:16:36 2015 -0700&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;net: call rcu_read_lock early in process_backlog

Incoming packet should be either in backlog queue or
in RCU read-side section. Otherwise, the final sequence of
flush_backlog() and synchronize_net() may miss packets
that can run without device reference:

CPU 1                  CPU 2
                       skb-&amp;gt;dev: no reference
                       process_backlog:__skb_dequeue
                       process_backlog:local_irq_enable

on_each_cpu for
flush_backlog =&amp;gt;       IPI(hardirq): flush_backlog
                       - packet not found in backlog

                       CPU delayed ...
synchronize_net
- no ongoing RCU
read-side sections

netdev_run_todo,
rcu_barrier: no
ongoing callbacks
                       __netif_receive_skb_core:rcu_read_lock
                       - too late
free dev
                       process packet for freed dev

Fixes: 6e583ce5242f (&amp;quot;net: eliminate refcounting in backlog queue&amp;quot;)
Cc: Eric W. Biederman &amp;lt;ebiederm@xmission.com&amp;gt;
Cc: Stephen Hemminger &amp;lt;stephen@networkplumber.org&amp;gt;
Signed-off-by: Julian Anastasov &amp;lt;ja@ssi.bg&amp;gt;
Signed-off-by: David S. Miller &amp;lt;davem@davemloft.net&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;history&#34;&gt;History&lt;/h1&gt;

&lt;h2 id=&#34;2001-read-copy-update-on-ols-https-www-kernel-org-doc-ols-2001-read-copy-pdf&#34;&gt;2001 &lt;a href=&#34;https://www.kernel.org/doc/ols/2001/read-copy.pdf&#34;&gt;Read-Copy Update on ols&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/541037/&#34;&gt;As of March 2013: Simplifying RCU&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www2.rdrop.com/users/paulmck/RCU/RCUdissertation.2004.07.14e1.pdf&#34;&gt;RCU dissertation.2004.07&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2008&#34;&gt;2008&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/264090/&#34;&gt;RCU part 3: the RCU API, 2008 edition&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2010&#34;&gt;2010&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/418853/&#34;&gt;The RCU API, 2010 Edition&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2014&#34;&gt;2014&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/609904/&#34;&gt;The RCU API, 2014 Edition&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;2019&#34;&gt;2019&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/777036/&#34;&gt;The RCU API, 2019 edition&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;formal-cause&#34;&gt;Formal cause&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/RCU/Design/Requirements/Requirements.html&#34;&gt;A Tour Through RCU&amp;rsquo;s Requirements&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.rdrop.com/~paulmck/RCU/rcu-exploit.2019.05.01a.pdf&#34;&gt;A Critical RCU Safety Property is&amp;hellip; Ease of Use!&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.rdrop.com/users/paulmck/RCU/whatisRCU.html&#34;&gt;What is RCU?&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/RCU/whatisRCU.txt&#34;&gt;What is RCU?  &amp;ndash;  &amp;ldquo;Read, Copy, Update&amp;rdquo;&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/652156/&#34;&gt;Requirements for RCU part 1: the fundamentals&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.joelfernandes.org/joel/slides/RCU_in_2019_KernelRecipes.pdf&#34;&gt;RCU in 2019&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=bsyXDAouI6E&#34;&gt;Kernel Recipes 2019 - RCU in 2019&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;rcu-and-dynticks&#34;&gt;RCU and dynticks&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://ertl.jp/~shinpei/conf/ospert13/slides/FredericWeisbecker.pdf&#34;&gt;Status of Linux dynticks&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=G3jHP9kNjwc&#34;&gt;Full dynticks status - Frederic Weisbecker, Red Hat&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;grace-period&#34;&gt;Grace period&lt;/h2&gt;

&lt;p&gt;Documentation/RCU/rcu.txt&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/573424/&#34;&gt;URCU: any period of time during which each reader thread resides in at least one quiescent state is called a grace period.&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/305782/#Start%20a%20new%20grace%20period.&#34;&gt;Start a New Grace Period&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/305782/#Brief%20Overview%20of%20Classic%20RCU%20Implementation&#34;&gt;&amp;hellip; after each CPU has passed through at least one quiescent state, the RCU grace period ends.&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/RCU/Design/Expedited-Grace-Periods/Expedited-Grace-Periods.html&#34;&gt;Must-read: Expedited Grace Period Design&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;quiescent-state&#34;&gt;Quiescent state&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://lse.sourceforge.net/locking/rcu/HOWTO/descrip.html&#34;&gt;&amp;hellip; after all the CPUs in the system have gone through at least one &amp;ldquo;quiescent&amp;rdquo; state (such as context switch, idle loop, or user code)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/573424/&#34;&gt;URCU: Any line of code not in an RCU read-side critical section is termed a quiescent state&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/305782/#Pass%20through%20a%20quiescent%20state.&#34;&gt;The rcu and rcu_bh flavors of RCU have different sets of quiescent states.&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://preshing.com/20160726/using-quiescent-states-to-reclaim-memory/&#34;&gt;Using Quiescent States to Reclaim Memory&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;granularity-of-waiting&#34;&gt;granularity of waiting&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/262464/#Wait%20For%20Pre-Existing%20RCU%20Readers%20to%20Complete&#34;&gt;The great advantage of RCU &amp;hellip; without having to explicitly track each and every one of them&lt;/a&gt;&lt;br /&gt;
In RCU&amp;rsquo;s case, the things waited on are called &amp;ldquo;RCU read-side critical sections&amp;rdquo;. ditto.&lt;/p&gt;

&lt;h1 id=&#34;classic-rcu&#34;&gt;Classic RCU&lt;/h1&gt;

&lt;p&gt;commit c17ef45342cc033fdf7bdd5b28615e0090f8d2e7&lt;br /&gt;
Author: Paul E. McKenney &lt;a href=&#34;mailto:paulmck@linux.vnet.ibm.com&#34;&gt;paulmck@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
Date:   Tue Jun 23 17:12:47 2009 -0700&lt;br /&gt;
    rcu: Remove Classic RCU&lt;br /&gt;
    Remove Classic RCU, given that the combination of Tree RCU and&lt;br /&gt;
    the proposed Bloatwatch RCU do everything that Classic RCU can&lt;br /&gt;
    with fewer bugs.&lt;br /&gt;
tags/v2.6.32-rc1~724^2~29&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/305782/#Brief%20Overview%20of%20Classic%20RCU%20Implementation&#34;&gt;Brief Overview of Classic RCU Implementation&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.wowotech.net/kernel_synchronization/linux2-6-11-RCU.html&#34;&gt;Linux2.6.11版本：classic RCU的实现&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;rcu-sched&#34;&gt;RCU sched&lt;/h1&gt;

&lt;p&gt;commit 9b06e818985d139fd9e82c28297f7744e1b484e1&lt;br /&gt;
Refs: v2.6.12-rc3-362-g9b06e818985d&lt;br /&gt;
Author:     Paul E. McKenney &lt;a href=&#34;mailto:paulmck@us.ibm.com&#34;&gt;paulmck@us.ibm.com&lt;/a&gt;&lt;br /&gt;
AuthorDate: Sun May 1 08:59:04 2005 -0700&lt;br /&gt;
Commit:     Linus Torvalds &lt;a href=&#34;mailto:torvalds@ppc970.osdl.org&#34;&gt;torvalds@ppc970.osdl.org&lt;/a&gt;&lt;br /&gt;
CommitDate: Sun May 1 08:59:04 2005 -0700&lt;br /&gt;
    [PATCH] Deprecate synchronize_kernel, GPL replacement&lt;br /&gt;
    The synchronize_kernel() primitive is used for quite a few different purposes:&lt;br /&gt;
    waiting for RCU readers, waiting for NMIs, waiting for interrupts, and so on.&lt;br /&gt;
    This makes RCU code harder to read, since synchronize_kernel() might or might&lt;br /&gt;
    not have matching rcu_read_lock()s.  This patch creates a new&lt;br /&gt;
    synchronize_rcu() that is to be used for RCU readers and a new&lt;br /&gt;
    synchronize_sched() that is used for the rest.  These two new primitives&lt;br /&gt;
    currently have the same implementation, but this is might well change with&lt;br /&gt;
    additional real-time support.&lt;br /&gt;
+ * synchronize_sched - block until all CPUs have exited any non-preemptive&lt;br /&gt;
+ * kernel code sequences.&lt;br /&gt;
+ * This means that all preempt_disable code sequences, including NMI and&lt;br /&gt;
+ * hardware-interrupt handlers, in progress on entry will have completed&lt;br /&gt;
+ * before this primitive returns.  However, this does not guarantee that&lt;br /&gt;
+ * softirq handlers will have completed, since in some kernels&lt;br /&gt;
+ * This primitive provides the guarantees made by the (deprecated)&lt;br /&gt;
+ * synchronize_kernel() API.  In contrast, synchronize_rcu() only&lt;br /&gt;
+ * guarantees that rcu_read_lock() sections will have completed.&lt;/p&gt;

&lt;h2 id=&#34;rcu-is-mapped-to-either-rcu-sched-or-rcu-preempt-depending-on-configuration&#34;&gt;RCU is mapped to either RCU-sched or RCU-preempt depending on configuration.&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lore.kernel.org/patchwork/cover/164913/&#34;&gt;[RFC,-tip,0/4] RCU cleanups and simplified preemptable RCU&lt;/a&gt;&lt;br /&gt;
o   Rename variables and functions so that RCU-sched is an&lt;br /&gt;
    underlying definition, along with RCU-bh and (when so&lt;br /&gt;
    configured) RCU-preempt.  RCU then maps to either RCU-sched&lt;br /&gt;
    or RCU-preempt, depending on configuration.&lt;br /&gt;
commit d6714c22b43fbcbead7e7b706ff270e15f04a791&lt;br /&gt;
Refs: v2.6.31-rc6-15-gd6714c22b43f&lt;br /&gt;
Author:     Paul E. McKenney &lt;a href=&#34;mailto:paulmck@linux.vnet.ibm.com&#34;&gt;paulmck@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
AuthorDate: Sat Aug 22 13:56:46 2009 -0700&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
CommitDate: Sun Aug 23 10:32:37 2009 +0200&lt;br /&gt;
    rcu: Renamings to increase RCU clarity&lt;br /&gt;
    Make RCU-sched, RCU-bh, and RCU-preempt be underlying&lt;br /&gt;
    implementations, with &amp;ldquo;RCU&amp;rdquo; defined in terms of one of the&lt;br /&gt;
    three.  Update the outdated rcu_qsctr_inc() names, as these&lt;br /&gt;
    functions no longer increment anything.&lt;/p&gt;

&lt;h2 id=&#34;quiescent-states-for-rcu-sched&#34;&gt;Quiescent states for RCU-sched&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.kroening.com/papers/date2018-rcu.pdf&#34;&gt;Verification of Tree-Based Hierarchical Read-Copy Update in the Linux Kernel&lt;/a&gt;&lt;br /&gt;
The non-preemptible RCU-sched flavor’s quiescent states&lt;br /&gt;
apply to CPUs, and are user-space execution, context switch,&lt;br /&gt;
idle, and offline state. Therefore, RCU-sched only needs to&lt;br /&gt;
track tasks and interrupt handlers that are actually running&lt;br /&gt;
because blocked and preempted tasks are always in quiescent states. Thus, RCU-sched needs only track CPU states.&lt;/p&gt;

&lt;h2 id=&#34;rcu-stalls&#34;&gt;RCU stalls&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=23_GOr8Sz-E&#34;&gt;Decoding Those Inscrutable RCU CPU Stall Warnings&lt;/a&gt;&lt;br /&gt;
update_process_times-&amp;gt;rcu_check_callbacks-&amp;gt;rcu_pending-&amp;gt;__rcu_pending-&amp;gt;check_cpu_stall-&amp;gt;print_other_cpu_stall&lt;br /&gt;
Documentation/RCU/stallwarn.txt&lt;/p&gt;

&lt;h1 id=&#34;rcu-preempt-preemptiable-rcu&#34;&gt;RCU-preempt Preemptiable RCU&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.joelfernandes.org/linuxinternals/2018/05/10/5-rcu-preempt-context-switch.html&#34;&gt;Must-read: RCU-preempt: What happens on a context switch&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.rdrop.com/users/paulmck/RCU/realtimeRCU.2005.04.23a.pdf&#34;&gt;Towards Hard Realtime Response from the Linux Kernel on SMP Hardware&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/201195/&#34;&gt;The 1st: Read-copy-update for realtime&lt;/a&gt; &lt;a href=&#34;http://www.rdrop.com/users/paulmck/RCU/OLSrtRCU.2006.08.11a.pdf&#34;&gt;Papper&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/253651/&#34;&gt;The design of preemptible read-copy-update&lt;/a&gt;&lt;br /&gt;
The RCU implementation for the -rt patchset is unusual in that it permits read-side critical sections to be preempted and to be blocked waiting for locks. However, it does not handle general blocking (for example, via the wait_event() primitive): if you need that, you should instead use SRCU.&lt;br /&gt;
&lt;a href=&#34;http://www.rdrop.com/users/paulmck/RCU/realtimeRCU.2005.04.23a.pdf&#34;&gt;Realtime RCU&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.joelfernandes.org/linuxinternals/2018/05/10/5-rcu-preempt-context-switch.html&#34;&gt;RCU-preempt: What happens on a context switch&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;

&lt;p&gt;+#define RCU_READ_UNLOCK_NEED_QS (1 &amp;lt;&amp;lt; 2) /* RCU core needs CPU response. */&lt;br /&gt;
f41d911f8c49a5d65c86504c19e8204bb605c4fd&lt;br /&gt;
need_qs&lt;br /&gt;
1d082fd061884a587c490c4fc8a2056ce1e47624&lt;/p&gt;

&lt;h2 id=&#34;rcu-preempt-and-sleeping&#34;&gt;RCU-preempt and sleeping&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.joelfernandes.org/linuxinternals/2018/05/10/5-rcu-preempt-context-switch.html&#34;&gt;A recent discussion on LKML clarified to me that “preempted to run something else” not only covers involuntary preemption but also voluntarily sleeping.&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;joelfernandes.org/linuxinternals/2018/05/10/5-rcu-preempt-context-switch.html&#34;&gt;The exception is -rt &amp;ldquo;spinlock&amp;rdquo; acquisition.  If the &amp;ldquo;spinlock&amp;rdquo; is held,&lt;/a&gt;&lt;br /&gt;
the task acquiring it will block, which is legal within an RCU-preempt&lt;br /&gt;
read-side critical section.&lt;br /&gt;
This exception is why I define bad things in terms of lack of&lt;br /&gt;
susceptibility to priority boosting instead of sleeping.&lt;/p&gt;

&lt;h2 id=&#34;priority-boosting-rcu&#34;&gt;Priority-Boosting RCU&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/220677/&#34;&gt;Priority-Boosting RCU Read-Side Critical Sections&lt;/a&gt;&lt;br /&gt;
CONFIG_RCU_BOOST&lt;/p&gt;

&lt;h2 id=&#34;the-motivation-for-that-cpu-reports-qs&#34;&gt;The motivation for that CPU reports QS&lt;/h2&gt;

&lt;p&gt;@冯博群 你好，请教一个问题，对于rcu-preempt， CPU report QS的意义是什么？ 我理解只有task QS 才不block GP。&lt;br /&gt;
冯博群: qs都是CPU的，每个task都要report qs的话，那记录的结构得多复杂; rcu preempt是搞了一个list用来记录block当前qs的task; 当前gp; 过gp的条件就是list为空，且所有的CPU都report过qs;你说得概念上没啥问题，但是实现中不是这样作的.&lt;/p&gt;

&lt;h1 id=&#34;rcu-bh&#34;&gt;RCU bh&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/ml/linux-kernel/CAJWu+oqCun1Ae6GqPxnS+eCDi3jadGPp+MO8TjOWgs+AiAh79A@mail.gmail.com/&#34;&gt;Questions on rcu-bh design&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;motivation-for-rcu-bh-and-vs-rcu-preempt-https-www-mail-archive-com-linux-kernel-vger-kernel-org-msg1682346-html&#34;&gt;&lt;a href=&#34;https://www.mail-archive.com/linux-kernel@vger.kernel.org/msg1682346.html&#34;&gt;Motivation for RCU-bh and vs RCU-preempt&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/RCU/Design/Requirements/Requirements.html#Bottom-Half%20Flavor&#34;&gt;From kernel doc rcu design&lt;/a&gt;&lt;br /&gt;
The softirq-disable (AKA “bottom-half”, hence the “_bh” abbreviations) flavor of RCU, or RCU-bh, was developed by Dipankar Sarma to provide a flavor of RCU that could withstand the network-based denial-of-service attacks researched by Robert Olsson. These attacks placed so much networking load on the system that some of the CPUs never exited softirq execution, which in turn prevented those CPUs from ever executing a context switch, which, in the RCU implementation of that time, prevented grace periods from ever ending. The result was an out-of-memory condition and a system hang.&lt;br /&gt;
The solution was the creation of RCU-bh, which does local_bh_disable() across its read-side critical sections, and which uses &lt;em&gt;the transition from one type of softirq processing to another as a quiescent state in addition to context switch, idle, user mode, and offline&lt;/em&gt;. This means that RCU-bh grace periods can complete even when some of the CPUs execute in softirq indefinitely, thus allowing algorithms based on RCU-bh to withstand network-based denial-of-service attacks.&lt;/p&gt;

&lt;h1 id=&#34;srcu&#34;&gt;SRCU&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/202847/&#34;&gt;Sleepable RCU&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;tasks-rcu&#34;&gt;Tasks RCU&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/607117/&#34;&gt;The RCU-tasks subsystem&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;tiny-rcu-rcu-the-bloatwatch-edition&#34;&gt;Tiny RCU / RCU: The Bloatwatch Edition&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/323929/&#34;&gt;RCU: The Bloatwatch Edition&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/396767/&#34;&gt;rcu: Add a TINY_PREEMPT_RCU&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lore.kernel.org/patchwork/patch/373048/&#34;&gt;rcu: Remove TINY_PREEMPT_RCU&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;tree-rcu-hierarchical-rcu&#34;&gt;Tree RCU / Hierarchical RCU&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.kroening.com/papers/date2018-rcu.pdf&#34;&gt;Verification of Tree-Based Hierarchical Read-Copy Update in the Linux Kernel&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/305782&#34;&gt;Hierarchical RCU&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/RCU/Design/Memory-Ordering/Tree-RCU-Memory-Ordering.html&#34;&gt;Tree RCU Grace Period Memory Ordering Components &lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/RCU/Design/Data-Structures/Data-Structures.html&#34;&gt;A Tour Through TREE_RCU&amp;rsquo;s Data Structures&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/RCU/Design/Expedited-Grace-Periods/Expedited-Grace-Periods.html&#34;&gt;A Tour Through TREE_RCU&amp;rsquo;s Expedited Grace Periods&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/453002/&#34;&gt;Tree preempt RCU: 3.0 and RCU: what went wrong&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;list-and-rcu&#34;&gt;list and rcu&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/610972/&#34;&gt;Using RCU for linked lists — a case study&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/RCU/listRCU.rst&#34;&gt;Using RCU to Protect Read-Mostly Linked Lists&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;hlist-nulls&#34;&gt;hlist-nulls&lt;/h2&gt;

&lt;p&gt;commit bbaffaca4810de1a25e32ecaf836eeaacc7a3d11&lt;br /&gt;
Refs: v2.6.28-rc4-513-gbbaffaca4810&lt;br /&gt;
Author:     Eric Dumazet &lt;a href=&#34;mailto:dada1@cosmosbay.com&#34;&gt;dada1@cosmosbay.com&lt;/a&gt;&lt;br /&gt;
AuthorDate: Sun Nov 16 19:37:55 2008 -0800&lt;br /&gt;
Commit:     David S. Miller &lt;a href=&#34;mailto:davem@davemloft.net&#34;&gt;davem@davemloft.net&lt;/a&gt;&lt;br /&gt;
CommitDate: Sun Nov 16 19:37:55 2008 -0800&lt;br /&gt;
    rcu: Introduce hlist_nulls variant of hlist&lt;br /&gt;
    hlist uses NULL value to finish a chain.&lt;br /&gt;
    hlist_nulls variant use the low order bit set to 1 to signal an end-of-list marker.&lt;br /&gt;
    This allows to store many different end markers, so that some RCU lockless&lt;br /&gt;
    algos (used in TCP/UDP stack for example) can save some memory barriers in&lt;br /&gt;
    fast paths.&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/RCU/rculist_nulls.txt&#34;&gt;Usage of hilsit-nulls in kernel doc&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;slab-and-rcu&#34;&gt;slab and rcu&lt;/h1&gt;

&lt;p&gt;tglx: commit 77631565ae40a44f23eac2e9c440cbceed8962a7&lt;br /&gt;
Author:     Hugh Dickins &lt;a href=&#34;mailto:hugh@veritas.com&#34;&gt;hugh@veritas.com&lt;/a&gt;&lt;br /&gt;
AuthorDate: Mon Aug 23 21:24:22 2004 -0700&lt;br /&gt;
Commit:     Linus Torvalds &lt;a href=&#34;mailto:torvalds@ppc970.osdl.org&#34;&gt;torvalds@ppc970.osdl.org&lt;/a&gt;&lt;br /&gt;
CommitDate: Mon Aug 23 21:24:22 2004 -0700&lt;br /&gt;
    [PATCH] rmaplock: SLAB_DESTROY_BY_RCU&lt;/p&gt;

&lt;p&gt;commit d7de4c1dc3a2faca0bf05d9e342f885cb2696766&lt;br /&gt;
Refs: v2.6.28-rc4-307-gd7de4c1dc3a2&lt;br /&gt;
Author:     Peter Zijlstra &lt;a href=&#34;mailto:a.p.zijlstra@chello.nl&#34;&gt;a.p.zijlstra@chello.nl&lt;/a&gt;&lt;br /&gt;
AuthorDate: Thu Nov 13 20:40:12 2008 +0200&lt;br /&gt;
Commit:     Pekka Enberg &lt;a href=&#34;mailto:penberg@cs.helsinki.fi&#34;&gt;penberg@cs.helsinki.fi&lt;/a&gt;&lt;br /&gt;
CommitDate: Thu Nov 13 20:49:02 2008 +0200&lt;br /&gt;
    slab: document SLAB_DESTROY_BY_RCU&lt;br /&gt;
    Explain this SLAB_DESTROY_BY_RCU thing..&lt;/p&gt;

&lt;h2 id=&#34;slab-typesafe-by-rcu&#34;&gt;SLAB_TYPESAFE_BY_RCU&lt;/h2&gt;

&lt;p&gt;commit 5f0d5a3ae7cff0d7fa943c199c3a2e44f23e1fac&lt;br /&gt;
Refs: v4.11-rc2-1-g5f0d5a3ae7cf&lt;br /&gt;
Author:     Paul E. McKenney &lt;a href=&#34;mailto:paulmck@linux.vnet.ibm.com&#34;&gt;paulmck@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
AuthorDate: Wed Jan 18 02:53:44 2017 -0800&lt;br /&gt;
Commit:     Paul E. McKenney &lt;a href=&#34;mailto:paulmck@linux.vnet.ibm.com&#34;&gt;paulmck@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
CommitDate: Tue Apr 18 11:42:36 2017 -0700&lt;br /&gt;
    mm: Rename SLAB_DESTROY_BY_RCU to SLAB_TYPESAFE_BY_RCU&lt;br /&gt;
    A group of Linux kernel hackers reported chasing a bug that resulted&lt;br /&gt;
    from their assumption that SLAB_DESTROY_BY_RCU provided an existence&lt;br /&gt;
    guarantee, that is, that no block from such a slab would be reallocated&lt;br /&gt;
    during an RCU read-side critical section.  Of course, that is not the&lt;br /&gt;
    case.  Instead, SLAB_DESTROY_BY_RCU only prevents freeing of an entire&lt;br /&gt;
    slab of blocks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Yet another guide on the way to linux kernel hacking</title>
      <link>http://firoyang.org/cs/kernel_hacking/</link>
      <pubDate>Sat, 25 Apr 2015 00:00:00 UTC</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/kernel_hacking/</guid>
      <description>

&lt;h1 id=&#34;hacking-goals&#34;&gt;Hacking goals&lt;/h1&gt;

&lt;h2 id=&#34;trade-time-for-space&#34;&gt;Trade time for space&lt;/h2&gt;

&lt;p&gt;search_exception_tables&lt;/p&gt;

&lt;h1 id=&#34;define-asm-extable-handle-from-to-handler&#34;&gt;define _ASM_EXTABLE_HANDLE(from, to, handler)                 &lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;    .pushsection &amp;quot;__ex_table&amp;quot;,&amp;quot;a&amp;quot; ;                         \
    .balign 4 ;                                             \
    .long (from) - . ;                                      \
    .long (to) - . ;                                        \
    .long (handler) - . ;                                   \
    .popsection
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;hacking-area&#34;&gt;Hacking area&lt;/h1&gt;

&lt;p&gt;mm&lt;br /&gt;
&lt;a href=&#34;https://kernsec.org/wiki/index.php/Kernel_Self_Protection_Project&#34;&gt;https://kernsec.org/wiki/index.php/Kernel_Self_Protection_Project&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/749064/&#34;&gt;Variable-length arrays and the max() mess&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=wlqjQe3vDx8&amp;amp;list=PLbzoR-pLrL6rOT6m50HdJFYUHyvA9lurI&amp;amp;index=11&amp;amp;t=0s&#34;&gt;Sub-system Update: Kernel Self-Protection Project - Kees Cook, Google&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;kernel-refactoring&#34;&gt;Kernel refactoring&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://linuxtv.org/wiki/index.php/Development:_Hints_for_Refactoring_Existing_Drivers&#34;&gt;https://linuxtv.org/wiki/index.php/Development:_Hints_for_Refactoring_Existing_Drivers&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=mxxicJZ8cis&#34;&gt;Kernel Recipes 2017 - Refactoring the Linux Kernel - Thomas Gleixner&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;feature&#34;&gt;Feature&lt;/h2&gt;

&lt;p&gt;some results or progress information for PFRA&lt;/p&gt;

&lt;h2 id=&#34;write-your-own-kernel&#34;&gt;Write your own kernel&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://os.phil-opp.com/&#34;&gt;Writing an OS in Rust&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.brokenthorn.com/Resources/OSDevIndex.html&#34;&gt;BrokenThorn Entertainment Operating System Development Series&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;build&#34;&gt;Build&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;if no .config, every config tools make a .config from scrach!&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;oldconfig just for new moduels patch merged in trunk. This no any relations to .config.old and /boot/config.x.y.z&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;make localmodconfig will reduce many unused kernel config.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;make bzImage  #kmods will not build that configured with M!&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;make modules_install INSTALL_MOD_PATH=/home/firo/kmods&lt;br /&gt;
##build signle kernel module&lt;br /&gt;
make menuconfig&lt;br /&gt;
make oldconfig &amp;amp;&amp;amp; make prepare&lt;br /&gt;
make -C $(pwd) M=/home/firo/linux/fs/ext3 modules V=1&lt;br /&gt;
make ARCH=arm CROSS_COMPILE=/usr/bin/arm-linux-gnu- drivers/pcmcia/sa11xx_base.o&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;git-repos&#34;&gt;Git repos&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/572068/&#34;&gt;Git tree maintenance&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;next-tree-2-6-1x-latest-tree-please-rebase-your-patch-against-this-tree-before-send-it-to-upstream&#34;&gt;next tree - 2.6.1x ~ latest tree; please rebase your patch against this tree before send it to upstream&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/man-pages/linux-next.html&#34;&gt;Working with linux-next&lt;/a&gt;&lt;br /&gt;
git add git://git.kernel.org/pub/scm/linux/kernel/git/next/linux-next.git&lt;/p&gt;

&lt;h2 id=&#34;tglx-tree-2-4-2-6-1x&#34;&gt;tglx tree - 2.4 - 2.6.1x&lt;/h2&gt;

&lt;p&gt;origin  git://git.kernel.org/pub/scm/linux/kernel/git/tglx/history.git (fetch)&lt;br /&gt;
origin  git://git.kernel.org/pub/scm/linux/kernel/git/tglx/history.git (push)&lt;/p&gt;

&lt;h2 id=&#34;history-tree-0-2-4&#34;&gt;history tree - 0 - 2.4&lt;/h2&gt;

&lt;p&gt;origin  &lt;a href=&#34;https://git.kernel.org/pub/scm/linux/kernel/git/history/history.git/&#34;&gt;https://git.kernel.org/pub/scm/linux/kernel/git/history/history.git/&lt;/a&gt; (fetch)&lt;br /&gt;
origin  &lt;a href=&#34;https://git.kernel.org/pub/scm/linux/kernel/git/history/history.git/&#34;&gt;https://git.kernel.org/pub/scm/linux/kernel/git/history/history.git/&lt;/a&gt; (push)&lt;br /&gt;
git checkout -b 240p 2.4.0-prerelease&lt;/p&gt;

&lt;h1 id=&#34;blogs&#34;&gt;Blogs&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.joelfernandes.org/linuxinternals/&#34;&gt;http://www.joelfernandes.org/linuxinternals/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://paulmck.livejournal.com/&#34;&gt;https://paulmck.livejournal.com/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;traning&#34;&gt;Traning&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/htmldocs/kernel-hacking/index.html&#34;&gt;Unreliable Guide To Hacking The Linux Kernel&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://linux-kernel-labs.github.io/master/index.html&#34;&gt;Bootlin linux kernel labs&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;mailing-list-archives&#34;&gt;Mailing list archives&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/lore.html&#34;&gt;The Linux Kernel Archives&lt;/a&gt;&lt;br /&gt;
Online: &lt;a href=&#34;https://lore.kernel.org/lists.html&#34;&gt;https://lore.kernel.org/lists.html&lt;/a&gt;&lt;br /&gt;
Git: &lt;a href=&#34;https://git.kernel.org/pub/scm/public-inbox/&#34;&gt;https://git.kernel.org/pub/scm/public-inbox/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/758034/&#34;&gt;LKML archives on lore.kernel.org&lt;/a&gt;&lt;br /&gt;
and marc.info&lt;/p&gt;

&lt;h1 id=&#34;source-code-navigator&#34;&gt;Source code navigator&lt;/h1&gt;

&lt;p&gt;Just make tags; make cscope&lt;br /&gt;
&lt;a href=&#34;https://www.gnu.org/software/global/links.html&#34;&gt;&amp;lsquo;Source code reading&amp;rsquo; related sites&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;kvm&#34;&gt;KVM&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://blacks3pt3mb3r.wordpress.com/linux-stuffz/264-2/&#34;&gt;Building a KVM host machine.&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/660404/&#34;&gt;Speeding up kernel development with QEMU&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mgalgs.github.io/2015/05/16/how-to-build-a-custom-linux-kernel-for-qemu-2015-edition.html&#34;&gt;How to Build A Custom Linux Kernel For Qemu&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://morbidrsa.github.io/2017/04/19/rapid-kernel-development-with-dracut-and-qemu.html&#34;&gt;Rapid kernel development with dracut and Qemu&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;suse&#34;&gt;SUSE&lt;/h2&gt;

&lt;p&gt;zypper &amp;ndash;root /home/firo/ws/suse addrepo &lt;a href=&#34;http://download.opensuse.org/distribution/leap/15.0/repo/oss/&#34;&gt;http://download.opensuse.org/distribution/leap/15.0/repo/oss/&lt;/a&gt; foss&lt;br /&gt;
&lt;a href=&#34;https://en.opensuse.org/Package_repositories&#34;&gt;https://en.opensuse.org/Package_repositories&lt;/a&gt;&lt;br /&gt;
zypper &amp;ndash;root /home/firo/ws/suse install kernel-default-devel&lt;/p&gt;

&lt;h2 id=&#34;build-minimal-bootable-rootfs-fedora&#34;&gt;Build minimal bootable rootfs - fedora&lt;/h2&gt;

&lt;p&gt;./etc/yum.repos.d/&lt;br /&gt;
./etc/yum.repos.d/fedora-updates-testing.repo&lt;br /&gt;
./etc/yum.repos.d/fedora.repo&lt;br /&gt;
./etc/yum.repos.d/fedora-updates.repo&lt;br /&gt;
./etc/yum.repos.d/fedora-cisco-openh264.repo&lt;br /&gt;
can be gotten by supermin &amp;ndash;prepare bash -o /tmp/supermin.d&lt;br /&gt;
or just copy from you host to some place like /home/firo/kernel/k/testfs/&lt;br /&gt;
sudo dnf &amp;ndash;releasever=27 &amp;ndash;installroot=/home/firo/kernel/k/testfs/ &amp;ndash;setopt=reposdir=/home/firo/kernel/k/testfs/etc/yum.repos.d install dnf udev passwd&lt;/p&gt;

&lt;h2 id=&#34;how-to-build-a-minimal-kernel-for-testing&#34;&gt;How to build a minimal kernel for testing?&lt;/h2&gt;

&lt;p&gt;[tiny config @ kernel.org][5]&lt;br /&gt;
[3 attempts to reduce the configurations][6]&lt;br /&gt;
&lt;a href=&#34;7&#34;&gt;Fedora equivalent of debootstrap&lt;/a&gt;&lt;br /&gt;
Then enable following config option&lt;br /&gt;
CONFIG_CHR_DEV_SG&lt;br /&gt;
Some ftrace stuff&lt;br /&gt;
CONFIG_SLUB&lt;br /&gt;
CONFIG_KASAN&lt;/p&gt;

&lt;h2 id=&#34;kernel-org-build-a-tiny-kernel-https-tiny-wiki-kernel-org&#34;&gt;&lt;a href=&#34;https://tiny.wiki.kernel.org/&#34;&gt;Kernel.org: Build a tiny kernel&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;make-initrd-for-nfs&#34;&gt;make initrd for NFS&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://migueleonardortiz.com.ar/linux/upgrade-kernel-and-initrd-in-linux/2067&#34;&gt;Upgrade kernel and initrd in Linux&lt;/a&gt;&lt;br /&gt;
sudo chroot suse mkinitrd -m &amp;lsquo;nfs nfsv3 nfsv4 iwlwifi&amp;rsquo; -A -D wlp4s0&lt;/p&gt;

&lt;h2 id=&#34;kvm-and-nfs&#34;&gt;KVM and NFS&lt;/h2&gt;

&lt;p&gt;qemu-system-x86_64 -nographic -enable-kvm  -kernel ./bzImag  -append &amp;lsquo; console=ttyS0 ip=dhcp root=/dev/nfs nfsroot=192.168.0.104:/home/firo/kernel/k/testfs,nfsvers=3,tcp rw nfsrootdebug debug  raid=noautodetect selinux=0 enforcing=0 &amp;lsquo;&lt;br /&gt;
dnf install nfs-utils&lt;br /&gt;
cat /etc/exports # For more details, man exports&lt;br /&gt;
/home/firo/kernel/k/testfs 127.0.0.1(rw,sync,fsid=0,no_root_squash)&lt;br /&gt;
systemctl start nfs-server.service&lt;br /&gt;
systemctl status nfs-server.service&lt;br /&gt;
● nfs-server.service - NFS server and services&lt;br /&gt;
   Loaded: loaded (/usr/lib/systemd/system/nfs-server.service; disabled; vendor preset: disabled)&lt;br /&gt;
   Active: active (exited) since Sat 2018-03-17 17:52:29 CST; 4s ago&lt;/p&gt;

&lt;h3 id=&#34;test-the-nfs&#34;&gt;Test the nfs&lt;/h3&gt;

&lt;p&gt;sudo mount -t nfs localhost://home/firo/kernel/k/testfs /mnt&lt;br /&gt;
if touch prermission denied, add no_all_squash to/etc/exports&lt;/p&gt;

&lt;h2 id=&#34;nfs-errors&#34;&gt;NFS errors&lt;/h2&gt;

&lt;p&gt;[   54.600121] NFS: sending MNT request for 10.0.2.2:/buildarea1/firo/ima/export/dist&lt;br /&gt;
[   54.600121] NFS: failed to create MNT RPC client, status=-101&lt;br /&gt;
[   54.600121] NFS: unable to mount server 10.0.2.2, error -101&lt;br /&gt;
CONFIG_E100 CONFIG_E1000 &amp;hellip;and IP_PNP and DHCP BOOTP RARP&lt;br /&gt;
try: nfsvers=3,tcp and 192.168.0.104 or 10.0.2.2 are mandatory!&lt;/p&gt;

&lt;h2 id=&#34;nfs-vers&#34;&gt;NFS vers&lt;/h2&gt;

&lt;p&gt;rpcinfo -t localhost nfs&lt;br /&gt;
program 100003 version 3 ready and waiting&lt;br /&gt;
program 100003 version 4 ready and waiting&lt;br /&gt;
rpcinfo -p | grep nfs&lt;br /&gt;
    100003    3   tcp   2049  nfs&lt;br /&gt;
    100003    4   tcp   2049  nfs&lt;br /&gt;
    100227    3   tcp   2049  nfs_acl&lt;/p&gt;

&lt;h1 id=&#34;submitting-patch&#34;&gt;Submitting patch&lt;/h1&gt;

&lt;h2 id=&#34;patch-prefix&#34;&gt;Patch prefix&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;git log --oneline  path/to/file.c
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;resending-the-patch&#34;&gt;Resending the patch&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://meta.stackexchange.com/questions/314212/why-is-it-called-initial-revision-if-its-not-a-revision&#34;&gt;First revision, version, second revision&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://kernelnewbies.org/Outreachyfirstpatch&#34;&gt;Versioning one patch revision&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://kernelnewbies.org/PatchTipsAndTricks&#34;&gt;For example, if you&amp;rsquo;re sending the second revision of a patch, you should use [PATCH v2]&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://kernelnewbies.org/PatchPhilosophy&#34;&gt;use PATCHv2 (or PATCHv3 and so on) in the subject lines instead of PATCH &amp;hellip; To update the subject lines, add the -v 2 (or -v 3, etc) options to git format-patch&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://kernelnewbies.org/PatchPhilosophy&#34;&gt;Finally, to send your new patch series as a reply to the previous one, first look up the Message-Id of the cover letter (or the one-and-only patch) in your previous patch series, and then pass that to the &amp;ndash;in-reply-to= option of either git format-patch or git send-email.&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://kernelnewbies.org/PatchTipsAndTricks&#34;&gt;Patch v2, v3, &amp;hellip; Changes, tags&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;patch-in-series-with-a-cover&#34;&gt;Patch in series with a cover&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;proxychains git send-email --subject &amp;quot;[PATCH v2 0/15] Remove unneeded casts of memory-alloc function return values&amp;quot; --thread --compose --confirm=compose --to firogm@gmail.com *.patch
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;dave-s-miller-s-perferences&#34;&gt;Dave S Miller&amp;rsquo;s perferences&lt;/h2&gt;

&lt;p&gt;@@ -325,13 +325,15 @@ static inline void empty_child_dec(struct key_vector *n)&lt;br /&gt;
  static struct key_vector *leaf_new(t_key key, struct fib_alias *fa)&lt;br /&gt;
  {&lt;br /&gt;
-       struct tnode *kv = kmem_cache_alloc(trie_leaf_kmem, GFP_KERNEL);&lt;br /&gt;
-       struct key_vector *l = kv-&amp;gt;kv;&lt;br /&gt;
+       struct tnode *kv;&lt;br /&gt;
+       struct key_vector *l;&lt;br /&gt;
Dave Miller usually prefers it if variables are ordered from longest to shortest.  So you should probably have l defined first, and then kv.&lt;/p&gt;

&lt;h2 id=&#34;julia-lawall-sorry-to-be-picky&#34;&gt;Julia Lawall Sorry to be picky,&lt;/h2&gt;

&lt;p&gt;but normally people put a space after the colon.  Also,&lt;br /&gt;
the subject line could be shorter: Remove unneeded cast.&lt;br /&gt;
The description part of the subject doesnt have to be unique,&lt;br /&gt;
just the whole thing, asfter the [PATCH] part.&lt;/p&gt;

&lt;h2 id=&#34;dan-carpenter&#34;&gt;Dan Carpenter&lt;/h2&gt;

&lt;p&gt;Otherwise your patch was fine, btw.  Other improvements.&lt;br /&gt;
Don&amp;rsquo;t put &amp;ldquo;Drivers:&amp;rdquo; in the subject.&lt;br /&gt;
On Wed, Apr 22, 2015 at 09:10:50PM +0800, Firo Yang wrote:&lt;br /&gt;
&amp;gt; From: Firo Yang &lt;a href=&#34;mailto:firogm@gmail.com&#34;&gt;firogm@gmail.com&lt;/a&gt;&lt;br /&gt;
Don&amp;rsquo;t include this line.  We can get it from you email address.&lt;br /&gt;
Include everyone from the ./scripts/get_maintainer.pl output except&lt;br /&gt;
don&amp;rsquo;t include linux-kernel@vger.kernel.org if there is another mailing&lt;br /&gt;
list there already.&lt;/p&gt;

&lt;h2 id=&#34;kubecek&#34;&gt;Kubecek&lt;/h2&gt;

&lt;p&gt;│17:31:57 mkubecek | For the record, once the commit is in net or net-next tree, there is no chance to tweak its commit message. │ vtsironis_ho&lt;br /&gt;
│17:32:26   alesak | mkubecek: ok, thanks for the clarification                                                                  │ wpreston&lt;br /&gt;
│17:33:19 mkubecek | These trees do not rebase and some people (like me) would appreciate if other subsystem trees didn&amp;rsquo;t        │ Zara&lt;br /&gt;
│                  | either.                                                                                                     │ zuzka&lt;br /&gt;
│17:34:20 mkubecek | We could avoid spurious git_sort failures and commits like kernel-source 174731527683&lt;/p&gt;

&lt;h1 id=&#34;git-mutt-patch&#34;&gt;git mutt patch&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=6zUVS4kJtrA&#34;&gt;Greg: How to Apply a Patch to the Linux Kernel Stable Tree&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;newbies-what-to-do&#34;&gt;newbies! what to do?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/286244/&#34;&gt;Peter Zijlstra: From DOS to kernel hacking&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://kernelnewbies.org/KernelJanitors/Todo&#34;&gt;KernelJanitors/Todo&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/284099/&#34;&gt;linux-wanking@vger.kernel.org&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;smatch&#34;&gt;Smatch&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;    make CHECK=&amp;quot;~/path/to/smatch/smatch -p=kernel&amp;quot; C=1 \
            bzImage modules | tee warns.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;coccinelle&#34;&gt;Coccinelle&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Computing Sorcery a sorcerer&#39;s perspective on computer science</title>
      <link>http://firoyang.org/cs/cs/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:14 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/cs/</guid>
      <description>

&lt;h1 id=&#34;computer-science&#34;&gt;Computer science&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://computersciencewiki.org/index.php/Computational_thinking_%26_problem-solving&#34;&gt;Firo: very good CS website: Computational thinking &amp;amp; problem-solving&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://computersciencewiki.org/index.php/Welcome&#34;&gt;Core topics of computer science&lt;/a&gt;&lt;br /&gt;
Underlying our approach to this subject is our conviction that “computer science” is not a science and that its significance has little to do with computers. The computer revolution is a revolution in the way we think and in the way we express what we think. The essence of this change is the emergence of what might best be called procedural epistemology —the study of the structure of knowledge from an imperative point of view, as opposed to the more declarative point of view taken by classical mathematical subjects. Mathematics provides a framework for dealing precisely with notions of “what is.” Computation provides a framework for dealing precisely with notions of “how to.”  &amp;ndash; The omnipotent SICP&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=lL4wg6ZAFIM&#34;&gt;Richard Feynman on Computer Science — Talk at Bell Labs (1985)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://plato.stanford.edu/entries/computer-science/&#34;&gt;The Philosophy of Computer Science&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;firo&#34;&gt;Firo&lt;/h2&gt;

&lt;p&gt;computation, storage, IO&lt;br /&gt;
Architecture: Memory hierarchy&lt;br /&gt;
OS: VM(layered smantic), Concurrency&lt;br /&gt;
Application:&lt;/p&gt;

&lt;h1 id=&#34;tools&#34;&gt;Tools&lt;/h1&gt;

&lt;p&gt;Parallemism and locality&lt;br /&gt;
Bandwidth and latency&lt;/p&gt;

&lt;h1 id=&#34;problems&#34;&gt;Problems&lt;/h1&gt;

&lt;p&gt;Complexity&lt;br /&gt;
Resource management&lt;br /&gt;
Observation&lt;br /&gt;
Latency&lt;br /&gt;
Scalibity&lt;br /&gt;
Performance/efficiency&lt;br /&gt;
Easy to use&lt;br /&gt;
Security/Protection/isolation&lt;br /&gt;
Reliability&lt;br /&gt;
Energy-efficiency&lt;/p&gt;

&lt;h1 id=&#34;computation&#34;&gt;Computation&lt;/h1&gt;

&lt;h2 id=&#34;function-subroutine-https-en-wikipedia-org-wiki-subroutine-and-call-stack-https-en-wikipedia-org-wiki-call-stack&#34;&gt;Function/&lt;a href=&#34;https://en.wikipedia.org/wiki/Subroutine&#34;&gt;subroutine&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Call_stack&#34;&gt;call stack&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;1945 Turing on subroutines in &lt;a href=&#34;http://www.alanturing.net/turing_archive/archive/p/p01/P01-011.html&#34;&gt;Proposed electronic calculator.&lt;/a&gt;: In Chapter 6. Outline of Logical Control. We also wish to be able to arrange for the splitting up of operations into&amp;hellip; When we wish to start on a subsidiary operation we need only make a note of where we left off the major operation&amp;hellip;&lt;br /&gt;
&lt;a href=&#34;https://link.springer.com/article/10.1007%2FBF01386232&#34;&gt;Firo-must: Dijkstra, E. W. (1960). &amp;ldquo;Recursive Programming&amp;rdquo;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;stack&#34;&gt;stack&lt;/h2&gt;

&lt;p&gt;Stack overflow: gurad page&lt;br /&gt;
Stack based buffer overflow: canary, STACKPROTECTOR, Stack Protector buffer overflow detection&lt;/p&gt;

&lt;p&gt;Related code: boot_init_stack_canary&lt;/p&gt;

&lt;h2 id=&#34;process-vs-event&#34;&gt;process vs event&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://courses.cs.vt.edu/cs5204/fall09-kafura/Presentations/Threads-VS-Events.pdf&#34;&gt;thread vs event&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;concurrency&#34;&gt;Concurrency&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cs.utexas.edu/users/EWD/transcriptions/EWD01xx/EWD123.html&#34;&gt;Firo: must thinking summary: EW Dijkstra: Cooperating sequential processes&lt;/a&gt;&lt;br /&gt;
CSAPP3e: Chapter 12 concurrent programming&lt;br /&gt;
Parallel and Concurrent Programming in Haskell&lt;br /&gt;
The origin of concurrent programming: from semaphores to remote procedure calls - Per Brinch Hansen&lt;br /&gt;
&lt;a href=&#34;https://www.dcl.hpi.uni-potsdam.de/teaching/pvprog/Slides/C1_concurrency.pdf&#34;&gt;Firo: good introduction on history of concurrency: Shared-Memory Concurrency&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=2771951&#34;&gt;Turing lecture: The computer science of concurrency: the early years&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/355700/&#34;&gt;Firo: example: Concurrency-managed workqueues&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://talks.golang.org/2012/concurrency.slide#6&#34;&gt;Rob Pike: Concurrency is the composition of independently executing computations.&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;asynchrony-computer-programming-https-en-wikipedia-org-wiki-asynchrony-computer-programming&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Asynchrony_(computer_programming)&#34;&gt;Asynchrony (computer programming)&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;concurrent-vs-parallel&#34;&gt;concurrent vs parallel&lt;/h2&gt;

&lt;p&gt;Programming vs computing: software vs hardware&lt;br /&gt;
concurrent programming: multi-thread stress on how to create thread to model the outside world.&lt;br /&gt;
parallel programming: smp, synchronization, lock, lock-free, atomic&lt;br /&gt;
&lt;a href=&#34;http://highscalability.com/blog/2014/12/31/linus-the-whole-parallel-computing-is-the-future-is-a-bunch.html&#34;&gt;Linus: The Whole &amp;ldquo;Parallel Computing Is The Future&amp;rdquo; Is A Bunch Of Crock.&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.realworldtech.com/forum/?threadid=146066&amp;amp;curpostid=146227&#34;&gt;Linus: Avoiding ping pong&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;concurrency-problem-1-with-communications&#34;&gt;Concurrency problem 1 with communications&lt;/h2&gt;

&lt;p&gt;IPC check wait.log&lt;/p&gt;

&lt;h2 id=&#34;problem-2-with-memory-access&#34;&gt;Problem 2 with memory access&lt;/h2&gt;

&lt;p&gt;consistency model&lt;/p&gt;

&lt;h1 id=&#34;resource-management&#34;&gt;Resource management&lt;/h1&gt;

&lt;p&gt;check mm.md&lt;/p&gt;

&lt;h1 id=&#34;history&#34;&gt;History&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.chilton-computing.org.uk/acl/technology/atlas/overview.htm&#34;&gt;Atlas&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;os&#34;&gt;OS&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://pages.cs.wisc.edu/~remzi/OSTEP/&#34;&gt;Operating Systems: Three Easy Pieces&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;unix&#34;&gt;Unix&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://users.soe.ucsc.edu/~sbrandt/221/Papers/History/thompson-bstj78.pdf&#34;&gt;Ken Thompson UNIX Implementation&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cs.grinnell.edu/~curtsinger/teaching/2019S/CSC213/files/unix_evolution.pdf&#34;&gt;The Evolution of the UNIX Time-sharing System&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.oreilly.com/openbook/opensources/book/kirkmck.html&#34;&gt;Twenty Years of Berkeley Unix From AT&amp;amp;T-Owned to Freely Redistributable&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://people.eecs.berkeley.edu/~brewer/cs262/unix.pdf&#34;&gt;The UNIX TimeSharing System Dennis M. Ritchie and Ken Thompson Bell Laboratories&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.bell-labs.com/usr/dmr/www/retro.pdf&#34;&gt;The UNIX Time-sharing SystemA Retrospective&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://bitsavers.trailing-edge.com/pdf/sun/sunos/&#34;&gt;SunOS 1.0 - 4.1.2&lt;/a&gt;&lt;br /&gt;
Life with Unix&lt;br /&gt;
&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.9119&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;Design and Implementation of the Berkeley Virtual Memory Extensions to the UNIX† Operating System‡&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;specifications&#34;&gt;Specifications&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://refspecs.linuxbase.org/&#34;&gt;Linux Foundation Referenced Specifications&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The art of debugging</title>
      <link>http://firoyang.org/cs/debugging/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:14 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/debugging/</guid>
      <description>

&lt;h1 id=&#34;quote&#34;&gt;Quote&lt;/h1&gt;

&lt;p&gt;Everyone knows that debugging is twice as hard as writing a program in the first place. So if you&amp;rsquo;re as clever as you can be when you write it, how will you ever debug it?&lt;br /&gt;
&amp;ldquo;The Elements of Programming Style&amp;rdquo;, 2nd edition, chapter 2. Brian Kernighan&lt;/p&gt;

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;Debug hacks: a book on how to debug.&lt;/p&gt;

&lt;h1 id=&#34;bug-classifications&#34;&gt;Bug classifications&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Software_bug#Types&#34;&gt;Software bug types&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://cwe.mitre.org/data/definitions/1000.html&#34;&gt;CWE VIEW: Research Concepts&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://cwe.mitre.org/data/definitions/1003.html&#34;&gt;CWE VIEW: Simplified Mapping&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://cwe.mitre.org/data/definitions/699.html&#34;&gt;CWE VIEW: Development Concepts&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;hardware-bugs&#34;&gt;Hardware Bugs&lt;/h2&gt;

&lt;p&gt;If this has only happened on a single physical machine, I suggest that machine be considered to be faulty.&lt;/p&gt;

&lt;h2 id=&#34;memory-corruption&#34;&gt;Memory corruption&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://cwe.mitre.org/data/definitions/119.html&#34;&gt;The generic term &amp;ldquo;memory corruption&amp;rdquo;&lt;/a&gt;is often used to describe the consequences of writing to memory outside the bounds of a buffer, when the root cause is something other than a sequential copies of excessive data from a fixed starting location(i.e., classic buffer overflows or CWE-120). This may include issues such as incorrect pointer arithmetic, accessing invalid pointers due to incomplete initialization or memory release, etc.]&lt;br /&gt;
&lt;a href=&#34;https://bugzilla.suse.com/show_bug.cgi?id=1155930#c12&#34;&gt;An example by Neil Brown: The corrupted list of inodes could be due to one inode being freed and re-used while still on the list - or it could be due to memory corruption of a forward pointer.&lt;/a&gt;&lt;br /&gt;
Memory corruption is one of the most intractable class of programming errors, for two reasons:&lt;br /&gt;
The source of the memory corruption and its manifestation may be far apart, making it hard to correlate the cause and the effect.&lt;br /&gt;
Symptoms appear under unusual conditions, making it hard to consistently reproduce the error.&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Memory_corruption&#34;&gt;Memory corruption&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Memory_safety&#34;&gt;Memory safety&lt;/a&gt;&lt;br /&gt;
uninitialized memory: &lt;a href=&#34;https://en.wikipedia.org/wiki/Dangling_pointer#Cause_of_wild_pointers&#34;&gt;wild pointer&lt;/a&gt;&lt;br /&gt;
use after free: &lt;a href=&#34;https://en.wikipedia.org/wiki/Dangling_pointer#Cause_of_dangling_pointers&#34;&gt;dangling pointer&lt;/a&gt;&lt;br /&gt;
buffer overflow:&lt;br /&gt;
unknown source memory corruption: The generic &amp;ldquo;memory corruption&amp;rdquo;.&lt;br /&gt;
memory leak:&lt;/p&gt;

&lt;h3 id=&#34;phonomenon&#34;&gt;Phonomenon&lt;/h3&gt;

&lt;p&gt;Invalid page fault(including NULL pointer dereference)&lt;/p&gt;

&lt;h1 id=&#34;debugging&#34;&gt;Debugging&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Abductive_reasoning#Logic-based_abduction&#34;&gt;Abductive reasoning&lt;/a&gt;&lt;br /&gt;
Every bug belons to a known type.&lt;/p&gt;

&lt;h2 id=&#34;steps-according-to-observations-narrow-down-hypothses-successive-approximation&#34;&gt;Steps according to observations, narrow down Hypothses, successive approximation&lt;/h2&gt;

&lt;p&gt;Scientific method&lt;/p&gt;

&lt;h2 id=&#34;get-observations-and-analysis-data&#34;&gt;Get observations and analysis data&lt;/h2&gt;

&lt;p&gt;observation.log&lt;br /&gt;
Data: whole structure, list corruption;life cycle; which part is ok and which part is wrong, Data connections&lt;br /&gt;
call paths: related&lt;/p&gt;

&lt;h2 id=&#34;think-backward&#34;&gt;Think backward&lt;/h2&gt;

&lt;p&gt;How far from symptom to root cause could we think?&lt;br /&gt;
Missing cause:&lt;/p&gt;

&lt;h2 id=&#34;known-bug-types-assumptions&#34;&gt;Known bug types assumptions&lt;/h2&gt;

&lt;p&gt;Mix up Bug types, observations and related all paths&lt;/p&gt;

&lt;h2 id=&#34;connect-to-programming-skills&#34;&gt;Connect to programming skills.&lt;/h2&gt;

&lt;h1 id=&#34;anti-debugging&#34;&gt;Anti-debugging&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Syntax checking&lt;br /&gt;
gcc -Wall&lt;br /&gt;
bash -n&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;static code analysis&lt;br /&gt;
smatch&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
