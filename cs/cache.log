# Buffer cache?

# SLAB

## Reclaim occasions
* Peoridically
cache_reap()

# TLB
http://www.infradead.org/~mchehab/kernel_docs/unsorted/cachetlb.html
https://stackoverflow.com/questions/6803762/dump-the-contents-of-tlb-buffer-of-x86-cpu
https://elixir.bootlin.com/linux/latest/source/Documentation/x86/tlb.txt

# mnt cache
type: hash table
mount_hashtable

# Dentry cache - dcache
## Think it over and human index
access -> accessers sync -> read inode and fill dentry
## Lifetime
?? refcount = -1; bind -> = 0; get =1, 2, 3...
?? LRU 2: 1st mark. 2nd move to head/tail
## Motion concurrent
### Multiple accessers synchronization
#### Locked lookup insert
1. lookup cache
if not; created the dentry, mark as ubound and update progress
2. get lock
lookup cache
if found, discard dentry
if not, insert dentry
Check d_alloc_parallel and ext2_lookup in lookup_slow
### Read dentry that is being reclaimed
Lockref and RCU, read and reclaim in parallel
?? [Introducing lockrefs](https://lwn.net/Articles/565734/)
* Read
d_alloc_parallel->lockref_get_not_dead
* reclaim
shrink_dentry_list
__dentry_kill->
{
	spin_lock(&dentry->d_lock);
	lockref_mark_dead		- why -128?
}
?? RCU
[Dcache scalability and RCU-walk](https://lwn.net/Articles/419811/)

## Connections

## cache
* dentry state
in use/bound
in use/unbound
not use/ boud - LRU
not use/unbound - new one

### Search structure 
Hashtable
### Reclaim polices
Third chance
sb->s_dentry_lru
?? LRU Generic LRU infrastructure
[Smarter shrinkers](https://lwn.net/Articles/550463/)
Check prune_dcache_sb
1. in use -> remove it from lru; and wait to be dput to the tail of lru
dentry->d_lockref.count
2. if referenced -> rotate to tail
DCACHE_REFERENCED
3. move it to dispose list
### Write behavior
### Cache coherence

## Example of using dentry
__shmem_file_setup
d_alloc_pseudo
shmem_get_inode-> inode_init_always
d_instantiate
alloc_file

# Page cache
## Search structure
### anon page: 
* Reverse mapping
rbtree-based Interval tree
[逆向映射的演进](http://www.wowotech.net/memory_management/reverse_mapping.html)
onset:
exec workflow: 
exec -> do_execveat_common-> bprm_mm_init setup_arg_pages
do_anonymous_page -> anon_vma_prepare & page_add_new_anon_rmap
fork workflow:
anon_vma_fork() -> anon_vma_chain_link: node: avc, key: avmc.vma->start/last_pgoff page.mapping=anon_vma.rb_root
rmap: add exclusively owned pages to the newest anon_vma - e8a03feb54ca7f1768bbdc2b491f9ef654e6d01d
nuclus:
rmap_walk_anon()

* swap cache - a fake cache
radix tree same as page cache
add_to_swap 

### file page:
* Reverse mapping 
onset:
rbtree-based interval tree - INTERVAL_TREE_DEFINE in mm/interval_tree.c
__vma_adjust -> __vma_link_file: node: vma.shared.rb, key: vma.start_pgoff and vma.last_pgoff  address_space->i_mmap
address_space is premise
nuclus:
rmap_walk_file(page.mapping=address_space.i_mmap
* page cache
Radix tree
page_cache_tree_insert, add_to_page_cache_lru

## Reclaim algorithm
### access
mark_page_accessed
{
	inactive,referenced          ->      active,unreferenced
	{
		if !PageLRU - on the pagevec
			mm: activate !PageLRU pages on mark_page_accessed if page is on local pagevec - 059285a25f30c13ed4f5d91cecd6094b9b20bb7b
			SetPageActive
		else
			activate_page
	}
	{in,}active,unreferenced        ->      {in,}active,referenced
	{
		SetPageReferenced
	}
}
### active list -> 
if pte with PAGE_ACCESSED - referenced in page_referenced() && VM_EXEC -> keep it in active list - tail -> head - rotated
else
de-activate it to inactive list head
### inactive list
page from tail page_check_references
{
	3 passes: 
	1. hardware pte; use and clear pte; might get reference; second chance.
	2. software flag: -> RECLAIM Clean page and clear, since dirty page is a good signal that the page was used recently because the flusher threads
				clean pages periodically.
	3. reclaim
	hardware accessed - if accessed, won't reclaim
	{
		PAGEREF_ACTIVATE: incline to activate swapbacked page
			PageSwapBacked
			referenced_page
			referenced_ptes > 1
			vm_flags & VM_EXEC
		PAGEREF_KEEP
	} 
	else if ?? software accessed - && dirty won't reclaim
	{
		vmscan: detect mapped file pages used only once - 645747462435d84c6c6a64269ed49cc3015f753d
		vmscan,tmpfs: treat used once pages on tmpfs as used once - 2e30244a7cc1ff09013a1238d415b4076406388e
		# From above commits: When a page has PG_referenced, shrink_page_list() discards it only if it
		# is not dirty. ... PG_dirty is a good signal that the page was used recently because
		# the flusher threads clean pages periodically.  In addition, page writeback
		# is costlier than simple page discard.
		#  Firo: not incline to reclaim dirty page.
		#  Firo: PG_referenced -> PAGEREF_RECLAIM_CLEAN
		file-backed -> PAGEREF_RECLAIM_CLEAN
		swapbacked -> PAGEREF_RECLAIM
	} else 
	{
		PAGEREF_RECLAIM
	}

}
### LQO
* activate writeback pages
mm: vmscan: move dirty pages out of the way until they're flushed - c55e8d035b28b2867e68b0e2d0eee2c0f1016b43

## Replacement polices
replacement policies: 
https://www.kernel.org/doc/gorman/html/understand/understand013.html
https://linux-mm.org/PageReplacementDesign
https://www.kernel.org/doc/gorman/html/understand/understand013.html
[PageReplacementDesign](https://linux-mm.org/PageReplacementDesign)
https://www.cnblogs.com/tolimit/p/5447448.html
### Leave questions open
I saw we always shrink active list from the head, what about the tail entries, if the nr_to_scan isn't enough to reach the end of active list?
Seems this problem is apporached by isolate_lru_pages with for-loop and list_add insert and move_active_pages_to_lru ( lru - LRU_ACTIVE).
### onset
rotate_reclaimable_page()?
### Nuclus
shrink_page_list()
pagevec_lru_move_fn - routines for move pages between inactive list and active list

### Second chance
[Second Chance Page Replacement Algorithm](https://www.youtube.com/watch?v=eHK749r5RGs)
[Second Chance Page Replacement Algorithms and Clock Page Replacement Algorithms](https://www.youtube.com/watch?v=DFmsm0J8joY)
core: page_check_references() in shrink_page_list().
shrink_active_list for VM_EXEC page.
core: page_referenced in shrink_active_list
### active list and inactive list
active list: working set; Am of LRU 2Q; how often
[Better active/inactive list balancing](https://lwn.net/Articles/495543/)
mark_page_accessed and called sub-functions.
active -> inactive head - list_add(&page->lru, &l_inactive); in shrink_active_list
inactive -> active head - __activate_page <- mark_page_accessed <- pagecache_get_page or generic_file_buffered_read
inactive -> inactive tail - rotate_reclaimable_page
cat /proc/meminfo  | grep ctive
Active:          3721100 kB
Inactive:        1005148 kB
Active(anon):    3047008 kB
Inactive(anon):   365148 kB
Active(file):     674092 kB
Inactive(file):   640000 kB

### Working set
mm: thrash detection-based file cache sizing - a528910e12ec7ee203095eb1711468a66b9b60b0
[Not merged - mm: refault distance-based file cache sizing](https://lkml.org/lkml/2012/5/1/51)
workingset_eviction() and workingset_refault()
* WSS
https://github.com/brendangregg/wss
http://www.10tiao.com/html/606/201807/2664605543/1.html

### Clock ??
[ClockProApproximation](https://linux-mm.org/ClockProApproximation)
[A CLOCK-Pro page replacement implementation](https://lwn.net/Articles/147879/)
[CLOCK-Pro: An Effective Improvement of the CLOCK Replacement](https://www.usenix.org/legacy/publications/library/proceedings/usenix05/tech/general/full_papers/jiang/jiang_html/html.html)

## Reclaim Occasions
* Periodically Keep a halthy avaliable free pages.
kswapd_shrink_node
* No enough memory for a large memory alloc.
get_page_from_freelist->node_claim
try_to_free_mem_cgroup_pages
try_to_free_pages
* Manually initiate
hibernate_preallocate_memory->shrink_all_memory
drop_caches

### Target pages
All user space pages, except some pages.
Do not reclaim kernel page in order to make things simple.
Where to store the pages?
        There may be many processes which use the same pages.
        We put list of pages in a global site.
How to organize the pages.
        LRU
        When to add the page to LRU
How to reclaim in deatils.
        For memory-mapped file page, write back.
        For private and anonymous, swap.
        For memroy-mapped file page without modification.
        How to distinguish kernel page from user space page?
How to modify the process's pte to let it know the page has been reclaimed.
        Reverse mapping.

## Write behavior

## Cache coherence

# CPU cache
https://www.scss.tcd.ie/~jones/vivio/caches/MESI.htm
## search structure - associative arrys
[Where exactly L1, L2 and L3 Caches located in computer?](https://superuser.com/questions/196143/where-exactly-l1-l2-and-l3-caches-located-in-computer)
![cpu cache locations](https://i.stack.imgur.com/4Z1nU.png)
### Associativity
* trade-off
a) Checking more places takes more power and chip area,
b) and potentially more time. On the other hand, caches with more associativity suffer fewer misses
fully associative - the best miss rates, but practical only for a small number of entries
N-way set associative cache: 8 is a common choice for later implementations
direct-mapped cache - if two locations map to the same entry, they may continually knock each other out. anti-fragmantion worsens this case.
### N-way set associative cache
* Why isn't set index in the MSB
[The vast majority of accesses are close together...](http://danluu.com/3c-conflict/#fn:L)
* set vs page-align
[comment 6](http://danluu.com/3c-conflict/#fn:4)
Why is transposing a matrix of 512x512 much slower than transposing a matrix of 513x513?
* etc
http://igoro.com/archive/gallery-of-processor-cache-effects/
## Replacement polices
Pseudo-LRU
## Write behavior
[background on ioremap, cacheing, cache coherency on x86](https://lkml.org/lkml/2008/4/29/480)
• write-through cache implementation;
• write-back cache implementation.
• write-combining; and
• uncacheable.
## Cache coherence
## Cache over context switch
[What happens to the cache contents on a context switch](https://cs.stackexchange.com/questions/1088/what-happens-to-the-cache-contents-on-a-context-switch)
https://mechanical-sympathy.blogspot.com/2013/02/cpu-cache-flushing-fallacy.html
[MMU: context switching needs Cache flushing?](https://community.arm.com/dev-platforms/f/discussions/8925/aarch32-1-1-mmu-context-switching-needs-cache-flushing)
[intel should be virtually indexed and physically tagged](https://www.realworldtech.com/sandy-bridge/7/)
Unix systems for modern architectures
## Cache aliasing
[VIPT Cache Aliasing - Georgia Tech - HPCA: Part 4](https://www.youtube.com/watch?v=mMHkIa6Lkek)
## Example 
dmidecode -t cache
cat /sys/devices/system/cpu/cpu0/cache/index0/number_of_sets 
64
cat /sys/devices/system/cpu/cpu0/cache/index0/ways_of_associativity 
8
cat /sys/devices/system/cpu/cpu0/cache/index0/size 
32K
cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size 
64
https://github.com/sysprog21/phonebook
