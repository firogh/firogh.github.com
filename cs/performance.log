
# Concepts
Disk I/O latency: = response time = Service time + Wait time
Network latency: can refer to the time it takes for a message to make a round trip between endpoints.
I/O wait: account_idle_time

# Instrumentation
tracepoints

# Backlog
http://oliveryang.net/2017/12/linux-high-loadavg-analysis-1/

Something like this:

  taskset 1 perf stat -a -e '{instructions,cycles}' --repeat 10 perf bench sched pipe

... will give a very good idea about the general impact of these changes on 
context switch overhead.
https://lore.kernel.org/lkml/1471106302-10159-5-git-send-email-brgerst@gmail.com/T/#u

[Off-CPU Analysis](http://www.brendangregg.com/offcpuanalysis.html#Analysis)

# Tools
[Give me 15 minutes and I'll change your view of Linux tracing](https://www.youtube.com/watch?v=GsMs3n8CB6g)
