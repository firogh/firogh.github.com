<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Cs on f(x) </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://firoyang.org/tags/cs/</link>
    <language>en-us</language>
    <author>Firo Yang</author>
    
    <updated>Wed, 02 Jan 2019 00:00:00 UTC</updated>
    
    <item>
      <title>Kernel memory bug - SLAB&#39;s 3 lists are corrupted.</title>
      <link>http://firoyang.org/howto/bug_mm_1/</link>
      <pubDate>Wed, 02 Jan 2019 00:00:00 UTC</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/howto/bug_mm_1/</guid>
      <description>

&lt;p&gt;Recently, I was working on a kernel memory bug.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://apibugzilla.suse.com/show_bug.cgi?id=1118875&#34;&gt;https://apibugzilla.suse.com/show_bug.cgi?id=1118875&lt;/a&gt;&lt;br /&gt;
L3: kernel BUG at ../mm/slab.c:2804! bad LRU list and active values in page structs in possible use-after-free&lt;/p&gt;

&lt;p&gt;After digging the binary vmcore file of kdump, I got the following findings.&lt;/p&gt;

&lt;h1 id=&#34;node-0&#34;&gt;Node 0&lt;/h1&gt;

&lt;h2 id=&#34;partial&#34;&gt;Partial&lt;/h2&gt;

&lt;p&gt;list page.lru  -H 0xffff8801a7c01348 -s page.lru,s_mem,active,slab_cache,flags &amp;gt;n0p.log&lt;br /&gt;
n0p -&amp;gt; n0f=0xffff8801a7c01358&lt;/p&gt;

&lt;h2 id=&#34;full&#34;&gt;Full&lt;/h2&gt;

&lt;p&gt;list page.lru  -H 0xffff8801a7c01358 -s page.lru,s_mem,active,slab_cache,flags &amp;gt;n0f.log&lt;br /&gt;
n0f -&amp;gt;&lt;br /&gt;
ffffea0006902380&lt;br /&gt;
    lru = {&lt;br /&gt;
      next = 0xffffea0080ed53e0,&lt;br /&gt;
      prev = 0xffffea00405f8ae0&lt;br /&gt;
    }&lt;br /&gt;
    s_mem = 0xffff8801a408e000&lt;br /&gt;
      active = 16&lt;br /&gt;
    slab_cache = 0xffff8801a7c00400&lt;br /&gt;
  flags = 6755398367314048&lt;br /&gt;
ffffea0080ed53c0&lt;br /&gt;
    lru = {&lt;br /&gt;
      next = 0xffffea00422a34e0,&lt;br /&gt;
      prev = 0xffffea00069023a0&lt;br /&gt;
    }&lt;br /&gt;
    s_mem = 0xffff88203b54f000&lt;br /&gt;
      active = 7&lt;br /&gt;
    slab_cache = 0xffff8801a7c00400&lt;br /&gt;
  flags = 24769796876796032&lt;br /&gt;
&amp;hellip; -&amp;gt; n1f = 0xffff881107c00358&lt;/p&gt;

&lt;h1 id=&#34;node-1&#34;&gt;Node 1&lt;/h1&gt;

&lt;h2 id=&#34;partial-1&#34;&gt;Partial&lt;/h2&gt;

&lt;p&gt;crash&amp;gt; list page.lru  -H 0xffff881107c00348 -s page.lru,s_mem,active,slab_cache,flags &amp;gt;n1p.log&lt;br /&gt;
nip-&amp;gt; SLAB ffffea0043ab74e0 -&amp;gt; 0xffff881107c00348 = n1p&lt;br /&gt;
SLAB ffffea0043ab74e0&amp;rsquo;s prev pointing to 0xffff881107c00358&lt;/p&gt;

&lt;h2 id=&#34;full-1&#34;&gt;Full&lt;/h2&gt;

&lt;p&gt;crash&amp;gt; list page.lru  -H 0xffff881107c00358 -s page.lru,s_mem,active,slab_cache,flags &amp;gt;n1f.log&lt;br /&gt;
n1f-&amp;gt; SLAB ffffea0043ab74e0  -&amp;gt; &amp;hellip; -&amp;gt; 0xffff881107c00348 = n1p&lt;/p&gt;

&lt;p&gt;This issue occured on a NUMA system with 2 memory nodes.&lt;br /&gt;
Both node 0 and node 1&amp;rsquo;s SLAB&amp;rsquo;s partial and full lists were corrupted. After looking into this issue a few days, I talked to Vlastimil Babka.&lt;br /&gt;
He provided a fix for this issue. That is 7810e6781e0fcbca78b91cf65053f895bf59e85f - mm, page_alloc: do not break __ GFP_THISNODE by zonelist reset.&lt;/p&gt;

&lt;p&gt;Now, I have a question: why did I cannot solve this issue?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Memory consistency model</title>
      <link>http://firoyang.org/cs/consistency_model/</link>
      <pubDate>Sat, 16 Dec 2017 15:46:12 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/consistency_model/</guid>
      <description>

&lt;p&gt;When we are talking on memory model, we are refering memory consistency model or memory ordering model.&lt;/p&gt;

&lt;h1 id=&#34;hisotry&#34;&gt;Hisotry&lt;/h1&gt;

&lt;p&gt;1979&lt;br /&gt;
&lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2016/12/How-to-Make-a-Multiprocessor-Computer-That-Correctly-Executes-Multiprocess-Programs.pdf&#34;&gt;How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Progranm&lt;/a&gt;&lt;br /&gt;
1987 ~ 1990&lt;br /&gt;
&lt;a href=&#34;https://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf&#34;&gt;Linearizability: A Correctness Condition for Concurrent Objects&lt;/a&gt;&lt;br /&gt;
1989&lt;br /&gt;
&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.3766&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;processor consistency: CACHE CONSISTENCY AND SEQUENTIAL CONSISTENCY&lt;/a&gt;&lt;br /&gt;
1990&lt;br /&gt;
&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=325102&#34;&gt;Release consistency: Memory consistency and event ordering in scalable shared-memory multiprocessors&lt;/a&gt;&lt;br /&gt;
1991&lt;br /&gt;
&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=113406&#34;&gt;Proving sequential consistency of high-performance shared memories&lt;/a&gt;&lt;br /&gt;
1992&lt;br /&gt;
&lt;a href=&#34;https://www.gaisler.com/doc/sparcv8.pdf&#34;&gt;TSO Sparc v8: A standard memory model called Total Store Ordering (TSO) is defined for SPARC&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-1-4615-3604-8_2&#34;&gt;Formal Specification of Memory Models: and two store ordered models TSO and PSO defined by the Sun Microsystem&amp;rsquo;s SPARC architecture.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2001 ~ Present&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=WUfvvFD5tAA&#34;&gt;IA64 memory ordering&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;purposes&#34;&gt;Purposes&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/lectures/14_relaxedReview.pdf&#34;&gt;Motivation: hiding latency&lt;/a&gt;&lt;br /&gt;
▪ Why are we interested in relaxing ordering requirements?&lt;br /&gt;
- Performance&lt;br /&gt;
- Speci!cally, hiding memory latency: overlap memory accesses with other operations&lt;br /&gt;
- Remember, memory access in a cache coherent system may entail much more then&lt;br /&gt;
simply reading bits from memory (!nding data, sending invalidations, etc.)&lt;/p&gt;

&lt;h2 id=&#34;why-tso-it-s-because-that-write-buffer-or-store-buffer-is-not-invisible-any-more-for-multiprocessor-https-www-cis-upenn-edu-devietti-classes-cis601-spring2016-sc-tso-pdf&#34;&gt;Why TSO? &lt;a href=&#34;https://www.cis.upenn.edu/~devietti/classes/cis601-spring2016/sc_tso.pdf&#34;&gt;It&amp;rsquo;s because that write buffer or Store buffer is not invisible any more for multiprocessor&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;To abandon SC; to Allow use of a FIFO write buffer.&lt;br /&gt;
&lt;a href=&#34;https://www.cs.utexas.edu/~bornholt/post/memory-models.html&#34;&gt;An example: There’s no reason why performing event (2) (a read from B) needs to wait until event (1) (a write to A) completes. They don’t interfere with each other at all, and so should be allowed to run in parallel. See Memory Consistency Models: A Primer&lt;/a&gt;&lt;br /&gt;
Hide the write latency by putting the data in the store buffer.&lt;/p&gt;

&lt;h3 id=&#34;why-not-read-write-reordering&#34;&gt;Why not read-write reordering?&lt;/h3&gt;

&lt;p&gt;reordering read-write is non-sense.&lt;/p&gt;

&lt;h1 id=&#34;formal-cause&#34;&gt;Formal cause&lt;/h1&gt;

&lt;p&gt;Shared memory&lt;br /&gt;
Multiprocessor&lt;br /&gt;
Memory access&lt;br /&gt;
program order&lt;br /&gt;
&lt;a href=&#34;https://www.hpl.hp.com/techreports/Compaq-DEC/WRL-95-7.pdf&#34;&gt;Recommened by CAAQA: Observity in SC, TSO, PC: Paragraph Relaxing the Write to Read Program Order in Shared Memory Consistency Models: A Tutorial&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf&#34;&gt;Memory Barriers: a Hardware View for Software Hackers - must read&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://15418.courses.cs.cmu.edu/spring2013/article/41&#34;&gt;&amp;lsquo;A Summary of Relaxed Consistency&amp;rsquo; CMU&lt;/a&gt;&lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/lectures/14_relaxedReview.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;sc&#34;&gt;SC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2016/12/How-to-Make-a-Multiprocessor-Computer-That-Correctly-Executes-Multiprocess-Programs.pdf&#34;&gt;sequential consistency&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://jepsen.io/consistency/models/sequential#formally&#34;&gt;Formal of Sequential Consistency by Jepsen&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;tso&#34;&gt;TSO&lt;/h2&gt;

&lt;p&gt;Total Store Ordering in Appendix k Sparc v8.&lt;/p&gt;

&lt;h3 id=&#34;tso-in-x86&#34;&gt;TSO in x86&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cl.cam.ac.uk/~pes20/weakmemory/x86tso-paper.tphols.pdf&#34;&gt;A Better x86 Memory Model: x86-TSO&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/27595595/when-are-x86-lfence-sfence-and-mfence-instructions-required&#34;&gt;When are x86 LFENCE, SFENCE and MFENCE instructions required?&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;tso-vs-pc&#34;&gt;TSO vs PC:&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://15418.courses.cs.cmu.edu/spring2013/article/41&#34;&gt;&amp;lsquo;A Summary of Relaxed Consistency&amp;rsquo; CMU&lt;/a&gt;&lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/lectures/14_relaxedReview.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;tso-and-peterson-s-algorithm&#34;&gt;TSO and Peterson&amp;rsquo;s algorithm&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://bartoszmilewski.com/2008/11/05/who-ordered-memory-fences-on-an-x86/&#34;&gt;Who ordered memory fences on an x86?&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cnblogs.com/caidi/p/6708789.html&#34;&gt;共同进入与饥饿&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;pc&#34;&gt;PC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.3766&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;processor consistency: CACHE CONSISTENCY AND SEQUENTIAL CONSISTENCY&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;wc&#34;&gt;WC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~kubitron/cs252/handouts/oldquiz/p434-dubois.pdf&#34;&gt;weak consistency: Memory access buffering in multiprocessors&lt;/a&gt;&lt;br /&gt;
They distinguish between ordinary shared accesses and synchronization accesses, where the latter are used to control concurrency&lt;br /&gt;
between several processes and to maintain the integrity of ordinary shared data.&lt;/p&gt;

&lt;h2 id=&#34;rc&#34;&gt;RC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=325102&#34;&gt;Firo: a must-read: Release consistency: Memory consistency and event ordering in scalable shared-memory multiprocessors&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/dxtecharts/lockless-programming?redirectedfrom=MSDN#read-acquire-and-write-release-barriers&#34;&gt;Must-read: Lockless Programming Considerations for Xbox 360 and Microsoft Windows&lt;/a&gt;&lt;br /&gt;
At right top of page 6&lt;br /&gt;
Condition 3.1: Conditions for Release Consistency&lt;br /&gt;
(A) before an ordinary load or store access is allowed to perform with respect to any other processor,&lt;br /&gt;
all previous acquire accesses must be performed, and&lt;br /&gt;
(B) before a release access is allowed to perform with&lt;br /&gt;
respect to any other processor, all previous ordinary&lt;br /&gt;
load and store accesses must be performed, and&lt;br /&gt;
&amp;copy; special accesses are processor consistent with respect to one another.&lt;br /&gt;
&lt;a href=&#34;https://preshing.com/20120913/acquire-and-release-semantics/&#34;&gt;Acquire and Release Semantics&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://marc.info/?l=linux-kernel&amp;amp;m=151844394031510&amp;amp;w=2&#34;&gt;mm/page_ref: use atomic_set_release in page_ref_unfreeze&lt;/a&gt;&lt;br /&gt;
commit 7088efa9137a15d7d21e3abce73e40c9c8a18d68&lt;br /&gt;
Refs: v4.15-rc1-4-g7088efa9137a&lt;br /&gt;
Author:     Paul E. McKenney &lt;a href=&#34;mailto:paulmck@linux.vnet.ibm.com&#34;&gt;paulmck@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
AuthorDate: Mon Oct 9 10:04:27 2017 -0700&lt;br /&gt;
Commit:     Paul E. McKenney &lt;a href=&#34;mailto:paulmck@linux.vnet.ibm.com&#34;&gt;paulmck@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
CommitDate: Mon Dec 4 10:52:52 2017 -0800&lt;br /&gt;
    fs/dcache: Use release-acquire for name/length update&lt;/p&gt;

&lt;h2 id=&#34;kernel&#34;&gt;Kernel&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/memory-barriers.txt&#34;&gt;Why do we need mb for SLEEP AND WAKE-UP FUNCTIONS?&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/718628/&#34;&gt;A formal kernel memory-ordering model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/720550/&#34;&gt;A formal kernel memory-ordering model (part 2)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4374.html&#34;&gt;Linux-Kernel Memory Model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0124r4.html&#34;&gt;Linux-Kernel Memory Model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0124r6.html&#34;&gt;Linux-Kernel Memory Model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://events.linuxfoundation.org/sites/events/files/slides/LinuxMM.2016.09.19a.LCE_.pdf&#34;&gt;Linux-Kernel Memory Ordering: Help Arrives At Last!&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/watch?v=ULFytshTvIY&#34;&gt;Talk on youtube on this!&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;compiler&#34;&gt;Compiler&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://preshing.com/20120625/memory-ordering-at-compile-time/&#34;&gt;Memory Ordering at Compile Time&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://blog.regehr.org/archives/232&#34;&gt;A Guide to Undefined Behavior in C and C++, Part 3&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;other-architectures&#34;&gt;Other architectures&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cl.cam.ac.uk/~pes20/weakmemory/&#34;&gt;Relaxed-Memory Concurrency&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;c11-library-memory-model&#34;&gt;C11(library) memory model&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://en.cppreference.com/w/c/atomic/memory_order&#34;&gt;C memory order&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cl.cam.ac.uk/~pes20/cpp/notes42.html&#34;&gt;Don&amp;rsquo;t read: The Thin-air Problem&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42967.pdf&#34;&gt;Outlawing Ghosts: Avoiding Out-of-Thin-Air Results&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4375.html&#34;&gt;Out-of-Thin-Air Execution is Vacuous&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;material&#34;&gt;Material&lt;/h1&gt;

&lt;h2 id=&#34;practices&#34;&gt;Practices&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://preshing.com/20120515/memory-reordering-caught-in-the-act/&#34;&gt;Memory Reordering Caught in the Act&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;lqo&#34;&gt;LQO&lt;/h2&gt;

&lt;p&gt;134 static void sysrq_handle_crash(int key)&lt;br /&gt;
 135 {&lt;br /&gt;
 136         char &lt;em&gt;killer = NULL;&lt;br /&gt;
 137&lt;br /&gt;
 138         /&lt;/em&gt; we need to release the RCU read lock here,&lt;br /&gt;
 139          * otherwise we get an annoying&lt;br /&gt;
 140          * &amp;lsquo;BUG: sleeping function called from invalid context&amp;rsquo;&lt;br /&gt;
 141          * complaint from the kernel before the panic.&lt;br /&gt;
 142          &lt;em&gt;/&lt;br /&gt;
 143         rcu_read_unlock();&lt;br /&gt;
 144         panic_on_oops = 1;      /&lt;/em&gt; force panic */&lt;br /&gt;
 145         wmb();&lt;br /&gt;
 146         *killer = 1;&lt;br /&gt;
 147 }&lt;/p&gt;

&lt;h1 id=&#34;memory-barrier&#34;&gt;Memory barrier&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/memory-barriers.txt&#34;&gt;https://www.kernel.org/doc/Documentation/memory-barriers.txt&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://en.wikipedia.org/wiki/Memory_barrier&#34;&gt;http://en.wikipedia.org/wiki/Memory_barrier&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://yarchive.net/comp/linux/compiler_barriers.html&#34;&gt;http://yarchive.net/comp/linux/compiler_barriers.html&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://preshing.com/20120710/memory-barriers-are-like-source-control-operations/&#34;&gt;Memory Barriers Are Like Source Control Operations&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/pub/linux/kernel/people/paulmck/Answers/SMP/lwsync.html&#34;&gt;Are All Linux Kernel Memory Barriers Transitive?&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://events.linuxfoundation.org/sites/events/files/slides/dbueso-elc2016-membarriers-final.pdf&#34;&gt;Memory Barriers in the Linux Kernel Semantics and Practices&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When a program runs on a single-CPU machine, the hardware performs the necessary bookkeeping to ensure that the program executes as if all memory operations were performed in the order specified by the programmer (program order), so memory barriers are not necessary. However, when the memory is shared with multiple devices, such as other CPUs in a multiprocessor system, or memory mapped peripherals, out-of-order access may affect program behavior. For example, a second CPU may see memory changes made by the first CPU in a sequence which differs from program order.&lt;br /&gt;
Compiler and cpu do the same optimization: reorder of instructions&lt;/p&gt;

&lt;h2 id=&#34;the-linux-kernel-has-a-variety-of-different-barriers-that-act-at-different-levels&#34;&gt;The Linux kernel has a variety of different barriers that act at different levels:&lt;/h2&gt;

&lt;p&gt;(&lt;em&gt;) Compiler barrier.&lt;br /&gt;
  (&lt;/em&gt;) CPU memory barriers.&lt;br /&gt;
  (*) MMIO write barrier.&lt;/p&gt;

&lt;h2 id=&#34;access-once&#34;&gt;ACCESS_ONCE&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Does it work cast a variable to volatile?&lt;br /&gt;
No, there is no efects on cast a variable to volatile.&lt;br /&gt;
Because, access variable is before volatile cast! That means you&lt;br /&gt;
still get a register value. What you do is just conversion a temporary variable&lt;br /&gt;
Rationale for International Standard&amp;ndash;Programming Languages&amp;ndash;C&lt;br /&gt;
&lt;a href=&#34;http://www.geeksforgeeks.org/understanding-volatile-qualifier-in-c/&#34;&gt;Understanding “volatile” qualifier in C&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Softirq of Linux Kernel</title>
      <link>http://firoyang.org/cs/softirq/</link>
      <pubDate>Mon, 03 Apr 2017 13:09:05 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/softirq/</guid>
      <description>

&lt;h1 id=&#34;the-old-bottom-half&#34;&gt;The old bottom half&lt;/h1&gt;

&lt;p&gt;ULK 1st: 4.6.6 Bottom Half&lt;br /&gt;
History: commit ad09492558ffa7c67f2b58d23d04dce9ffb9b9dd (tag: 0.99)&lt;br /&gt;
Author: Linus Torvalds &lt;a href=&#34;mailto:torvalds@linuxfoundation.org&#34;&gt;torvalds@linuxfoundation.org&lt;/a&gt;&lt;br /&gt;
Date:   Fri Nov 23 15:09:07 2007 -0500&lt;br /&gt;
    [PATCH] Linux-0.99 (December 13, 1992)&lt;br /&gt;
Firo: There isn&amp;rsquo;t to much useful comment. But the code is very simple. Search bh_base.&lt;/p&gt;

&lt;h1 id=&#34;task-queue&#34;&gt;task queue&lt;/h1&gt;

&lt;p&gt;history: commit 98606bddf430f0a60d21fba93806f4e3c736b170 (tag: 1.1.13)&lt;br /&gt;
Author: Linus Torvalds &lt;a href=&#34;mailto:torvalds@linuxfoundation.org&#34;&gt;torvalds@linuxfoundation.org&lt;/a&gt;&lt;br /&gt;
Date:   Fri Nov 23 15:09:30 2007 -0500&lt;br /&gt;
    Import 1.1.13&lt;br /&gt;
+ * New proposed &amp;ldquo;bottom half&amp;rdquo; handlers:&lt;br /&gt;
+ * &amp;copy; 1994 Kai Petzke, wpp@marie.physik.tu-berlin.de&lt;br /&gt;
+ * Advantages:&lt;br /&gt;
+ * - Bottom halfs are implemented as a linked list.  You can have as many&lt;br /&gt;
+ *   of them, as you want.&lt;br /&gt;
+ * - No more scanning of a bit field is required upon call of a bottom half.&lt;br /&gt;
+ * - Support for chained bottom half lists.  The run_task_queue() function can be&lt;br /&gt;
+ *   used as a bottom half handler.  This is for example usefull for bottom&lt;br /&gt;
+ *   halfs, which want to be delayed until the next clock tick.&lt;br /&gt;
+ * Problems:&lt;br /&gt;
+ * - The queue_task_irq() inline function is only atomic with respect to itself.&lt;br /&gt;
+ *   Problems can occur, when queue_task_irq() is called from a normal system&lt;br /&gt;
+ *   call, and an interrupt comes in.  No problems occur, when queue_task_irq()&lt;br /&gt;
+ *   is called from an interrupt or bottom half, and interrupted, as run_task_queue()&lt;br /&gt;
+ *   will not be executed/continued before the last interrupt returns.  If in&lt;br /&gt;
+ *   doubt, use queue_task(), not queue_task_irq().&lt;br /&gt;
+ * - Bottom halfs are called in the reverse order that they were linked into&lt;br /&gt;
+ *   the list.&lt;br /&gt;
+struct tq_struct {&lt;br /&gt;
Check ULK2nd 4.7.3.1 Extending a bottom half for task queues, especially tq_context and keventd&lt;br /&gt;
The Old Task Queue Mechanism in LKD3rd. Cition from it below.&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/11351/&#34;&gt;The end of task queues&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;softirq&#34;&gt;Softirq&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cs.unca.edu/brock/classes/Spring2013/csci331/notes/paper-1130.pdf&#34;&gt;I’ll Do It Later: Softirqs, Tasklets, Bottom Halves, Task Queues, Work Queues and Timers&lt;/a&gt;&lt;br /&gt;
* not allow execute nest but can recusive lock:local_bh_disable&lt;br /&gt;
current-&amp;gt;preemt_count + SOFIRQ_OFFSET also disable preempt current process.&lt;br /&gt;
* hardirq on, can&amp;rsquo;t sleep&lt;br /&gt;
* not percpu&lt;/p&gt;

&lt;h1 id=&#34;occassions-of-softirq&#34;&gt;Occassions of Softirq&lt;/h1&gt;

&lt;p&gt;irq_exit()&lt;br /&gt;
re-enables softirq, local_bh_enable/spin_unlock_bh(); explicity checks executes, netstack/blockIO.&lt;br /&gt;
ksoftirqd&lt;/p&gt;

&lt;h1 id=&#34;tasklet&#34;&gt;Tasklet&lt;/h1&gt;

&lt;p&gt;History: commit 6cc120a8e71a8d124bf6411fc6e730a884b82701 (tag: 2.3.43pre7)&lt;br /&gt;
Author: Linus Torvalds &lt;a href=&#34;mailto:torvalds@linuxfoundation.org&#34;&gt;torvalds@linuxfoundation.org&lt;/a&gt;&lt;br /&gt;
Date:   Fri Nov 23 15:30:52 2007 -0500&lt;br /&gt;
    Import 2.3.43pre7&lt;br /&gt;
+ Tasklets &amp;mdash; multithreaded analogue of BHs.&lt;br /&gt;
+   Main feature differing them of generic softirqs: tasklet&lt;br /&gt;
+   is running only on one CPU simultaneously.&lt;br /&gt;
+   Main feature differing them of BHs: different tasklets&lt;br /&gt;
+   may be run simultaneously on different CPUs.&lt;br /&gt;
+   Properties:&lt;br /&gt;
+   * If tasklet_schedule() is called, then tasklet is guaranteed&lt;br /&gt;
+     to be executed on some cpu at least once after this.&lt;br /&gt;
+   * If the tasklet is already scheduled, but its excecution is still not&lt;br /&gt;
+     started, it will be executed only once.&lt;br /&gt;
+   * If this tasklet is already running on another CPU (or schedule is called&lt;br /&gt;
+     from tasklet itself), it is rescheduled for later.&lt;br /&gt;
+   * Tasklet is strictly serialized wrt itself, but not&lt;br /&gt;
+     wrt another tasklets. If client needs some intertask synchronization,&lt;br /&gt;
+     he makes it with spinlocks.&lt;/p&gt;

&lt;h1 id=&#34;timer&#34;&gt;Timer&lt;/h1&gt;

&lt;h2 id=&#34;irqsafe-timer&#34;&gt;irqsafe timer&lt;/h2&gt;

&lt;p&gt;__run_timers&lt;br /&gt;
irqsafe = timer-&amp;gt;flags &amp;amp; TIMER_IRQSAFE&lt;br /&gt;
check del_timer_sync&lt;br /&gt;
and definition of TIMER_IRQSAFE&lt;br /&gt;
&lt;a href=&#34;https://patchwork.kernel.org/patch/10811995/&#34;&gt;https://patchwork.kernel.org/patch/10811995/&lt;/a&gt;&lt;br /&gt;
Is timer pending&lt;/p&gt;

&lt;h1 id=&#34;lqo&#34;&gt;LQO&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://thread.gmane.org/gmane.linux.kernel/1152658&#34;&gt;Deal PF_MEMALLOC in softirq&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Softirq of Linux Kernel</title>
      <link>http://firoyang.org/dark_ages/softirq/</link>
      <pubDate>Mon, 03 Apr 2017 13:09:05 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/dark_ages/softirq/</guid>
      <description>

&lt;p&gt;##softirq&lt;br /&gt;
同一个softirq可以在不同的CPU上同时运行，softirq必须是可重入的。&lt;br /&gt;
* not allow execute nest but can recusive lock:local_bh_disable&lt;br /&gt;
current-&amp;gt;preemt_count + SOFIRQ_OFFSET also disable preempt current process.&lt;br /&gt;
* hardirq on, can&amp;rsquo;t sleep&lt;br /&gt;
* not percpu&lt;/p&gt;

&lt;h2 id=&#34;tasklet-and-kernel-timer-is-based-on-softirq&#34;&gt;tasklet and kernel timer is based on softirq&lt;/h2&gt;

&lt;p&gt;新增softirq, 是要重新编译内核的, 试试tasklet也不错.&lt;br /&gt;
.不允许两个两个相同类型的tasklet同时执行，即使在不同的处理器上&lt;br /&gt;
* First of all, it&amp;rsquo;s a conglomerate of mostly unrelated jobs,&lt;br /&gt;
 which run in the context of a randomly chosen victim&lt;br /&gt;
 w/o the ability to put any control on them. &amp;ndash;Thomas Gleixner&lt;/p&gt;

&lt;p&gt;tasklet different with other softirq is run  signal cpu core&lt;br /&gt;
spinlock_bh wider then spinlock&lt;/p&gt;

&lt;p&gt;###time of softirq&lt;br /&gt;
* follow hardirq, irq_exit()&lt;br /&gt;
* re-enables softirq, local_bh_enable/spin_unlock_bh(); explicity checks executes, netstack/blockIO.&lt;br /&gt;
* ksoftirqd&lt;/p&gt;

&lt;p&gt;###tasklet&lt;br /&gt;
tasklet like a workqueue, sofirq like kthread. that is wonderful, does it?&lt;br /&gt;
tasklet 被__tasklet_schedule到某个cpu的percu 变量tasklet_vec.tail上保证了&lt;br /&gt;
只有一个cpu执行同一时刻.&lt;/p&gt;

&lt;p&gt;#FAQ&lt;br /&gt;
##When to save irq rather than just disable irq&lt;br /&gt;
local_irq_disable() used in the code path that never disabled interrupts.&lt;br /&gt;
local_irq_save(flags) used in the code path that already disabled interrupts.&lt;/p&gt;

&lt;p&gt;##what about irq nested?&lt;br /&gt;
&lt;a href=&#34;http://lwn.net/Articles/380937/&#34;&gt;http://lwn.net/Articles/380937/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://thread.gmane.org/gmane.linux.kernel/1152658&#34;&gt;Deal PF_MEMALLOC in softirq&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>x86 interrupt and exception</title>
      <link>http://firoyang.org/cs/interrupt_and_exception/</link>
      <pubDate>Mon, 03 Apr 2017 13:02:12 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/interrupt_and_exception/</guid>
      <description>

&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://people.cs.clemson.edu/~mark/interrupts.html&#34;&gt;history of interrupts&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://virtualirfan.com/history-of-interrupts&#34;&gt;Another History of interrupts with video&lt;/a&gt;&lt;br /&gt;
Interrupts: asynonymous(passively received), external&lt;br /&gt;
Exception: synonymous(actively detected), internal&lt;br /&gt;
Software interrupts: is a trap. int/int3, into, bound.&lt;br /&gt;
&lt;a href=&#34;http://wangcong.org/2012/06/01/-e4-b8-ba-e4-bb-80-e4-b9-88linux-e5-86-85-e6-a0-b8-e4-b8-8d-e5-85-81-e8-ae-b8-e5-9c-a8-e4-b8-ad-e6-96-ad-e4-b8-ad-e4-bc-91-e7-9c-a0-ef-bc-9f/&#34;&gt;为什么Linux内核不允许在中断中休眠&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=-pehAzaP1eg&#34;&gt;IRQs: the Hard, the Soft, the Threaded and the Preemptible&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=YE8cRHVIM4E&#34;&gt;How Dealing with Modern Interrupt Architectures can Affect Your Sanity&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;mask-exception&#34;&gt;Mask exception&lt;/h2&gt;

&lt;p&gt;RF in EFLAGS for masking #DB&lt;br /&gt;
SS &amp;amp; SP&lt;/p&gt;

&lt;h1 id=&#34;form&#34;&gt;Form&lt;/h1&gt;

&lt;h2 id=&#34;interrupt-context-terminology&#34;&gt;Interrupt Context terminology&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;interrupt context - in_irq or in_interrupt&lt;br /&gt;
irq_enter&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;bh context - in_softirq&lt;br /&gt;
local_bh_disable&lt;br /&gt;
__do_softirq -&amp;gt; __local_bh_disable_ip&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;recusively-disbale-irq&#34;&gt;Recusively disbale irq&lt;/h2&gt;

&lt;p&gt;local_irq_disable() used in the code path that never disabled interrupts.&lt;br /&gt;
local_irq_save(flags) used in the code path that already disabled interrupts.&lt;/p&gt;

&lt;h2 id=&#34;irq-nested&#34;&gt;irq nested?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://lwn.net/Articles/380937/&#34;&gt;Prevent nested interrupts when the IRQ stack is near overflowing v2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.lenky.info/archives/2013/03/2245&#34;&gt;对Linux x86-64架构上硬中断的重新认识&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;exceptions&#34;&gt;Exceptions&lt;/h1&gt;

&lt;h2 id=&#34;faults-a-fault-is-an-exception-that-can-generally-be-corrected-and-that-once-corrected-allows-the-program&#34;&gt;Faults — A fault is an exception that can generally be corrected and that, once corrected, allows the program&lt;/h2&gt;

&lt;p&gt;to be restarted with no loss of continuity. When a fault is reported, the processor restores the machine state to&lt;br /&gt;
the state prior to the beginning of execution of the faulting instruction. The return address (saved contents of&lt;br /&gt;
the CS and EIP registers) for the fault handler points to the faulting instruction, rather than to the instruction&lt;br /&gt;
following the faulting instruction.&lt;/p&gt;

&lt;h2 id=&#34;traps-a-trap-is-an-exception-that-is-reported-immediately-following-the-execution-of-the-trapping-instruction&#34;&gt;Traps — A trap is an exception that is reported immediately following the execution of the trapping instruction.&lt;/h2&gt;

&lt;p&gt;Traps allow execution of a program or task to be continued without loss of program continuity. The return&lt;br /&gt;
address for the trap handler points to the instruction to be executed after the trapping instruction.&lt;/p&gt;

&lt;h2 id=&#34;aborts-an-abort-is-an-exception-that-does-not-always-report-the-precise-location-of-the-instruction-causing&#34;&gt;Aborts — An abort is an exception that does not always report the precise location of the instruction causing&lt;/h2&gt;

&lt;p&gt;the exception and does not allow a restart of the program or task that caused the exception. Aborts are used to&lt;br /&gt;
report severe errors, such as hardware errors and inconsistent or illegal values in system tables.&lt;/p&gt;

&lt;h2 id=&#34;kernel-handler&#34;&gt;kernel handler&lt;/h2&gt;

&lt;p&gt;do_error_trap&lt;/p&gt;

&lt;p&gt;#x86 Interrupt&lt;br /&gt;
If interrupt occured in user mode, then cpu will context swith for potential reschedule.&lt;br /&gt;
The Interrupt Descriptor Table (IDT) is a data structure used by the x86 architecture to implement an interrupt vector table.&lt;br /&gt;
##Hardware interrupts&lt;br /&gt;
are used by devices to communicate that they require attention from the operating system.&lt;br /&gt;
more details in init_IRQ() or set_irq() in driver.&lt;br /&gt;
##software interrupt&lt;br /&gt;
more details in trap_init().&lt;br /&gt;
* exception or trap&lt;br /&gt;
is caused either by an exceptional condition in the processor itself,&lt;br /&gt;
divide zero painc?&lt;br /&gt;
* special instruction, for example INT 0x80&lt;br /&gt;
or a special instruction in the instruction set which causes an interrupt when it is executed.&lt;/p&gt;

&lt;h1 id=&#34;x86&#34;&gt;x86&lt;/h1&gt;

&lt;h2 id=&#34;interrupt-vector&#34;&gt;Interrupt vector&lt;/h2&gt;

&lt;p&gt;arch/x86/include/asm/irq_vectors.h&lt;/p&gt;

&lt;h2 id=&#34;why-do-timer-interrupt-and-de-share-the-same-vector-0&#34;&gt;Why do timer interrupt and #DE share the same vector 0.&lt;/h2&gt;

&lt;p&gt;cat /proc/interrupts&lt;br /&gt;
            CPU0       CPU1       CPU2       CPU3&lt;br /&gt;
   0:         21          0          0          0  IR-IO-APIC    2-edge      timer&lt;br /&gt;
v3a Chapter 6&lt;br /&gt;
0, DE, Divide Error, Fault, No DIV and IDIV instructions.&lt;br /&gt;
Check ULK3 Chapter 4 Interrupt vectors and Linux 技术内幕 7.2.1中断号&lt;br /&gt;
the 0 in /proc/interrupts is a IRQ line number&lt;br /&gt;
The 0 for Divide error is a interrupt vector.&lt;/p&gt;

&lt;h2 id=&#34;an-example-of-threaded-irq&#34;&gt;An example of threaded irq&lt;/h2&gt;

&lt;p&gt;mei_me_probe&lt;br /&gt;
ps axjf | grep irq | grep mei&lt;br /&gt;
    2   499     0     0 ?           -1 S        0   0:00  _ [irq/126-mei_me]&lt;/p&gt;

&lt;h2 id=&#34;does-sti-cli-affect-software-interrupt&#34;&gt;Does sti/cli affect software interrupt&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com/a/1581729/1025001&#34;&gt;https://stackoverflow.com/a/1581729/1025001&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ipi&#34;&gt;IPI&lt;/h2&gt;

&lt;p&gt;commit 52aec3308db85f4e9f5c8b9f5dc4fbd0138c6fa4&lt;br /&gt;
Author: Alex Shi &lt;a href=&#34;mailto:alex.shi@intel.com&#34;&gt;alex.shi@intel.com&lt;/a&gt;&lt;br /&gt;
Date:   Thu Jun 28 09:02:23 2012 +0800&lt;br /&gt;
    x86/tlb: replace INVALIDATE_TLB_VECTOR by CALL_FUNCTION_VECTOR&lt;br /&gt;
 73 #define ERROR_APIC_VECTOR               0xfe&lt;br /&gt;
 74 #define RESCHEDULE_VECTOR               0xfd&lt;br /&gt;
 75 #define CALL_FUNCTION_VECTOR            0xfc&lt;br /&gt;
 76 #define CALL_FUNCTION_SINGLE_VECTOR     0xfb&lt;br /&gt;
 77 #define THERMAL_APIC_VECTOR             0xfa&lt;br /&gt;
 78 #define THRESHOLD_APIC_VECTOR           0xf9&lt;br /&gt;
 79 #define REBOOT_VECTOR                   0xf8&lt;/p&gt;

&lt;h2 id=&#34;practices&#34;&gt;Practices&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Triggering a #GP exception&lt;br /&gt;
exception_GP_trigger.S&lt;br /&gt;
&lt;a href=&#34;http://wiki.osdev.org/Exceptions&#34;&gt;Exceptions&lt;/a&gt;&lt;br /&gt;
if you do lidt in userspace program, you will receive SIGSEGV with si_code 128(somewhere of kernel).&lt;br /&gt;
But with the dmesg traps: int0x80[15066] general protection ip:4000c7 sp:7ffc8706cdf0 error:0 in int0x80[400000+1000] form do_general_protection.&lt;br /&gt;
Privilege instructions in V3a chapter 5 Protection&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Obtain sys_call_table on amd64&lt;br /&gt;
&lt;a href=&#34;https://www.exploit-db.com/papers/13146/&#34;&gt;https://www.exploit-db.com/papers/13146/&lt;/a&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;material&#34;&gt;Material&lt;/h1&gt;

&lt;h2 id=&#34;irq-and-exeception-init&#34;&gt;irq and exeception init&lt;/h2&gt;

&lt;p&gt;type: gate_desc; desc_struct&lt;br /&gt;
file: arch/x86/kernel/idt.c&lt;br /&gt;
start_kernel&lt;br /&gt;
{&lt;br /&gt;
        setup_arch&lt;br /&gt;
        {&lt;br /&gt;
                idt_setup_early_traps           #===&amp;gt; idt_table: ist=0; DB, BP&lt;br /&gt;
                &amp;hellip;&lt;br /&gt;
                idt_setup_early_pf              #===&amp;gt; idt_table: PF ist=0;&lt;br /&gt;
        }&lt;br /&gt;
        &amp;hellip;&lt;br /&gt;
        trap_init&lt;br /&gt;
        {&lt;br /&gt;
                idt_setup_traps                 #===&amp;gt; idt_table: ist=0; DE, 0x80 &amp;hellip; etc.&lt;br /&gt;
                &amp;hellip;&lt;br /&gt;
                cpu_init&lt;br /&gt;
                {&lt;br /&gt;
                        load_current_idt&lt;br /&gt;
                        &amp;hellip;&lt;br /&gt;
                        ist stacks init - exception_stacks&lt;br /&gt;
                        t-&amp;gt;x86_tss.ist[v] points to top of each stack.&lt;br /&gt;
                }&lt;br /&gt;
                idt_setup_ist_traps             #===&amp;gt; idt_table: ist=1; DB, NMI, BP, DF, MC;&lt;br /&gt;
                x86_init.irqs.trap_init         #===&amp;gt; if !KVM, noop&lt;br /&gt;
                idt_setup_debugidt_traps        #===&amp;gt; debug_idt_table, check debug stack; INTG; #DB debug; #BP int; check arch/x86/entry/entry_64.S&lt;br /&gt;
                                # idtentry debug                  do_debug                has_error_code=0        paranoid=1 shift_ist=DEBUG_STACK&lt;br /&gt;
                                # idtentry int3                 do_int3                 has_error_code=0        paranoid=1 shift_ist=DEBUG_STACK&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    }
    early_irq_init = alloc NR_IRQS_LEGACY irq_desc; - 16    #===&amp;gt; [    0.000000] NR_IRQS: 65792, nr_irqs: 1024, preallocated irqs: 16
    init_IRQ()-&amp;gt;x86_init.irqs.intr_init=native_init_IRQ     #===&amp;gt; external interrupt init; 
    {
            pre_vector_init = init_ISA_irqs #===&amp;gt; 1) legacy_pic-&amp;gt;init(0); init 8259a; 2) link irq_desc in irq_desc_tree with flow handle and chip.
            idt_setup_apic_and_irq_gates    #===&amp;gt; apic normal(from 32) and system interrupts; 
    }
    softirq_init
    local_irq_enable
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;h3 id=&#34;interrupt-and-exception-stack&#34;&gt;Interrupt and exception stack&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/x86/kernel-stacks&#34;&gt;https://www.kernel.org/doc/Documentation/x86/kernel-stacks&lt;/a&gt;&lt;br /&gt;
TSS v3a 6.12&lt;br /&gt;
6.14.4 Stack Switching in IA-32e Mode&lt;/p&gt;

&lt;h4 id=&#34;exception-page-fault&#34;&gt;Exception - page_fault&lt;/h4&gt;

&lt;p&gt;Kernel doesn&amp;rsquo;t change the inherit TSS stack&lt;/p&gt;

&lt;h4 id=&#34;interrupt-irq-entries-start&#34;&gt;interrupt irq_entries_start&lt;/h4&gt;

&lt;p&gt;Kernel change it irq_stack_union in &amp;ldquo;.macro interrupt&amp;rdquo;&lt;br /&gt;
SWAPGS 要手动切换.&lt;br /&gt;
ENTER_IRQ_STACK old_rsp=%rdi&lt;br /&gt;
movq    %rsp, \old_rsp          #==========&amp;gt; old_rsp should be %rdi, check &lt;a href=&#34;https://sourceware.org/binutils/docs/as/Macro.html&#34;&gt;https://sourceware.org/binutils/docs/as/Macro.html&lt;/a&gt;&lt;br /&gt;
movq    \old_rsp, PER_CPU_VAR(irq_stack_union + IRQ_STACK_SIZE - 8)&lt;br /&gt;
movq    PER_CPU_VAR(irq_stack_ptr), %rsp&lt;/p&gt;

&lt;h4 id=&#34;ist-exception&#34;&gt;IST exception&lt;/h4&gt;

&lt;p&gt;6.14.5 Interrupt Stack Table&lt;br /&gt;
Documentation/x86/kernel-stacks&lt;br /&gt;
Why Debug stack is double page? Spare IST pointer.&lt;/p&gt;

&lt;h3 id=&#34;link-to-process-stack-from-irq-stack&#34;&gt;Link to process stack from irq stack&lt;/h3&gt;

&lt;p&gt;commit a2bbe75089d5eb9a3a46d50dd5c215e213790288&lt;br /&gt;
x86: Don&amp;rsquo;t use frame pointer to save old stack on irq entry&lt;br /&gt;
       /* Save previous stack value &lt;em&gt;/&lt;br /&gt;
       movq %rsp, %rsi&lt;br /&gt;
&amp;hellip;&lt;br /&gt;
2:     /&lt;/em&gt; Store previous stack value */&lt;br /&gt;
       pushq %rsi&lt;br /&gt;
&lt;a href=&#34;https://lore.kernel.org/patchwork/patch/736894/&#34;&gt;Firo: end of EOI; x86/dumpstack: make stack name tags more comprehensible&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;lqo&#34;&gt;LQO&lt;/h2&gt;

&lt;h3 id=&#34;do-nmi-do-int3-debug-stack-usage-inc-debug-idt-descr-debug-idt-table&#34;&gt;do_nmi do_int3 debug_stack_usage_inc, debug_idt_descr, debug_idt_table,&lt;/h3&gt;

&lt;p&gt;load_debug_idt&lt;br /&gt;
commit 42181186ad4db986fcaa40ca95c6e407e9e79372&lt;br /&gt;
Author: Steven Rostedt &lt;a href=&#34;mailto:srostedt@redhat.com&#34;&gt;srostedt@redhat.com&lt;/a&gt;&lt;br /&gt;
Date:   Fri Dec 16 11:43:02 2011 -0500&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x86: Add counter when debug stack is used with interrupts enabled
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;clear-the-flags-for-pf-through-interrupt-gate&#34;&gt;clear the flags for PF through interrupt gate&lt;/h3&gt;

&lt;p&gt;v3a: 6.12.1 Exception- or Interrupt-Handler Procedures&lt;br /&gt;
6.12.1.2 Flag Usage By Exception- or Interrupt-Handler Procedure&lt;/p&gt;

&lt;h3 id=&#34;rbx-in-page-fault&#34;&gt;rbx in page_fault?&lt;/h3&gt;

&lt;h3 id=&#34;x86-64-kernel-don-t-use-trap-gate&#34;&gt;x86_64 kernel don&amp;rsquo;t use trap gate?&lt;/h3&gt;

&lt;p&gt;Yes&lt;/p&gt;

&lt;h3 id=&#34;paranoid&#34;&gt;Paranoid?&lt;/h3&gt;

&lt;p&gt;Documentation/x86/entry_64.txt&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scheduling in operating system</title>
      <link>http://firoyang.org/cs/scheduling/</link>
      <pubDate>Wed, 29 Mar 2017 10:49:04 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/scheduling/</guid>
      <description>

&lt;h1 id=&#34;formal-causes&#34;&gt;Formal causes&lt;/h1&gt;

&lt;h2 id=&#34;preemption&#34;&gt;Preemption&lt;/h2&gt;

&lt;h3 id=&#34;voluntary-kernel-preemption-2-6-12-rc4-mm2-https-lwn-net-articles-137259&#34;&gt;&lt;a href=&#34;https://lwn.net/Articles/137259/&#34;&gt;Voluntary Kernel Preemption, 2.6.12-rc4-mm2&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Voluntary preemption works by adding a cond_resched()&lt;br /&gt;
(reschedule-if-needed) call to every might_sleep() check. It is lighter&lt;br /&gt;
than CONFIG_PREEMPT - at the cost of not having as tight latencies. It&lt;br /&gt;
represents a different latency/complexity/overhead tradeoff.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com/questions/5174955/what-is-voluntary-preemption&#34;&gt;voluntary preemption&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/563185/&#34;&gt;Optimizing preemption&lt;/a&gt;&lt;br /&gt;
commit 41719b03091911028116155deddc5eedf8c45e37&lt;br /&gt;
Refs: v2.6.29-rc1-226-g41719b030919&lt;br /&gt;
Author:     Peter Zijlstra &lt;a href=&#34;mailto:a.p.zijlstra@chello.nl&#34;&gt;a.p.zijlstra@chello.nl&lt;/a&gt;&lt;br /&gt;
AuthorDate: Wed Jan 14 15:36:26 2009 +0100&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
CommitDate: Wed Jan 14 18:09:00 2009 +0100&lt;br /&gt;
    mutex: preemption fixes&lt;br /&gt;
    The problem is that dropping the spinlock right before schedule is a voluntary&lt;br /&gt;
    preemption point and can cause a schedule, right after which we schedule again.&lt;br /&gt;
    Fix this inefficiency by keeping preemption disabled until we schedule, do this&lt;br /&gt;
    by explicity disabling preemption and providing a schedule() variant that&lt;br /&gt;
    assumes preemption is already disabled.&lt;br /&gt;
Firo: spin_unlock_mutex&lt;/p&gt;

&lt;h2 id=&#34;user-preemption-linux-kernel-user-mode-is-always-user-preemption&#34;&gt;User preemption - Linux kernel user mode is always User preemption.&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;When returning to user-space from a system call.&lt;br /&gt;
syscall_return_slowpath&lt;br /&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When returning to user-space from an interrupt hander.&lt;br /&gt;
retint_user-&amp;gt;prepare_exit_to_usermode&lt;/p&gt;

&lt;h2 id=&#34;linux-kernel-kernel-mode-is-coppertive-when-config-preempt-is-not-set&#34;&gt;Linux kernel kernel mode is coppertive when CONFIG_PREEMPT is not set.&lt;/h2&gt;

&lt;p&gt;bloked (which results in a call to schedule())&lt;br /&gt;
If a task in the kernel explicitly calls schedule() it&amp;rsquo;s involuntary!!!&lt;/p&gt;

&lt;h2 id=&#34;linux-kernel-kernel-mode-is-coppertive-preemptive-when-config-preempt-is-set&#34;&gt;Linux kernel kernel mode is coppertive + preemptive when CONFIG_PREEMPT is set.&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When an interrupt handler exits, before returning to kernel-space.&lt;br /&gt;
retint_kernel-&amp;gt;preempt_schedule_irq-&amp;gt;cond_resched&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;__local_bh_enable_ip -&amp;gt; preempt_check_resched&lt;/p&gt;

&lt;h2 id=&#34;the-following-also-t-relates-to-preemption-it-s-preempt-voluntary&#34;&gt;The following also t relates to preemption; it&amp;rsquo;s PREEMPT_VOLUNTARY.&lt;/h2&gt;

&lt;p&gt;For example, in might_resched(). The task willingly yeilds the CPU, but it should stay on rq.&lt;br /&gt;
config PREEMPT_VOLUNTARY&lt;br /&gt;
    bool &amp;ldquo;Voluntary Kernel Preemption (Desktop)&amp;rdquo;&lt;br /&gt;
    help&lt;br /&gt;
      This option reduces the latency of the kernel by adding more&lt;br /&gt;
      &amp;ldquo;explicit preemption points&amp;rdquo; to the kernel code. These new&lt;br /&gt;
      preemption points have been selected to reduce the maximum&lt;br /&gt;
      latency of rescheduling, providing faster application reactions,&lt;br /&gt;
      at the cost of slightly lower throughput.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;need_resched - When kernel code becomes preemptible again.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;set_tsk_need_resched() in resched_curr&lt;br /&gt;
tick: check_preempt_tick or entity_tick&lt;br /&gt;
fork: wake_up_new_task-&amp;gt;check_preempt_curr-&amp;gt;check_preempt_wakeup&lt;br /&gt;
wakeup: check_preempt_wakeup&lt;br /&gt;
&amp;hellip;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;if (need_resched()) cond_resched();&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;lqo&#34;&gt;LQO&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;if (!preempt &amp;amp;&amp;amp; prev-&amp;gt;state)in __schedule; why prev-&amp;gt;state?&lt;br /&gt;
if preempt is true; it should mean PREEMPT_VOLUNTARY.&lt;br /&gt;
prev-&amp;gt;state means deactivate.&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;Process scheduling in Linux &amp;ndash; Volker Seeker from University of Edinburgh&lt;br /&gt;
&lt;a href=&#34;https://tampub.uta.fi/bitstream/handle/10024/96864/GRADU-1428493916.pdf&#34;&gt;A complete guide to Linux process scheduling&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt&#34;&gt;https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://helix979.github.io/jkoo/post/os-scheduler/&#34;&gt;JINKYU KOO&amp;rsquo;s Linux kernel scheduler&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.joelfernandes.org/linuxinternals/2016/03/20/tif-need-resched-why-is-it-needed.html&#34;&gt;TIF_NEED_RESCHED: why is it needed&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;general-runqueues&#34;&gt;General runqueues&lt;/h1&gt;

&lt;p&gt;static DEFINE_PER_CPU_SHARED_ALIGNED(struct rq, runqueues);&lt;br /&gt;
activate_task - move a task to the runqueue.&lt;br /&gt;
wake_up_new_task&lt;br /&gt;
ttwu_do_activate&lt;/p&gt;

&lt;h1 id=&#34;latency&#34;&gt;Latency&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/404993/&#34;&gt;Improving scheduler latency&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;cfs-runqueues&#34;&gt;CFS runqueues&lt;/h1&gt;

&lt;p&gt;cfa_rq&lt;br /&gt;
on_list&lt;br /&gt;
sched_entity-&amp;gt;on_rq, check enqueue_entity&lt;/p&gt;

&lt;h2 id=&#34;cfs-runqueue-and-sched-entity&#34;&gt;CFS runqueue and sched entity&lt;/h2&gt;

&lt;p&gt;set_task_rq&lt;/p&gt;

&lt;h2 id=&#34;on-rq&#34;&gt;on_rq&lt;/h2&gt;

&lt;p&gt;on_rq should be same as task-&amp;gt;on_rq. It doesn&amp;rsquo;t mean sched_entity is on cfs_rq, but rq.&lt;br /&gt;
commit fd2f4419b4cbe8fe90796df9617c355762afd6a4&lt;br /&gt;
Author: Peter Zijlstra &lt;a href=&#34;mailto:a.p.zijlstra@chello.nl&#34;&gt;a.p.zijlstra@chello.nl&lt;/a&gt;&lt;br /&gt;
Date:   Tue Apr 5 17:23:44 2011 +0200&lt;br /&gt;
    sched: Provide p-&amp;gt;on_rq&lt;br /&gt;
p-&amp;gt;on_rq on any rq.&lt;br /&gt;
se-&amp;gt;on_rq on specific rq.&lt;/p&gt;

&lt;h2 id=&#34;cfs-runqueue-and-task-group&#34;&gt;CFS runqueue and task group&lt;/h2&gt;

&lt;p&gt;sched_create_group -&amp;gt; alloc_fair_sched_group -&amp;gt; init_tg_cfs_entry&lt;/p&gt;

&lt;h1 id=&#34;cfs-core-codes&#34;&gt;CFS core codes&lt;/h1&gt;

&lt;p&gt;git log 20b8a59f2461e&lt;/p&gt;

&lt;h1 id=&#34;group-scheduling&#34;&gt;Group scheduling&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt&#34;&gt;GROUP SCHEDULER EXTENSIONS TO CFS&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.wowotech.net/process_management/449.html&#34;&gt;CFS调度器（3）-组调度&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://oenhan.com/task-group-sched&#34;&gt;Linux进程组调度机制分析&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;two-trees&#34;&gt;Two trees&lt;/h2&gt;

&lt;p&gt;task_group-&amp;gt;parent; task_group-&amp;gt;css.cgroup&lt;br /&gt;
cgroup-&amp;gt;parent and cgroup_tg: container_of(cgroup_subsys_state(cgrp, cpu_cgroup_subsys_id), struct task_group, css);&lt;/p&gt;

&lt;h2 id=&#34;task-group-and-cgroup-is-1-1&#34;&gt;Task group and cgroup is 1:1&lt;/h2&gt;

&lt;h2 id=&#34;system-bootup&#34;&gt;System bootup&lt;/h2&gt;

&lt;p&gt;struct task_group root_task_group; and cpu_cgroup_create;&lt;/p&gt;

&lt;h2 id=&#34;creating-task-group&#34;&gt;Creating task_group&lt;/h2&gt;

&lt;p&gt;sched_create_group&lt;br /&gt;
task_group 1 : cpu &amp;lsquo;group sched_entity&amp;rsquo;&lt;br /&gt;
group sched_entity 1 : 1 greoup cfs_rq&lt;br /&gt;
gse_CPUx&amp;rsquo;s load = grq_CPUx&amp;rsquo;s all se&amp;rsquo;s load * task_group-&amp;gt;shares / grq_CPU&lt;em&gt;&amp;rsquo;s all se&amp;rsquo;s load&lt;br /&gt;
        /&lt;/em&gt; rq on which this entity is (to be) queued: */&lt;br /&gt;
        struct cfs_rq           &lt;em&gt;cfs_rq;&lt;br /&gt;
        /&lt;/em&gt; rq &amp;ldquo;owned&amp;rdquo; by this entity/group: */&lt;br /&gt;
        struct cfs_rq           *my_q;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/240474/&#34;&gt;CFS group scheduling&lt;/a&gt;&lt;br /&gt;
commit 29f59db3a74b0bdf78a1f5b53ef773caa82692dc&lt;br /&gt;
Author: Srivatsa Vaddagiri &lt;a href=&#34;mailto:vatsa@linux.vnet.ibm.com&#34;&gt;vatsa@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
Date:   Mon Oct 15 17:00:07 2007 +0200&lt;br /&gt;
    sched: group-scheduler core&lt;/p&gt;

&lt;h2 id=&#34;why-double-for-each-sched-entity&#34;&gt;Why double for_each_sched_entity&lt;/h2&gt;

&lt;p&gt;commit 2069dd75c7d0f49355939e5586daf5a9ab216db7&lt;br /&gt;
Author: Peter Zijlstra &lt;a href=&#34;mailto:a.p.zijlstra@chello.nl&#34;&gt;a.p.zijlstra@chello.nl&lt;/a&gt;&lt;br /&gt;
Date:   Mon Nov 15 15:47:00 2010 -0800&lt;br /&gt;
    sched: Rewrite tg_shares_up)&lt;/p&gt;

&lt;p&gt;371fd7e7a56a5 (Peter Zijlstra       2010-03-24 16:38:48 +0100 1129) enqueue_task_fair(struct rq *rq, struct task_struct *p, int flags)&lt;br /&gt;
bf0f6f24a1ece (Ingo Molnar          2007-07-09 18:51:58 +0200 1134)     for_each_sched_entity(se) {&lt;br /&gt;
62fb185130e4d (Peter Zijlstra       2008-02-25 17:34:02 +0100 1135)             if (se-&amp;gt;on_rq)&lt;br /&gt;
bf0f6f24a1ece (Ingo Molnar          2007-07-09 18:51:58 +0200 1136)                     break;&lt;br /&gt;
bf0f6f24a1ece (Ingo Molnar          2007-07-09 18:51:58 +0200 1137)             cfs_rq = cfs_rq_of(se);&lt;br /&gt;
88ec22d3edb72 (Peter Zijlstra       2009-12-16 18:04:41 +0100 1138)             enqueue_entity(cfs_rq, se, flags);&lt;br /&gt;
88ec22d3edb72 (Peter Zijlstra       2009-12-16 18:04:41 +0100 1139)             flags = ENQUEUE_WAKEUP;&lt;br /&gt;
bf0f6f24a1ece (Ingo Molnar          2007-07-09 18:51:58 +0200 1140)     }&lt;br /&gt;
8f4d37ec073c1 (Peter Zijlstra       2008-01-25 21:08:29 +0100 1141)&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1142)     for_each_sched_entity(se) {&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1143)             struct cfs_rq *cfs_rq = cfs_rq_of(se);&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1144)&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1145)             update_cfs_load(cfs_rq);&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1146)             update_cfs_shares(cfs_rq);&lt;/p&gt;

&lt;h1 id=&#34;wake-up&#34;&gt;Wake up&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lkml.org/lkml/2015/4/19/111&#34;&gt;sched: lockless wake-queues&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=-8c47dHuGIY&#34;&gt;Futex Scaling for Multi-core Systems&lt;/a&gt;&lt;a href=&#34;https://www.slideshare.net/davidlohr/futex-scaling-for-multicore-systems&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;program-order-guarantees&#34;&gt;Program-Order guarantees&lt;/h1&gt;

&lt;p&gt;commit 8643cda549ca49a403160892db68504569ac9052&lt;br /&gt;
Author: Peter Zijlstra &lt;a href=&#34;mailto:peterz@infradead.org&#34;&gt;peterz@infradead.org&lt;/a&gt;&lt;br /&gt;
Date:   Tue Nov 17 19:01:11 2015 +0100&lt;br /&gt;
    sched/core, locking: Document Program-Order guarantees&lt;/p&gt;

&lt;h2 id=&#34;lkml-discussions&#34;&gt;LKML discussions&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lkml.org/lkml/2015/11/2/311&#34;&gt;scheduler ordering bits&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lkml.org/lkml/2015/12/3/323&#34;&gt;scheduler ordering bits -v2&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;pi-lock&#34;&gt;pi_lock&lt;/h2&gt;

&lt;p&gt;commit b29739f902ee76a05493fb7d2303490fc75364f4&lt;br /&gt;
Author: Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
Date:   Tue Jun 27 02:54:51 2006 -0700&lt;br /&gt;
    [PATCH] pi-futex: scheduler support for pi&lt;br /&gt;
    Add framework to boost/unboost the priority of RT tasks.&lt;/p&gt;

&lt;h1 id=&#34;rq-lock-in-schedule-and-context-switch&#34;&gt;rq-&amp;gt;lock in schedule() and context_switch()&lt;/h1&gt;

&lt;p&gt;commit 3a5f5e488ceee9e08df3dff3f01b12fafc9e7e68&lt;br /&gt;
Author: Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
Date:   Fri Jul 14 00:24:27 2006 -0700&lt;br /&gt;
    [PATCH] lockdep: core, fix rq-lock handling on __ARCH_WANT_UNLOCKED_CTXSW&lt;br /&gt;
+        * Since the runqueue lock will be released by the next&lt;br /&gt;
+        * task&lt;/p&gt;

&lt;h1 id=&#34;etc&#34;&gt;ETC&lt;/h1&gt;

&lt;h2 id=&#34;the-wake-up-lost-problem&#34;&gt;the wake-up lost problem&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.linuxjournal.com/article/8144&#34;&gt;Kernel Korner - Sleeping in the Kernel&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;reordering-issue&#34;&gt;Reordering issue&lt;/h2&gt;

&lt;p&gt;CPU0:Process A&lt;br /&gt;
while(!done) {&lt;br /&gt;
        schedule();&lt;br /&gt;
        set_current_state = *interruptable;&lt;br /&gt;
}&lt;br /&gt;
CPU1: Process B&lt;br /&gt;
done = true;&lt;br /&gt;
wake_up_process(A);&lt;br /&gt;
Ordering issue: reorder load of done and store of state;&lt;br /&gt;
A: load of done&lt;br /&gt;
B: done = true&lt;br /&gt;
B: wake up&lt;br /&gt;
A: set state&lt;br /&gt;
A: schedule&lt;br /&gt;
Check bcbd94ff481ec1d7b5c824d90df82d0faafabd35&lt;br /&gt;
dm crypt: fix a possible hang due to race condition on exit&lt;/p&gt;

&lt;h2 id=&#34;pelt&#34;&gt;PELT&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/531853/&#34;&gt;Per-entity load tracking&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;running-time&#34;&gt;Running time&lt;/h1&gt;

&lt;p&gt;proc_sched_show_task&lt;/p&gt;

&lt;h1 id=&#34;problems&#34;&gt;Problems&lt;/h1&gt;

&lt;h2 id=&#34;why-scheduling&#34;&gt;Why scheduling?&lt;/h2&gt;

&lt;p&gt;Customers demand multitasking/concurrent&lt;br /&gt;
Processes are blocked&lt;/p&gt;

&lt;h2 id=&#34;fairness&#34;&gt;Fairness&lt;/h2&gt;

&lt;p&gt;Unit: /proc/sys/kernel/sched_min_granularity_ns&lt;/p&gt;

&lt;h1 id=&#34;conceptions&#34;&gt;Conceptions&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://android.googlesource.com/kernel/msm/+/android-msm-bullhead-3.10-marshmallow-dr/Documentation/scheduler/sched-hmp.txt&#34;&gt;Cpu capacity&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;running-compensator-records-the-running-process&#34;&gt;Running Compensator records the running process&lt;/h1&gt;

&lt;p&gt;scheduler_tick&lt;br /&gt;
{&lt;br /&gt;
    update_rq_clock&lt;br /&gt;
    task_tick_fair -&amp;gt; entity_tick&lt;br /&gt;
    {&lt;br /&gt;
        update_curr&lt;br /&gt;
        {&lt;br /&gt;
            sum_exec_runtime - total runtime&lt;br /&gt;
            cfs_rq-&amp;gt;exec_clock - cfs_rq runtime&lt;br /&gt;
            vruntime    - inverse proportion to the weight or priority&lt;br /&gt;
            update_min_vruntime&lt;br /&gt;
            {&lt;br /&gt;
                cfs_rq-&amp;gt;curr, leftmost, min_vruntime, who is min?&lt;br /&gt;
            }&lt;br /&gt;
            cpuacct - cpu sys/user time&lt;br /&gt;
        }&lt;br /&gt;
    }&lt;br /&gt;
}&lt;/p&gt;

&lt;h1 id=&#34;next-pick-next-task-fair&#34;&gt;Next -&amp;gt; pick_next_task_fair&lt;/h1&gt;

&lt;p&gt;put_prev_entity: update_curr; insert into rb-tree;&lt;br /&gt;
pick_next_entity: left most of rb-tree.&lt;br /&gt;
set_next_entity: remove next from tree since it will disturb inserting and deleting when it is being updated.&lt;/p&gt;

&lt;h1 id=&#34;unrunnable&#34;&gt;Unrunnable&lt;/h1&gt;

&lt;p&gt;dequeue_task&lt;/p&gt;

&lt;h1 id=&#34;resuming&#34;&gt;Resuming&lt;/h1&gt;

&lt;p&gt;try_to_wake_up-&amp;gt;ttwu_queue-&amp;gt;ttwu_do_activate-&amp;gt; or local wakeup: schedule-&amp;gt;try_to_wake_up_local-&amp;gt;&lt;br /&gt;
{&lt;br /&gt;
    ttwu_activate               #=== speical compensation and enqueue rq&lt;br /&gt;
    {&lt;br /&gt;
        activate_task&lt;br /&gt;
        p-&amp;gt;on_rq = TASK_ON_RQ_QUEUED    #=== 1) rq for task; 2)&lt;br /&gt;
    }&lt;br /&gt;
    ttwu_do_wakeup              #=== normal compensation&lt;br /&gt;
    {&lt;br /&gt;
        check_preempt_curr&lt;br /&gt;
        p-&amp;gt;state = TASK_RUNNING;&lt;br /&gt;
    }&lt;br /&gt;
}&lt;/p&gt;

&lt;p&gt;enqueue_task-&amp;gt; place_entity compensation for wakeup process&lt;/p&gt;

&lt;h2 id=&#34;wake-up-a-sleep-task&#34;&gt;wake up a sleep task&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;se-&amp;gt;on_rq &amp;amp; TASK_ON_RQ_QUEUED; deactivate_task set on_rq to 0;
enqueue_task_fair handles group stuff
enqueue_entity deals with sched_entity - uptodate the vruntime, load average, account load numa perfering,
sysctl_sched_latency: the cfs pledge to the pre-existing tasks that they have 6ms to run before new task to run.
try_to_wake_up_local for local task
try_to_wake_up for any task
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;new-task&#34;&gt;New task&lt;/h1&gt;

&lt;p&gt;speical debit compensation: sched_fork-&amp;gt;task_fork_fair-&amp;gt;place_entity - compensation for new process&lt;br /&gt;
normal compensation: wake_up_new_task&lt;br /&gt;
{&lt;br /&gt;
    activate_task               #=== speical compensation&lt;br /&gt;
    check_preempt_curr          #=== normal compensation&lt;br /&gt;
}&lt;/p&gt;

&lt;h1 id=&#34;priority&#34;&gt;Priority&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;weight&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;priority&lt;br /&gt;
DEFAULT_PRIO&lt;br /&gt;
fs/proc/array.c&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;latency-1&#34;&gt;Latency&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;sched_nr_latency= /proc/sys/kernel/sched_latency_ns / /proc/sys/kernel/sched_min_granularity_ns&lt;br /&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;if running process &amp;gt; sched_nr_latency, latency cannot be ensured. just focus on min granularity&lt;/p&gt;

&lt;h2 id=&#34;lqo-1&#34;&gt;LQO&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;is the difference of leftmost and rightmost smaller than sched_min_granularity_ns??&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;sched_slice&lt;/p&gt;

&lt;h1 id=&#34;energy&#34;&gt;Energy&lt;/h1&gt;

&lt;p&gt;blocked &amp;amp; schedule&lt;br /&gt;
check preempt &amp;amp; schedule&lt;br /&gt;
check_preempt_tick              # new preempts curr&lt;br /&gt;
{&lt;br /&gt;
curr running time &amp;gt; sched_slice     # enough time to yield.&lt;br /&gt;
curr - leftmost &amp;gt; sched_slice       # nice to others.&lt;br /&gt;
}&lt;br /&gt;
check_preempt_wakeup                # the wakeuped preempts curr&lt;br /&gt;
{&lt;br /&gt;
curr - wakeuped &amp;gt; sysctl_sched_wakeup_granularity;  # pass the wakeup-preempt-delay&lt;br /&gt;
}&lt;/p&gt;

&lt;h1 id=&#34;io-wait&#34;&gt;io wait&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/342378/&#34;&gt;https://lwn.net/Articles/342378/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;load-avg&#34;&gt;Load avg&lt;/h1&gt;

&lt;p&gt;update_load&lt;em&gt;avg&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Load&#34;&gt;https://en.wikipedia.org/wiki/Load&lt;/a&gt;&lt;/em&gt;(computing)&lt;br /&gt;
Check External links&lt;br /&gt;
calc_load_fold_active&lt;br /&gt;
Etymology of avenrun: &lt;a href=&#34;https://elixir.bootlin.com/linux/v4.1/source/arch/s390/appldata/appldata_os.c&#34;&gt;average nr. of running processes during&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;lqo-2&#34;&gt;LQO&lt;/h1&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;h_nr_running and throttled&lt;br /&gt;
sched: Implement hierarchical task accounting for SCHED_OTHER - 953bfcd10e6f3697233e8e5128c611d275da39c1&lt;br /&gt;
&lt;a href=&#34;https://groups.google.com/forum/#!topic/linux.kernel/gRzxHclMy50&#34;&gt;https://groups.google.com/forum/#!topic/linux.kernel/gRzxHclMy50&lt;/a&gt;&lt;br /&gt;
&amp;lsquo;root&amp;rsquo;&lt;br /&gt;
\&lt;br /&gt;
&amp;lsquo;A&amp;rsquo;&lt;br /&gt;
/ \&lt;br /&gt;
t1 t2&lt;br /&gt;
root.nr_running := 2&lt;br /&gt;
root.h_nr_running := 2&lt;br /&gt;
Check enqueue_task_fair()&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;idle&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/scheduler/sched-arch.txt&#34;&gt;https://www.kernel.org/doc/Documentation/scheduler/sched-arch.txt&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/136065/&#34;&gt;improve SMP reschedule and idle routines&lt;/a&gt;&lt;br /&gt;
TIF_POLLING_NRFLAG -&amp;gt; Need-Resched-Flag?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;process migration&lt;br /&gt;
e761b7725234276a802322549cee5255305a0930&lt;br /&gt;
Introduce cpu_active_map and redo sched domain managment&lt;br /&gt;
When to migration&lt;br /&gt;
    sched_setaffinity __set_cpus_allowed_ptr manuly&lt;br /&gt;
    Selecting a new CPU during wak up a sleeper&lt;br /&gt;
    For balancing, selecting CPU during  wake up new process in _do_fork&lt;br /&gt;
    execve&amp;rsquo;s sched_exec&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;shceduler clock&lt;br /&gt;
rq-&amp;gt;clock is nano seconds?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;clock_task and wraps&lt;br /&gt;
fe44d62122829959e960bc699318d58966922a69&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;START_DEBIT&lt;br /&gt;
no standalone commit&lt;br /&gt;
bf0f6f24a1ece8988b243aefe84ee613099a9245&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;why ahead?&lt;br /&gt;
8 /*&lt;br /&gt;
9  * Place new tasks ahead so that they do not starve already running&lt;br /&gt;
10  * tasks&lt;br /&gt;
11  */&lt;br /&gt;
12 SCHED_FEAT(START_DEBIT, true)&lt;br /&gt;
the tree is named timeline&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lwn.net/Articles/404993/&#34;&gt;Improving scheduler latency &lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;skip next last buddy&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;git-log&#34;&gt;Git log&lt;/h1&gt;

&lt;p&gt;e9c8431185d6c406887190519f6dbdd112641686&lt;br /&gt;
TASK_WAKING; see migrate_task_rq_fair and try_to_wake_up&lt;br /&gt;
88ec22d3edb72b261f8628226cd543589a6d5e1b&lt;br /&gt;
In order to remove the cfs_rq dependency from set_task_cpu() we need to ensure the task is cfs_rq invariant for all callsites.&lt;br /&gt;
2f950354e6d535b892f133d20bd6a8b09430424c&lt;br /&gt;
sched/fair: Fix fairness issue on migration&lt;br /&gt;
&lt;a href=&#34;http://linux.kernel.narkive.com/p15Wmn0i/migrated-cfs-task-getting-an-unfair-advantage&#34;&gt;Migrated CFS task getting an unfair advantage&lt;/a&gt;&lt;br /&gt;
30cfdcfc5f180fc21a3dad6ae3b7b2a9ee112186&lt;br /&gt;
curr was not kept in rb-tree&lt;/p&gt;

&lt;h1 id=&#34;load-balancing&#34;&gt;Load balancing&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/80911/&#34;&gt;Scheduling domains&lt;/a&gt;&lt;br /&gt;
set sd&lt;br /&gt;
kernel_init_freeable-&amp;gt;&lt;br /&gt;
sched_init_smp-&amp;gt;&lt;br /&gt;
init_sched_domains-&amp;gt;build_sched_domains:-&amp;gt;&lt;br /&gt;
&lt;strong&gt;visit_domain_allocation_hell()-&amp;gt;&lt;/strong&gt;sdt_alloc() alloc the sdd-&amp;gt;sg which is used by build groups&lt;br /&gt;
and sg = kzalloc_node(sizeof(struct sched_group) + cpumask_size(); it covered the size of cpumask&lt;br /&gt;
/* Build the groups for the domains */&lt;br /&gt;
detach_destroy_domains&lt;br /&gt;
cpu_attach_domain&lt;/p&gt;

&lt;p&gt;CONFIG_SCHED_MC=y&lt;br /&gt;
static noinline struct sched_domain *                                   &lt;br /&gt;
sd&lt;em&gt;init&lt;/em&gt;##type(struct sched_domain_topology_level *tl, int cpu)         &lt;br /&gt;
{                                                                       &lt;br /&gt;
        struct sched_domain *sd = *per_cpu&lt;em&gt;ptr(tl-&amp;gt;data.sd, cpu);       &lt;br /&gt;
        *sd = SD&lt;/em&gt;##type##_INIT;                                         &lt;br /&gt;
        SD_INIT_NAME(sd, type);                                         &lt;br /&gt;
        sd-&amp;gt;private = &amp;amp;tl-&amp;gt;data;                                        &lt;br /&gt;
        return sd;                                                      &lt;br /&gt;
}&lt;br /&gt;
tl-&amp;gt;mask(cpu)&lt;br /&gt;
static struct sched_domain_topology_level default_topology[] = {&lt;br /&gt;
#ifdef CONFIG_SCHED_SMT&lt;br /&gt;
        { sd_init_SIBLING, cpu_smt_mask, },&lt;br /&gt;
#endif&lt;br /&gt;
#ifdef CONFIG_SCHED_MC&lt;br /&gt;
        { sd_init_MC, cpu_coregroup_mask, },&lt;br /&gt;
#endif&lt;br /&gt;
#ifdef CONFIG_SCHED_BOOK&lt;br /&gt;
        { sd_init_BOOK, cpu_book_mask, },&lt;br /&gt;
#endif&lt;br /&gt;
        { sd_init_CPU, cpu_cpu_mask, },&lt;br /&gt;
        { NULL, },&lt;br /&gt;
};&lt;/p&gt;

&lt;h2 id=&#34;leaf-cfs-runqueues-leaf-cfs-rq&#34;&gt;Leaf CFS runqueues leaf_cfs_rq&lt;/h2&gt;

&lt;h3 id=&#34;first&#34;&gt;First&lt;/h3&gt;

&lt;p&gt;commit 6aa645ea5f7a246702e07f29edc7075d487ae4a3&lt;br /&gt;
Refs: v2.6.22-14-g6aa645ea5f7a&lt;br /&gt;
Author:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
AuthorDate: Mon Jul 9 18:51:58 2007 +0200&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
CommitDate: Mon Jul 9 18:51:58 2007 +0200&lt;br /&gt;
    sched: cfs rq data types&lt;br /&gt;
 * leaf cfs_rqs are those that hold tasks (lowest schedulable entity in&lt;br /&gt;
 * a hierarchy). Non-leaf lrqs hold other higher schedulable entities&lt;br /&gt;
 * (like users, containers etc.)&lt;br /&gt;
 * leaf_cfs_rq_list ties together list of leaf cfs_rq&amp;rsquo;s in a cpu. This&lt;br /&gt;
 * list is used during load balance.&lt;br /&gt;
Head of list: rq-&amp;gt;leaf_cfs_rq_list&lt;/p&gt;

&lt;h3 id=&#34;core-load-balance-fair&#34;&gt;Core load_balance_fair&lt;/h3&gt;

&lt;p&gt;commit bf0f6f24a1ece8988b243aefe84ee613099a9245&lt;br /&gt;
Refs: v2.6.22-10-gbf0f6f24a1ec&lt;br /&gt;
Author:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
AuthorDate: Mon Jul 9 18:51:58 2007 +0200&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
CommitDate: Mon Jul 9 18:51:58 2007 +0200&lt;br /&gt;
    sched: cfs core, kernel/sched_fair.c&lt;br /&gt;
    add kernel/sched_fair.c - which implements the bulk of CFS&amp;rsquo;s&lt;br /&gt;
    behavioral changes for SCHED_OTHER tasks.&lt;br /&gt;
+load_balance_fair(struct rq *this_rq, int this_cpu, struct rq *busiest,&lt;br /&gt;
+       for_each_leaf_cfs_rq(busiest, busy_cfs_rq) {&lt;/p&gt;

&lt;h3 id=&#34;make-parent-appear-after-us&#34;&gt;make parent appear after us.&lt;/h3&gt;

&lt;p&gt;commit 67e86250f8ea7b8f7da53ac25ea73c6bd71f5cd9&lt;br /&gt;
Author: Paul Turner &lt;a href=&#34;mailto:pjt@google.com&#34;&gt;pjt@google.com&lt;/a&gt;&lt;br /&gt;
Date:   Mon Nov 15 15:47:05 2010 -0800&lt;br /&gt;
    sched: Introduce hierarchal order on shares update list&lt;br /&gt;
    Avoid duplicate shares update calls by ensuring children always appear before                 # leaf&amp;rsquo;s meaning is changed&lt;br /&gt;
    parents in rq-&amp;gt;leaf_cfs_rq_list.&lt;br /&gt;
    This allows us to do a single in-order traversal for update_shares().&lt;br /&gt;
    Since we always enqueue in bottom-up order this reduces to 2 cases:&lt;br /&gt;
    1) Our parent is already in the list, e.g.&lt;br /&gt;
       root&lt;br /&gt;
         &lt;br /&gt;
          b&lt;br /&gt;
          /&lt;br /&gt;
          c d* (root-&amp;gt;b-&amp;gt;c already enqueued)&lt;br /&gt;
    Since d&amp;rsquo;s parent is enqueued we push it to the head of the list, implicitly ahead of b.&lt;br /&gt;
    2) Our parent does not appear in the list (or we have no parent)&lt;br /&gt;
    In this case we enqueue to the tail of the list, if our parent is subsequently enqueued&lt;br /&gt;
    (bottom-up) it will appear to our right by the same rule.&lt;/p&gt;

&lt;h3 id=&#34;tmp-alone-branch&#34;&gt;tmp_alone_branch&lt;/h3&gt;

&lt;p&gt;commit 9c2791f936ef5fd04a118b5c284f2c9a95f4a647&lt;br /&gt;
Refs: v4.9-rc5-195-g9c2791f936ef&lt;br /&gt;
Author:     Vincent Guittot &lt;a href=&#34;mailto:vincent.guittot@linaro.org&#34;&gt;vincent.guittot@linaro.org&lt;/a&gt;&lt;br /&gt;
AuthorDate: Tue Nov 8 10:53:43 2016 +0100&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@kernel.org&#34;&gt;mingo@kernel.org&lt;/a&gt;&lt;br /&gt;
CommitDate: Wed Nov 16 10:29:08 2016 +0100&lt;br /&gt;
    sched/fair: Fix hierarchical order in rq-&amp;gt;leaf_cfs_rq_list&lt;br /&gt;
    Fix the insertion of cfs_rq in rq-&amp;gt;leaf_cfs_rq_list to ensure that a&lt;br /&gt;
    child will always be called before its parent.&lt;br /&gt;
    The hierarchical order in shares update list has been introduced by&lt;br /&gt;
    commit:&lt;br /&gt;
      67e86250f8ea (&amp;ldquo;sched: Introduce hierarchal order on shares update list&amp;rdquo;)&lt;/p&gt;

&lt;p&gt;commit 5d299eabea5a251fbf66e8277704b874bbba92dc&lt;br /&gt;
Author: Peter Zijlstra &lt;a href=&#34;mailto:peterz@infradead.org&#34;&gt;peterz@infradead.org&lt;/a&gt;&lt;br /&gt;
Date:   Wed Jan 30 14:41:04 2019 +0100&lt;br /&gt;
    sched/fair: Add tmp_alone_branch assertion&lt;br /&gt;
    The magic in list_add_leaf_cfs_rq() requires that at the end of&lt;br /&gt;
    enqueue_task_fair():&lt;br /&gt;
      rq-&amp;gt;tmp_alone_branch == &amp;amp;rq-&amp;gt;lead_cfs_rq_list&lt;/p&gt;

&lt;h3 id=&#34;load-balance-fair-removed&#34;&gt;load_balance_fair - removed&lt;/h3&gt;

&lt;p&gt;commit 9763b67fb9f3050c6da739105888327587c30c4d&lt;br /&gt;
Refs: v3.0-rc7-197-g9763b67fb9f3&lt;br /&gt;
Author:     Peter Zijlstra &lt;a href=&#34;mailto:a.p.zijlstra@chello.nl&#34;&gt;a.p.zijlstra@chello.nl&lt;/a&gt;&lt;br /&gt;
AuthorDate: Wed Jul 13 13:09:25 2011 +0200&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
CommitDate: Thu Jul 21 18:01:46 2011 +0200&lt;br /&gt;
    sched, cgroup: Optimize load_balance_fair()&lt;br /&gt;
    Use for_each_leaf_cfs_rq() instead of list_for_each_entry_rcu(), this&lt;br /&gt;
    achieves that load_balance_fair() only iterates those task_groups that&lt;br /&gt;
    actually have tasks on busiest, and that we iterate bottom-up, trying to&lt;br /&gt;
    move light groups before the heavier ones.&lt;/p&gt;

&lt;h1 id=&#34;throttling-entities&#34;&gt;Throttling entities&lt;/h1&gt;

&lt;p&gt;commit 85dac906bec3bb41bfaa7ccaa65c4706de5cfdf8&lt;br /&gt;
Author: Paul Turner &lt;a href=&#34;mailto:pjt@google.com&#34;&gt;pjt@google.com&lt;/a&gt;&lt;br /&gt;
Date:   Thu Jul 21 09:43:33 2011 -0700&lt;br /&gt;
    sched: Add support for throttling group entities&lt;br /&gt;
    Now that consumption is tracked (via update_curr()) we add support to throttle&lt;br /&gt;
    group entities (and their corresponding cfs_rqs) in the case where this is no&lt;br /&gt;
    run-time remaining.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>System booting</title>
      <link>http://firoyang.org/cs/boot/</link>
      <pubDate>Thu, 12 Nov 2015 00:00:00 UTC</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/boot/</guid>
      <description>

&lt;h1 id=&#34;kernel-boot-process&#34;&gt;kernel boot process&lt;/h1&gt;

&lt;p&gt;Documentation/x86/boot.txt&lt;br /&gt;
&lt;a href=&#34;https://manybutfinite.com/post/kernel-boot-process/&#34;&gt;The Kernel Boot Process&lt;/a&gt;&lt;br /&gt;
arch/x86/boot/header.S::start_of_setup&lt;br /&gt;
arch/x86/boot/main.c::main()&lt;br /&gt;
    arch/x86/boot/memory.c::detect_memory()&lt;br /&gt;
    arch/x86/boot/memory.c::detect_memory_e820() = boot_params.e820_entries&lt;br /&gt;
    arch/x86/boot/pm.c::go_to_protected_mode()&lt;br /&gt;
arch/x86/boot/pmjump.S::protected_mode_jump&lt;br /&gt;
arch/x86/kernel/compressed/head_64.S::startup_32&lt;br /&gt;
arch/x86/kernel/compressed/head_64.S::startup_64&lt;br /&gt;
arch/x86/kernel/head_64.S::startup_64&lt;br /&gt;
kernel/main.c::start_kernel()&lt;/p&gt;

&lt;h2 id=&#34;reloctaion-for-decompress&#34;&gt;Reloctaion for decompress&lt;/h2&gt;

&lt;p&gt;974f221c84b05b1dc2f5ea50dc16d2a9d1e95eda&lt;br /&gt;
x86/boot: Move compressed kernel to the end of the decompression buffer&lt;/p&gt;

&lt;h2 id=&#34;horrable-commit-description-on-phys-base&#34;&gt;Horrable commit description on phys_base&lt;/h2&gt;

&lt;p&gt;commit 1ab60e0f72f71ec54831e525a3e1154f1c092408&lt;br /&gt;
Author: Vivek Goyal &lt;a href=&#34;mailto:vgoyal@in.ibm.com&#34;&gt;vgoyal@in.ibm.com&lt;/a&gt;&lt;br /&gt;
Date:   Wed May 2 19:27:07 2007 +0200&lt;br /&gt;
    [PATCH] x86-64: Relocatable Kernel Support&lt;/p&gt;

&lt;h1 id=&#34;smp-boot&#34;&gt;SMP boot&lt;/h1&gt;

&lt;p&gt;Check SDM v3 BSP and AP Processors&lt;br /&gt;
BSP - boot strap processor； AP - application processor&lt;/p&gt;

&lt;h2 id=&#34;core-commit&#34;&gt;Core commit&lt;/h2&gt;

&lt;p&gt;setup_real_mode-&amp;gt; trampoline_header-&amp;gt;start = (u64) secondary_startup_64;&lt;br /&gt;
commit f37240f16bec91f15ce564515f70a6ca9715ce96&lt;br /&gt;
Author: Jarkko Sakkinen &lt;a href=&#34;mailto:jarkko.sakkinen@intel.com&#34;&gt;jarkko.sakkinen@intel.com&lt;/a&gt;&lt;br /&gt;
Date:   Tue May 8 21:22:43 2012 +0300&lt;br /&gt;
    x86, realmode: header for trampoline code&lt;/p&gt;

&lt;h2 id=&#34;bsp&#34;&gt;BSP&lt;/h2&gt;

&lt;h3 id=&#34;build-time-for-real-mode-header-in-arch-x86-realmode-rm-header-s&#34;&gt;Build time for real_mode_header in arch/x86/realmode/rm/header.S&lt;/h3&gt;

&lt;p&gt;In pasyms.h, git gud!&lt;br /&gt;
pa_trampoline_header = trampoline_header;&lt;br /&gt;
pa_trampoline_start = trampoline_start;&lt;br /&gt;
pa_startup_32 = startup_32;&lt;br /&gt;
pa_startup_64 = startup_64;&lt;/p&gt;

&lt;h3 id=&#34;early-init&#34;&gt;Early init&lt;/h3&gt;

&lt;p&gt;setup_real_mode-&amp;gt; trampoline_header-&amp;gt;start = (u64) secondary_startup_64;  # tr_start&lt;/p&gt;

&lt;h3 id=&#34;start-kernel&#34;&gt;start_kernel&lt;/h3&gt;

&lt;p&gt;kernel_init-&amp;gt;smp_init-&amp;gt;cpu_up-&amp;gt;do_cpu_up-&amp;gt;_cpu_up-&amp;gt;&lt;br /&gt;
ap hp threadfn -&amp;gt; bringup_cpu -&amp;gt; __cpu_up -&amp;gt; smp_ops.cpu_up(cpu, tidle) is native_cpu_up&lt;br /&gt;
        do_boot_cpu is the core function. It set up the code for APs to run and check cpu_callin_mask.&lt;br /&gt;
        start_eip = real_mode_header-&amp;gt;trampoline_start;&lt;br /&gt;
        initial_code = (unsigned long)start_secondary                   # initial_code&lt;/p&gt;

&lt;h2 id=&#34;ap&#34;&gt;AP&lt;/h2&gt;

&lt;p&gt;trampoline_start -&amp;gt; &amp;hellip; -&amp;gt; startup_64 -&amp;gt; tr_start(%rip) is secondary_startup_64 -&amp;gt; initial_code(%rip) is start_secondary&lt;br /&gt;
-&amp;gt; cpu_init&lt;/p&gt;

&lt;h1 id=&#34;normalize-cs&#34;&gt;Normalize %cs&lt;/h1&gt;

&lt;p&gt;程序的起始地址在链接脚本中被设置为 0，如果 setup 被加载到其他地方(起始地&lt;br /&gt;
址不为 0 的地方)，那么指令里面访问的全局符号都会有重定位的问题。由于 Boot Loader&lt;br /&gt;
跳转到上面这段代码的时候，把 DS 设置为 setup 加载的基地址，而第 17 行访问_end 默认&lt;br /&gt;
是用数据段寄存器 DS 的，所以不会有重定位的问题。但是在 38 行转移指令用的 CS 寄存器，&lt;br /&gt;
而符号 main 的地址是在链接期决定的，现在加载的基地址改变了，那肯定会出问题了。所&lt;br /&gt;
以事先在第 24 行把 CS 设置为和 DS 一样，这样就解决了重定位的问题了。代码的最后跳转&lt;br /&gt;
到了 arch/x86/boot/main.c 中的 main 函数中继续执行。&lt;/p&gt;

&lt;h1 id=&#34;print-with-int-0x10&#34;&gt;print with int $0x10&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com/questions/38041478/int-10h-not-working-in-qemu&#34;&gt;https://stackoverflow.com/questions/38041478/int-10h-not-working-in-qemu&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;a20&#34;&gt;A20&lt;/h1&gt;

&lt;p&gt;[Why enable A20 line in Protected Mode?][&lt;a href=&#34;https://stackoverflow.com/questions/33827474/why-enable-a20-line-in-protected-mode&#34;&gt;https://stackoverflow.com/questions/33827474/why-enable-a20-line-in-protected-mode&lt;/a&gt;]&lt;br /&gt;
This gate, (the A20 gate), is controlled by a GPIO pin on the keyboard controller IC. Thus, you need to enable it before going into protected mode. If you didn&amp;rsquo;t, (and say you flat-mapped all 4GB of physical memory), then as Micheal Petch indicated, &amp;ldquo;every odd numbered megabyte region will be inaccessible. So 1mb-2mb will actually reference 0-1mb, 3mb-4mb will reference 2mb-3mb etc.&amp;rdquo; See also:&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Computer architecture</title>
      <link>http://firoyang.org/cs/arch/</link>
      <pubDate>Tue, 13 Oct 2015 00:00:00 UTC</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/arch/</guid>
      <description>

&lt;p&gt;##Reference&lt;br /&gt;
&lt;a href=&#34;https://people.cs.clemson.edu/~mark/architects.html&#34;&gt;https://people.cs.clemson.edu/~mark/architects.html&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html&#34;&gt;Latency Numbers Every Programmer Should Know&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://youtu.be/cNN_tTXABUA&#34;&gt;How a CPU Works&lt;/a&gt;&lt;br /&gt;
A Symbolic Analysis of Relay and Switching Circuits&lt;br /&gt;
The Mathematical Theory of Communication&lt;br /&gt;
Given a symbol level, the architecture is the description of the system in&lt;br /&gt;
whatever system-description scheme exists next below the symbol level. - Newell, 1990, p. 81&lt;br /&gt;
&lt;a href=&#34;https://news.ycombinator.com/item?id=9844090&#34;&gt;Ask HN: How to learn about the history of computing?&lt;/a&gt;&lt;br /&gt;
《模拟电子技术基础 童诗白 第四版》第一章前半部分&lt;br /&gt;
Structured Computer Organization 6th Edition&lt;br /&gt;
Digital Design and Computer Architecture 2nd Edition&lt;br /&gt;
Computer Organization and Design 5th Edition&lt;br /&gt;
Write Great Code: Volume 1: Understanding the Machine&lt;br /&gt;
See MIPS run&lt;br /&gt;
Intel 64 and IA-32 architectures software developers manual combined volumes 3A, 3B, and 3C: System programming guide&lt;br /&gt;
Microelectronics&lt;/p&gt;

&lt;h1 id=&#34;definition&#34;&gt;Definition&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Architectural_state&#34;&gt;Architectural state&lt;/a&gt;&lt;br /&gt;
microarchitectural state, such as information stored in TLBs and caches&lt;/p&gt;

&lt;h2 id=&#34;isa&#34;&gt;ISA&lt;/h2&gt;

&lt;p&gt;model: 1570s, &amp;ldquo;likeness made to scale; architect&amp;rsquo;s set of designs,&amp;rdquo; from Middle French modelle&lt;br /&gt;
Semantics in computer science: In programming language theory, semantics is the field concerned&lt;br /&gt;
with the rigorous mathematical study of the meaning of programming languages.&lt;br /&gt;
Language primitive&lt;br /&gt;
ISA: memory model, registers, data types, instructions, word size(?).&lt;br /&gt;
Memory model: unit of address resolution, word, aligment, address space, addressing mode, memory barrier/memory order primitive&amp;rsquo;s semantics.&lt;/p&gt;

&lt;h1 id=&#34;i-o-ic&#34;&gt;I/O IC&lt;/h1&gt;

&lt;p&gt;serial communication: UART(16550) + RS-232&lt;br /&gt;
parallel communication: SCSI, ISA, ATA, PCI, FSB&lt;/p&gt;

&lt;h1 id=&#34;data-struct-aligment&#34;&gt;Data struct aligment&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://pzemtsov.github.io/2016/11/06/bug-story-alignment-on-x86.html&#34;&gt;A bug story: data alignment on x86&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.catb.org/esr/structure-packing/&#34;&gt;The Lost Art of C Structure Packing&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://en.wikipedia.org/wiki/Data_structure_alignment#Typical_alignment_of_C_structs_on_x86&#34;&gt;Typical alignment of C structs on x86&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;为什么需要结构体对齐&#34;&gt;为什么需要结构体对齐?&lt;/h2&gt;

&lt;p&gt;struct foo {&lt;br /&gt;
char c;&lt;br /&gt;
int i;};&lt;br /&gt;
如果是32位, cpu 一次取4byte a word 数据.&lt;br /&gt;
如果我们把i的前3byte和c存到一起, 剩下1byte of i自己单独存.&lt;br /&gt;
那么我们访问i这个数据就要读两个4byte a word. 对cpu来说性能损耗.&lt;br /&gt;
如果我们把i单独放到4byte 对齐的地址, 那么我们只需要一次cpu读取.fast!&lt;/p&gt;

&lt;h2 id=&#34;产生非对齐访问的场景&#34;&gt;产生非对齐访问的场景&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Casting variables to types of different lengths, 比如char * 到int *&lt;br /&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pointer arithmetic followed by access to at least 2 bytes of data , 不太理解.&lt;/p&gt;

&lt;h2 id=&#34;我们做什么&#34;&gt;我们做什么?&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;什么也不干, 按默认对齐来Natural alignment&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;为了不影响性能, 同时减少内存使用, 编程时最好显示reorder.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;get/put_unaligned  to avoid analigned access.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过attribute aligned指定对齐要求.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;数据要在不同体系, 32/64之间使用, 比如网络,写到disk, 我们必须要attribute packed&lt;br /&gt;
也就是说不对齐, 不同平台对齐可能不同, 我们不能让数据corruption.&lt;/p&gt;

&lt;h2 id=&#34;如果数据不对齐有什么-cpu怎么办&#34;&gt;如果数据不对齐有什么, cpu怎么办?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/unaligned-memory-access.txt&#34;&gt;必读UNALIGNED MEMORY ACCESSES&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果用了packed, 编译器会生成extra代码阻止非对齐访问, performance loss.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cpu呢? 可能正确处理raise a exception to fix it with performance loss.&lt;/p&gt;

&lt;h2 id=&#34;calculate-the-sizeof-of-aligned-c-struct&#34;&gt;Calculate the sizeof of aligned c struct&lt;/h2&gt;

&lt;p&gt;Data alignment means putting the data at a memory address equal to some multiple of the word size,&lt;br /&gt;
which increases the system&amp;rsquo;s performance due to the way the CPU handles memory.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;find the widest scalar member and attribute( aligned(x)) to determin alignment.&lt;br /&gt;
找到结构体内scalar和attribute最大的对齐要求.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;fill the member to alignement without wrap&lt;br /&gt;
把结构的成员一次填满对齐宽度, 不够的填到下个对齐宽度, 空出来留着padding&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pading to alignment&lt;br /&gt;
填上所有空.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;endianess-and-bitfield&#34;&gt;Endianess and bitfield&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://gcc.gnu.org/onlinedocs/gcc/Structures-unions-enumerations-and-bit-fields-implementation.html&#34;&gt;The order of allocation of bit-fields within a unit&lt;/a&gt;&lt;br /&gt;
It&amp;rsquo;s Determined by ABI not Gcc. Check comments on &lt;a href=&#34;https://stackoverflow.com/questions/47600584/bitfield-endianness-in-gcc&#34;&gt;Bitfield endianness in gcc&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;how-endianness-effects-bitfield-packing-http-mjfrazer-org-mjfrazer-bitfields&#34;&gt;&lt;a href=&#34;http://mjfrazer.org/mjfrazer/bitfields/&#34;&gt;How Endianness Effects Bitfield Packing&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;if defined(__LITTLE_ENDIAN_BITFIELD)&lt;br /&gt;
    __u8    ihl:4,&lt;br /&gt;
        version:4;  # MSB, check wikipeida ipv4 header&lt;/p&gt;

&lt;h2 id=&#34;gcc-bug-on-bitfield&#34;&gt;GCC bug on bitfield&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/478657/&#34;&gt;Betrayed by a bitfield&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Algorithms and data structues</title>
      <link>http://firoyang.org/cs/algorithm/</link>
      <pubDate>Wed, 27 May 2015 12:42:12 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/algorithm/</guid>
      <description>

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://cstheory.stackexchange.com/questions/19759/core-algorithms-deployed#&#34;&gt;Core algorithms deployed&lt;/a&gt;&lt;br /&gt;
Algorithms: Design Techniques and Analysis&lt;br /&gt;
The Algorithm Design Manual 2nd Edition&lt;/p&gt;

&lt;h1 id=&#34;leetcode&#34;&gt;Leetcode&lt;/h1&gt;

&lt;h2 id=&#34;1p3c&#34;&gt;1p3c&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.1point3acres.com/bbs/thread-270312-1-1.html&#34;&gt;http://www.1point3acres.com/bbs/thread-270312-1-1.html&lt;/a&gt;&lt;br /&gt;
最终我觉得像word search12， word break12，word ladder12，LIS，sort color，LRU，insert &amp;amp; delete in O1，rob house123，234sum这种题要达到闭眼秒杀的程度，min/max heap，bucket sort，topological sort，binary pre/in/post/level 遍历，combination/permutation这种东西要做梦都梦到&lt;br /&gt;
最后祝lz好运，加油~&lt;/p&gt;

&lt;h2 id=&#34;why-do-we-have-to-solve-leetcode-problems&#34;&gt;Why do we have to solve leetcode problems?&lt;/h2&gt;

&lt;p&gt;尤其是在北美，Google，Facebook，Microsoft，Amazon 等等大公司，无一不考刷题，以算法面试为主。而无论是北美留学生，还是工作几年的上班族，想进大公司，唯一的出路就是刷题。&lt;br /&gt;
&lt;a href=&#34;https://cspiration.com/leetcodeClassification&#34;&gt;Leetcode 分类顺序表第二版&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;computational-complexity-theory&#34;&gt;Computational complexity theory&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://bigocheatsheet.com/&#34;&gt;http://bigocheatsheet.com/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;core-conceptions&#34;&gt;Core conceptions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;representations&lt;br /&gt;
&lt;a href=&#34;https://www.geeksforgeeks.org/binary-tree-array-implementation/&#34;&gt;Linked vs sequential&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;ADT vs data structure&lt;br /&gt;
ADT is a data type defined by its behavior.&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Data_type#Abstract_data_types&#34;&gt;Any type that does not specify an implementation is an abstract data type.&lt;/a&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;linked-list&#34;&gt;Linked list&lt;/h1&gt;

&lt;h2 id=&#34;static-linked-list&#34;&gt;Static linked list&lt;/h2&gt;

&lt;p&gt;Reprented in an array.&lt;/p&gt;

&lt;h2 id=&#34;internal-vs-external-liked&#34;&gt;Internal vs external liked&lt;/h2&gt;

&lt;p&gt;Sometimes, SLUB put freelist in object&lt;/p&gt;

&lt;h2 id=&#34;kernel-doubly-linked-list-operations&#34;&gt;kernel doubly linked list operations&lt;/h2&gt;

&lt;h3 id=&#34;add&#34;&gt;add&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;kernel version&lt;br /&gt;
next-&amp;gt;prev = new;&lt;br /&gt;
new-&amp;gt;next = next;&lt;br /&gt;
new-&amp;gt;prev = prev;&lt;br /&gt;
prev-&amp;gt;next = new;&lt;/p&gt;

&lt;h3 id=&#34;delete&#34;&gt;delete&lt;/h3&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kernel version&lt;br /&gt;
next-&amp;gt;prev = prev;&lt;br /&gt;
WRITE_ONCE(prev-&amp;gt;next, next);&lt;br /&gt;
entry-&amp;gt;next = LIST_POISON1;&lt;br /&gt;
entry-&amp;gt;prev = LIST_POISON2;&lt;/p&gt;

&lt;h1 id=&#34;bl-list&#34;&gt;BL list&lt;/h1&gt;

&lt;p&gt;kernel: add bl_list - 4e35e6070b1ceed89c3bba2af4216c286fb1dafd&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;double-linked-list&#34;&gt;Double linked list&lt;/h1&gt;

&lt;h1 id=&#34;associative-array&#34;&gt;Associative array&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=qTZJLJ3Gm6Q&#34;&gt;Essentials: Brian Kernighan on Associative Arrays - Computerphile&lt;/a&gt;&lt;br /&gt;
vs indexed array&lt;/p&gt;

&lt;h2 id=&#34;associativity&#34;&gt;Associativity&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;trade-off&lt;br /&gt;
a) Checking more places takes more power and chip area,&lt;br /&gt;
b) and potentially more time. On the other hand, caches with more associativity suffer fewer misses&lt;br /&gt;
fully associative - the best miss rates, but practical only for a small number of entries&lt;br /&gt;
N-way set associative cache: 8 is a common choice for later implementations&lt;br /&gt;
direct-mapped cache - if two locations map to the same entry, they may continually knock each other out. anti-fragmantion worsens this case.&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;judy-array&#34;&gt;Judy array&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://judy.sourceforge.net/&#34;&gt;http://judy.sourceforge.net/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;hashtable&#34;&gt;Hashtable&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/510202/&#34;&gt;A generic hash table&lt;/a&gt;&lt;br /&gt;
hash function&lt;/p&gt;

&lt;h1 id=&#34;bst&#34;&gt;BST&lt;/h1&gt;

&lt;p&gt;Pre-order&lt;br /&gt;
In-order traversal&lt;br /&gt;
Post-order&lt;br /&gt;
postfix and prefix and sort&lt;/p&gt;

&lt;h1 id=&#34;graph&#34;&gt;Graph&lt;/h1&gt;

&lt;h1 id=&#34;depth-first-sarch&#34;&gt;Depth first sarch&lt;/h1&gt;

&lt;p&gt;DAG&lt;/p&gt;

&lt;h1 id=&#34;interval-tree-in-kernel&#34;&gt;Interval tree in kernel&lt;/h1&gt;

&lt;p&gt;anonymous page: anon_vma_interval_tree_insert&lt;/p&gt;

&lt;h1 id=&#34;trie&#34;&gt;Trie&lt;/h1&gt;

&lt;p&gt;Trie is prefix tree.&lt;br /&gt;
Trees only store keys.&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=AXjmTQ8LEoI&#34;&gt;Trie Data Structure&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=MC-iQHFdEDI&#34;&gt;Trie with numeric key&lt;/a&gt;&lt;br /&gt;
* terms very confused&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/14708134/what-is-the-difference-between-trie-and-radix-trie-data-structures&#34;&gt;Radix tree vs Trie, check radix meaning&lt;/a&gt;&lt;br /&gt;
Patricia is compact trie or Patricia is radix = 2 trie?&lt;/p&gt;

&lt;h1 id=&#34;radix-tree-in-kernel-not-wikipedia&#34;&gt;Radix tree in kernel not wikipedia&lt;/h1&gt;

&lt;p&gt;page cache: page_cache_tree_insert&lt;br /&gt;
Wikipedia: Radix tree looks like a compact trie.&lt;br /&gt;
Kernel: Radix tree was more like a Multi-level index associative arrya or judy array.&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/175432/&#34;&gt;Trees I: Radix trees&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://events17.linuxfoundation.org/sites/events/files/slides/LinuxConNA2016%20-%20Radix%20Tree.pdf&#34;&gt;Enhancing the Linux Radix Tree&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=v0C9_Fp-co4&#34;&gt;The design and implementation of the XArray&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/688130/&#34;&gt;A multi-order radix tree&lt;/a&gt;&lt;br /&gt;
radix_tree_init_maxnodes(): height is 11 in kernel?&lt;br /&gt;
&lt;strong&gt;radix_tree_create() add one page&lt;/strong&gt;&lt;br /&gt;
radix_tree_lookup_slot: find one page&lt;/p&gt;

&lt;h1 id=&#34;search&#34;&gt;Search&lt;/h1&gt;

&lt;p&gt;Data property: unique key, indexed&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Search_data_structure&#34;&gt;Search data structure&lt;/a&gt;&lt;br /&gt;
Sequencial array: binary search&lt;br /&gt;
Associative array&lt;br /&gt;
BST&lt;br /&gt;
Hashtable&lt;/p&gt;

&lt;h2 id=&#34;which-algorithm&#34;&gt;Which algorithm?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.geeksforgeeks.org/advantages-of-bst-over-hash-table/&#34;&gt;Advantages of BST over Hash Table&lt;/a&gt;&lt;br /&gt;
1. Can get all keys in sorted order  by just doing in-order traversal of BST&lt;br /&gt;
2. Doing order statistics, finding closest lower and greater elements, doing range  queries  are easy to do with BSTs.&lt;br /&gt;
3. BSTs are easy to implement compared to hashing.&lt;br /&gt;
4. With Self Balancing BSTs, all operations are guarnateed to work in O(logN) time.&lt;/p&gt;

&lt;h1 id=&#34;replacement-polices&#34;&gt;Replacement polices&lt;/h1&gt;

&lt;p&gt;Pseudo-LRU&lt;/p&gt;

&lt;h1 id=&#34;lru&#34;&gt;LRU&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://leetcode.com/problems/lru-cache/description/&#34;&gt;Leetcode 146 LRU cache&lt;/a&gt;&lt;br /&gt;
Order items by access times&lt;/p&gt;

&lt;h2 id=&#34;pseudo-lru-2-second-chance-and-queue&#34;&gt;Pseudo LRU/2 - Second chance and queue&lt;/h2&gt;

&lt;p&gt;type: Reclaim&lt;br /&gt;
Order items by enqueueing sequence&lt;br /&gt;
dcache&lt;/p&gt;

&lt;h2 id=&#34;second-chance-and-2q-https-pdfs-semanticscholar-org-d62d-e5f995164fff50f5ce61c0113f6bc9f04225-pdf&#34;&gt;Second chance and &lt;a href=&#34;https://pdfs.semanticscholar.org/d62d/e5f995164fff50f5ce61c0113f6bc9f04225.pdf&#34;&gt;2Q&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Page reclaim algorithm&lt;br /&gt;
type: Reclaim&lt;/p&gt;

&lt;h1 id=&#34;ring-buffer-or-circular-buffer&#34;&gt;Ring buffer or Circular buffer&lt;/h1&gt;

&lt;h1 id=&#34;redblack-tree&#34;&gt;Redblack tree&lt;/h1&gt;

&lt;p&gt;gap between linar node can be optimized by argument rb tree. O(n) -&amp;gt; O(log n)&lt;br /&gt;
mm: augment vma rbtree with rb_subtree_gap d37371870ceb1d2165397dc36114725b6dca946c&lt;br /&gt;
&lt;a href=&#34;http://sidsen.azurewebsites.net//papers/rb-trees-talg.pdf&#34;&gt;Rank-Balanced Trees&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://leetcode.com/problems/count-of-smaller-numbers-after-self/description/&#34;&gt;https://leetcode.com/problems/count-of-smaller-numbers-after-self/description/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://yuex.in/post/2017/08/red-black-tree-in-action.html&#34;&gt;http://yuex.in/post/2017/08/red-black-tree-in-action.html&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cs.princeton.edu/~rs/talks/LLRB/08Dagstuhl/RedBlack.pdf&#34;&gt;Left-Leaning Red-Black Trees&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;history&#34;&gt;History&lt;/h2&gt;

&lt;p&gt;AVL tree, B-tree, symmetric binary B-tree or 2–3–4 tree, red–black tree&lt;br /&gt;
&lt;a href=&#34;https://www.cs.purdue.edu/homes/ayg/CS251/slides/chap13b.pdf&#34;&gt;2-3-4 Trees and RedBlack Trees&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Computing Sorcery a sorcerer&#39;s perspective on computer science</title>
      <link>http://firoyang.org/cs/cs/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:14 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/cs/</guid>
      <description>

&lt;h1 id=&#34;computer-science&#34;&gt;Computer science&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://computersciencewiki.org/index.php/Computational_thinking_%26_problem-solving&#34;&gt;Firo: very good CS website: Computational thinking &amp;amp; problem-solving&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://computersciencewiki.org/index.php/Welcome&#34;&gt;Core topics of computer science&lt;/a&gt;&lt;br /&gt;
Underlying our approach to this subject is our conviction that “computer science” is not a science and that its significance has little to do with computers. The computer revolution is a revolution in the way we think and in the way we express what we think. The essence of this change is the emergence of what might best be called procedural epistemology —the study of the structure of knowledge from an imperative point of view, as opposed to the more declarative point of view taken by classical mathematical subjects. Mathematics provides a framework for dealing precisely with notions of “what is.” Computation provides a framework for dealing precisely with notions of “how to.”  &amp;ndash; The omnipotent SICP&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=lL4wg6ZAFIM&#34;&gt;Richard Feynman on Computer Science — Talk at Bell Labs (1985)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://plato.stanford.edu/entries/computer-science/&#34;&gt;The Philosophy of Computer Science&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;specifications-and-books&#34;&gt;Specifications and books&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://refspecs.linuxbase.org/&#34;&gt;Linux Foundation Referenced Specifications&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;os&#34;&gt;OS&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://pages.cs.wisc.edu/~remzi/OSTEP/&#34;&gt;Operating Systems: Three Easy Pieces&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;history&#34;&gt;History&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.chilton-computing.org.uk/acl/technology/atlas/overview.htm&#34;&gt;Atlas&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;unix&#34;&gt;Unix&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://users.soe.ucsc.edu/~sbrandt/221/Papers/History/thompson-bstj78.pdf&#34;&gt;Ken Thompson UNIX Implementation&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cs.grinnell.edu/~curtsinger/teaching/2019S/CSC213/files/unix_evolution.pdf&#34;&gt;The Evolution of the UNIX Time-sharing System&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.oreilly.com/openbook/opensources/book/kirkmck.html&#34;&gt;Twenty Years of Berkeley Unix From AT&amp;amp;T-Owned to Freely Redistributable&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://people.eecs.berkeley.edu/~brewer/cs262/unix.pdf&#34;&gt;The UNIX TimeSharing System Dennis M. Ritchie and Ken Thompson Bell Laboratories&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.bell-labs.com/usr/dmr/www/retro.pdf&#34;&gt;The UNIX Time-sharing SystemA Retrospective&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://bitsavers.trailing-edge.com/pdf/sun/sunos/&#34;&gt;SunOS 1.0 - 4.1.2&lt;/a&gt;&lt;br /&gt;
Life with Unix&lt;br /&gt;
&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.9119&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;Design and Implementation of the Berkeley Virtual Memory Extensions to the UNIX† Operating System‡&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;problems&#34;&gt;Problems&lt;/h1&gt;

&lt;p&gt;Concurrency&lt;br /&gt;
VM&lt;br /&gt;
IO&lt;br /&gt;
Memory hierarchy&lt;br /&gt;
Resource management&lt;br /&gt;
Latency&lt;br /&gt;
Scalibity&lt;/p&gt;

&lt;h2 id=&#34;etc&#34;&gt;ETC&lt;/h2&gt;

&lt;p&gt;performance/efficiency&lt;br /&gt;
Easy to use&lt;br /&gt;
Security/Protection/isolation&lt;br /&gt;
Reliability&lt;br /&gt;
Energy-efficiency&lt;/p&gt;

&lt;h1 id=&#34;concurrency&#34;&gt;Concurrency&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cs.utexas.edu/users/EWD/transcriptions/EWD01xx/EWD123.html&#34;&gt;Firo: must thinking summary: EW Dijkstra: Cooperating sequential processes&lt;/a&gt;&lt;br /&gt;
CSAPP3e: Chapter 12 concurrent programming&lt;br /&gt;
Parallel and Concurrent Programming in Haskell&lt;br /&gt;
The origin of concurrent programming: from semaphores to remote procedure calls - Per Brinch Hansen&lt;br /&gt;
&lt;a href=&#34;https://www.dcl.hpi.uni-potsdam.de/teaching/pvprog/Slides/C1_concurrency.pdf&#34;&gt;Firo: good introduction on history of concurrency: Shared-Memory Concurrency&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=2771951&#34;&gt;Turing lecture: The computer science of concurrency: the early years&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/355700/&#34;&gt;Firo: example: Concurrency-managed workqueues&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;concurrent-vs-parallel&#34;&gt;concurrent vs parallel&lt;/h2&gt;

&lt;p&gt;Programming vs computing: software vs hardware&lt;br /&gt;
concurrent programming: multi-thread stress on how to create thread to model the outside world.&lt;br /&gt;
parallel programming: smp, synchronization, lock, lock-free, atomic&lt;br /&gt;
&lt;a href=&#34;http://highscalability.com/blog/2014/12/31/linus-the-whole-parallel-computing-is-the-future-is-a-bunch.html&#34;&gt;Linus: The Whole &amp;ldquo;Parallel Computing Is The Future&amp;rdquo; Is A Bunch Of Crock.&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.realworldtech.com/forum/?threadid=146066&amp;amp;curpostid=146227&#34;&gt;Linus: Avoiding ping pong&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;concurrency-problem-1-with-communications&#34;&gt;Concurrency problem 1 with communications&lt;/h2&gt;

&lt;p&gt;IPC check wait.log&lt;/p&gt;

&lt;h2 id=&#34;prblem-2-with-memory&#34;&gt;Prblem 2 with memory&lt;/h2&gt;

&lt;p&gt;consistency model&lt;/p&gt;

&lt;h1 id=&#34;resource-management&#34;&gt;Resource management&lt;/h1&gt;

&lt;h2 id=&#34;garbage-collection&#34;&gt;Garbage collection&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=2473932&#34;&gt;Linus Torvalds on Garbage Collection (2002)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://yarchive.net/comp/linux/reference_counting.html&#34;&gt;Linus on refrence counting&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.3800&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;Paul E. McKenney: Overview of Linux-Kernel Reference Counting&lt;/a&gt;&lt;br /&gt;
Book: The Garbage Collection Handbook&lt;br /&gt;
Book: Japanese GC book.&lt;br /&gt;
&lt;a href=&#34;https://www.linuxidc.com/Linux/2015-01/111565.htm&#34;&gt;https://www.linuxidc.com/Linux/2015-01/111565.htm&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;reference-counting&#34;&gt;Reference counting&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/565734/&#34;&gt;Introducing lockrefs&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;memory-hierarchy&#34;&gt;Memory hierarchy&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>The art of debugging</title>
      <link>http://firoyang.org/cs/debugging/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:14 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/debugging/</guid>
      <description>

&lt;h1 id=&#34;quote&#34;&gt;Quote&lt;/h1&gt;

&lt;p&gt;Everyone knows that debugging is twice as hard as writing a program in the first place. So if you&amp;rsquo;re as clever as you can be when you write it, how will you ever debug it?&lt;br /&gt;
&amp;ldquo;The Elements of Programming Style&amp;rdquo;, 2nd edition, chapter 2. Brian Kernighan&lt;/p&gt;

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;Debug hacks: a book on how to debug.&lt;/p&gt;

&lt;h1 id=&#34;bug-classifications&#34;&gt;Bug classifications&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Software_bug#Types&#34;&gt;Software bug types&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://cwe.mitre.org/data/definitions/1000.html&#34;&gt;CWE VIEW: Research Concepts&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://cwe.mitre.org/data/definitions/1003.html&#34;&gt;CWE VIEW: Simplified Mapping&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://cwe.mitre.org/data/definitions/699.html&#34;&gt;CWE VIEW: Development Concepts&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;hardware-bugs&#34;&gt;Hardware Bugs&lt;/h2&gt;

&lt;p&gt;If this has only happened on a single physical machine, I suggest that machine be considered to be faulty.&lt;/p&gt;

&lt;h2 id=&#34;memory-corruption&#34;&gt;Memory corruption&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://cwe.mitre.org/data/definitions/119.html&#34;&gt;The generic term &amp;ldquo;memory corruption&amp;rdquo;&lt;/a&gt;is often used to describe the consequences of writing to memory outside the bounds of a buffer, when the root cause is something other than a sequential copies of excessive data from a fixed starting location(i.e., classic buffer overflows or CWE-120). This may include issues such as incorrect pointer arithmetic, accessing invalid pointers due to incomplete initialization or memory release, etc.]&lt;br /&gt;
&lt;a href=&#34;https://bugzilla.suse.com/show_bug.cgi?id=1155930#c12&#34;&gt;An example by Neil Brown: The corrupted list of inodes could be due to one inode being freed and re-used while still on the list - or it could be due to memory corruption of a forward pointer.&lt;/a&gt;&lt;br /&gt;
Memory corruption is one of the most intractable class of programming errors, for two reasons:&lt;br /&gt;
The source of the memory corruption and its manifestation may be far apart, making it hard to correlate the cause and the effect.&lt;br /&gt;
Symptoms appear under unusual conditions, making it hard to consistently reproduce the error.&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Memory_corruption&#34;&gt;Memory corruption&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Memory_safety&#34;&gt;Memory safety&lt;/a&gt;&lt;br /&gt;
uninitialized memory: &lt;a href=&#34;https://en.wikipedia.org/wiki/Dangling_pointer#Cause_of_wild_pointers&#34;&gt;wild pointer&lt;/a&gt;&lt;br /&gt;
use after free: &lt;a href=&#34;https://en.wikipedia.org/wiki/Dangling_pointer#Cause_of_dangling_pointers&#34;&gt;dangling pointer&lt;/a&gt;&lt;br /&gt;
buffer overflow:&lt;br /&gt;
unknown source memory corruption: The generic &amp;ldquo;memory corruption&amp;rdquo;.&lt;br /&gt;
memory leak:&lt;/p&gt;

&lt;h3 id=&#34;phonomenon&#34;&gt;Phonomenon&lt;/h3&gt;

&lt;p&gt;Invalid page fault(including NULL pointer dereference)&lt;/p&gt;

&lt;h1 id=&#34;debugging&#34;&gt;Debugging&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Abductive_reasoning#Logic-based_abduction&#34;&gt;Abductive reasoning&lt;/a&gt;&lt;br /&gt;
Every bug belons to a known type.&lt;/p&gt;

&lt;h2 id=&#34;steps-according-to-observations-narrow-down-hypothses-successive-approximation&#34;&gt;Steps according to observations, narrow down Hypothses, successive approximation&lt;/h2&gt;

&lt;p&gt;Scientific method&lt;/p&gt;

&lt;h2 id=&#34;get-observations-and-analysis-data&#34;&gt;Get observations and analysis data&lt;/h2&gt;

&lt;p&gt;observation.log&lt;br /&gt;
Data: whole structure, list corruption;life cycle; which part is ok and which part is wrong, Data connections&lt;br /&gt;
call paths: related&lt;/p&gt;

&lt;h2 id=&#34;think-backward&#34;&gt;Think backward&lt;/h2&gt;

&lt;p&gt;How far from symptom to root cause could we think?&lt;br /&gt;
Missing cause:&lt;/p&gt;

&lt;h2 id=&#34;known-bug-types-assumptions&#34;&gt;Known bug types assumptions&lt;/h2&gt;

&lt;p&gt;Mix up Bug types, observations and related all paths&lt;/p&gt;

&lt;h2 id=&#34;connect-to-programming-skills&#34;&gt;Connect to programming skills.&lt;/h2&gt;

&lt;h1 id=&#34;anti-debugging&#34;&gt;Anti-debugging&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Syntax checking&lt;br /&gt;
gcc -Wall&lt;br /&gt;
bash -n&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;static code analysis&lt;br /&gt;
smatch&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The art of programming</title>
      <link>http://firoyang.org/cs/programming/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:14 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/programming/</guid>
      <description>

&lt;h1 id=&#34;basic-conceptions&#34;&gt;Basic conceptions&lt;/h1&gt;

&lt;p&gt;Reentrancy&lt;/p&gt;

&lt;h1 id=&#34;cps&#34;&gt;CPS&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://spin.atomicobject.com/2012/11/01/hey-c-is-a-functional-language-too/&#34;&gt;https://spin.atomicobject.com/2012/11/01/hey-c-is-a-functional-language-too/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Direct_style&#34;&gt;https://en.wikipedia.org/wiki/Direct_style&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Category:Programming_principles&#34;&gt;Programming principles&lt;/a&gt;&lt;br /&gt;
programming principles&lt;br /&gt;
High cohesion low coupling&lt;/p&gt;

&lt;h1 id=&#34;design-pattern&#34;&gt;Design pattern&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://lwn.net/Articles/336224/&#34;&gt;Linux kernel design patterns&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.cs.fsu.edu/~baker/devices/notes/patterns.html#&#34;&gt;Linux Kernel Programming Patterns&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;ipc&#34;&gt;IPC&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cyberiapc.com/os/ipc_whatisit.htm&#34;&gt;Busy waiting vs blocking&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;computer-programming&#34;&gt;Computer programming&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cs.princeton.edu/~bwk/tpop.webpage/&#34;&gt;The practice of programming&lt;/a&gt;, &lt;a href=&#34;http://www.ccs.neu.edu/home/matthias/HtDP2e/&#34;&gt;How to design programs&lt;/a&gt;, &lt;a href=&#34;http://sarabander.github.io/sicp/&#34;&gt;SICP&lt;/a&gt;, and Elements of programming.&lt;/p&gt;

&lt;h2 id=&#34;procedure-and-subroutine&#34;&gt;Procedure and Subroutine&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Link_register&#34;&gt;https://en.wikipedia.org/wiki/Link_register&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://link.springer.com/article/10.1007%2FBF01386232&#34;&gt;Dijkstra, E. W. (1960). &amp;ldquo;Recursive Programming&amp;rdquo;&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://people.cs.clemson.edu/~mark/subroutines.html&#34;&gt;Subroutine and procedure call support&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://people.cs.clemson.edu/~mark/subroutines.html&#34;&gt;https://people.cs.clemson.edu/~mark/subroutines.html&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Subroutine&#34;&gt;https://en.wikipedia.org/wiki/Subroutine&lt;/a&gt;&lt;br /&gt;
* 1945 Turing on subroutines in &lt;a href=&#34;http://www.alanturing.net/turing_archive/archive/p/p01/P01-011.html&#34;&gt;Proposed electronic calculator.&lt;/a&gt;&lt;br /&gt;
In Chapter 6. Outline of Logical Control.&lt;br /&gt;
We also wish to be able to arrange for the splitting up of operations into&amp;hellip;&lt;br /&gt;
When we wish to start on a subsidiary operation we need only make a note&lt;br /&gt;
of where we left off the major operation&amp;hellip;&lt;br /&gt;
* 1952 &lt;a href=&#34;http://www.laputan.org/pub/papers/wheeler.pdf&#34;&gt;The use of sub-routines in programmes&lt;/a&gt;&lt;br /&gt;
The above remarks may be summarized by saying sub-routines are very useful — although not absolutely necessary — and that the prime objectives to be born     in mind when constructing them are simplicity of use, correctness of codes and accuracy of description. All complexities should—if possible—be buried out of sight.&lt;/p&gt;

&lt;h1 id=&#34;files-sytle&#34;&gt;Files sytle&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lists.kernelnewbies.org/pipermail/kernelnewbies/2012-March/004986.html&#34;&gt;kernel asm/asm-generic&lt;/a&gt;&lt;br /&gt;
asm stands for arch specific macros(FIXME).&lt;/p&gt;

&lt;h1 id=&#34;coding-style&#34;&gt;Coding style&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.gnu.org/prep/standards/standards.html&#34;&gt;GNU Coding Standards&lt;/a&gt;&lt;br /&gt;
比如GNU coding standards, Linux kernel coding style, Shell coding standard&lt;br /&gt;
* Label&lt;br /&gt;
It is considered to be safer that the label reflect what happens at the&lt;br /&gt;
destination, and not the reason for reaching the label. &amp;ndash;Julia&lt;/p&gt;

&lt;h1 id=&#34;verification-and-validation&#34;&gt;Verification and validation&lt;/h1&gt;

&lt;p&gt;抽象的知识来自生活经验的总结, 所以学习抽象知识的重要方向是从实践不断总结抽象.&lt;br /&gt;
programming is a goal-oriented activity&lt;br /&gt;
14.4&lt;br /&gt;
Before attempting to solve a problem, make absolutely sure you  what the problem is.&lt;br /&gt;
14.5&lt;br /&gt;
Before developing a program, make precise and refine the pre/postcondition.&lt;br /&gt;
program -&amp;gt;&lt;br /&gt;
{Q} S {R}: predicte, formal notation&lt;br /&gt;
Q: input asseration&lt;br /&gt;
R: output asseration&lt;br /&gt;
predictes -&amp;gt; asseration&lt;br /&gt;
asseration: a predicate placed in a program is called an asseration.&lt;br /&gt;
Proof outline: a program together with an asseration between each pair of statements&lt;br /&gt;
Program specification ⊃ excution ∪ speed ∪ size&lt;br /&gt;
Instances: summation, squre root approximation, sorting&lt;br /&gt;
command-comment ⊃ all input ∪ output&lt;/p&gt;

&lt;h1 id=&#34;lock-free-programming&#34;&gt;Lock-free programming&lt;/h1&gt;

&lt;p&gt;ring buffer, rcu&lt;/p&gt;

&lt;h1 id=&#34;testing&#34;&gt;Testing&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://googletesting.blogspot.com/&#34;&gt;Google testing blog&lt;/a&gt;&lt;br /&gt;
1.Black-box testing test software function.&lt;br /&gt;
2.White-box testing test software internal logic.&lt;/p&gt;

&lt;h1 id=&#34;good-taste&#34;&gt;Good taste&lt;/h1&gt;

&lt;p&gt;remove_list_entry(entry)&lt;br /&gt;
{&lt;br /&gt;
  // The &amp;ldquo;indirect&amp;rdquo; pointer points to the&lt;br /&gt;
  // &lt;em&gt;address&lt;/em&gt; of the thing we&amp;rsquo;ll update&lt;br /&gt;
  indirect = &amp;head;&lt;/p&gt;

&lt;p&gt;// Walk the list, looking for the thing that&lt;br /&gt;
  // points to the entry we want to remove&lt;/p&gt;

&lt;p&gt;while ((*indirect) != entry)&lt;br /&gt;
    indirect = &amp;amp;(*indirect)-&amp;gt;next;&lt;/p&gt;

&lt;p&gt;// .. and just remove it&lt;br /&gt;
  *indirect = entry-&amp;gt;next;&lt;br /&gt;
}&lt;/p&gt;

&lt;p&gt;remove_list_entry(entry)&lt;br /&gt;
{&lt;br /&gt;
  prev = NULL;&lt;br /&gt;
  walk = head;&lt;/p&gt;

&lt;p&gt;// Walk the list&lt;/p&gt;

&lt;p&gt;while (walk != entry) {&lt;br /&gt;
    prev = walk;&lt;br /&gt;
    walk = walk-&amp;gt;next;&lt;br /&gt;
  }&lt;/p&gt;

&lt;p&gt;// Remove the entry by updating the&lt;br /&gt;
  // head or the previous entry&lt;/p&gt;

&lt;p&gt;if (!prev)&lt;br /&gt;
    head = entry-&amp;gt;next;&lt;br /&gt;
  else&lt;br /&gt;
    prev-&amp;gt;head = entry-&amp;gt;next;&lt;br /&gt;
}&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The computing processes</title>
      <link>http://firoyang.org/cs/task_/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:12 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/task_/</guid>
      <description>

&lt;h1 id=&#34;formal-cause&#34;&gt;Formal cause&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://courses.cs.vt.edu/cs5204/fall09-kafura/Presentations/Threads-VS-Events.pdf&#34;&gt;thread vs event&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;pid&#34;&gt;PID&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/606925/&#34;&gt;PIDTYPE_PID&lt;/a&gt;&lt;br /&gt;
task-&amp;gt;pid: thread id: unique&lt;br /&gt;
task-&amp;gt;tgid: task group id: child thread share parent&amp;rsquo;s tgid&lt;br /&gt;
Check copy_process&lt;/p&gt;

&lt;h1 id=&#34;kthread-kernel-thread&#34;&gt;kthread - Kernel thread&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/vm/active_mm.txt&#34;&gt;active_mm&lt;/a&gt;&lt;br /&gt;
kernel_thead-&amp;gt;kthread-&amp;gt;do_exit&lt;br /&gt;
#define PF_KTHREAD              0x00200000&lt;br /&gt;
#define PF_KSWAPD               0x00020000&lt;br /&gt;
#define PF_IDLE                 0x00000002      /* I am an IDLE thread &lt;em&gt;/&lt;br /&gt;
#define PF_VCPU                 0x00000010      /&lt;/em&gt; I&amp;rsquo;m a virtual CPU &lt;em&gt;/&lt;br /&gt;
#define PF_WQ_WORKER            0x00000020      /&lt;/em&gt; I&amp;rsquo;m a workqueue worker */&lt;br /&gt;
PID: 197    TASK: ffff8bc8dd350480  CPU: 0   COMMAND: &amp;ldquo;kswapd0&amp;rdquo;&lt;br /&gt;
  flags = 0xa20840,&lt;br /&gt;
PID: 19     TASK: ffff8bc214160780  CPU: 1   COMMAND: &amp;ldquo;kworker/1:0H&amp;rdquo;&lt;br /&gt;
  flags = 0x4208060,&lt;br /&gt;
crash&amp;gt; task -R flags&lt;br /&gt;
PID: 0      TASK: ffffffff880134c0  CPU: 0   COMMAND: &amp;ldquo;swapper/0&amp;rdquo;&lt;br /&gt;
  flags = 0x200102,&lt;br /&gt;
PID: 0      TASK: ffff8bc21476c500  CPU: 14  COMMAND: &amp;ldquo;swapper/14&amp;rdquo;&lt;br /&gt;
  flags = 0x200042,&lt;/p&gt;

&lt;h2 id=&#34;task-kthread&#34;&gt;task =&amp;gt; kthread&lt;/h2&gt;

&lt;p&gt;to_kthread and vfork_done&lt;br /&gt;
commit 63706172f332fd3f6e7458ebfb35fa6de9c21dc5&lt;br /&gt;
Author: Oleg Nesterov &lt;a href=&#34;mailto:oleg@redhat.com&#34;&gt;oleg@redhat.com&lt;/a&gt;&lt;br /&gt;
Date:   Wed Jun 17 16:27:45 2009 -0700&lt;/p&gt;

&lt;h2 id=&#34;kthread-and-worker&#34;&gt;kthread and worker&lt;/h2&gt;

&lt;p&gt;kthread-&amp;gt;data&lt;/p&gt;

&lt;h2 id=&#34;worker-is-rescuer&#34;&gt;worker is rescuer?&lt;/h2&gt;

&lt;p&gt;current_is_workqueue_rescuer and worker-&amp;gt;rescue_wq&lt;/p&gt;

&lt;h1 id=&#34;insepct-process-status&#34;&gt;Insepct process status&lt;/h1&gt;

&lt;p&gt;do_task_stat&lt;br /&gt;
Kernel mapping: tgid_base_stuff show_map_vma&lt;/p&gt;

&lt;h1 id=&#34;protection&#34;&gt;Protection&lt;/h1&gt;

&lt;p&gt;3A: Chaper 5&lt;/p&gt;

&lt;h2 id=&#34;idle-kernel-stack&#34;&gt;idle kernel stack&lt;/h2&gt;

&lt;p&gt;master idle进程的kernel stack在init/init_task.c:init_thread_union&lt;br /&gt;
this_cpu_write(kernel_stack,(unsigned long)task_stack_page(next_p) +THREAD_SIZE);&lt;br /&gt;
this_cpu_write(cpu_current_top_of_stack,(unsigned long)task_stack_page(next_p) +THREAD_SIZE);&lt;br /&gt;
主处理器上的idle由原始进程(pid=0)演变而来。从处理器上的idle由init进程fork得到，但是它们的pid都为0 init_idle.&lt;/p&gt;

&lt;h1 id=&#34;zombie-process-defunct&#34;&gt;Zombie process &lt;defunct&gt;&lt;/h1&gt;

&lt;p&gt;forked child not reaped by parent will hooked in process list.&lt;br /&gt;
if parent was killed and exit &lt;defunct&gt; will repaped.&lt;/p&gt;

&lt;h1 id=&#34;context-switch&#34;&gt;Context switch&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.maizure.org/projects/evolution_x86_context_switch_linux/index.html&#34;&gt;Evolution of the x86 context switch in Linux&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/520227/&#34;&gt;Al Viro&amp;rsquo;s new execve/kernel_thread design&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;call-jump-ret-0100301bfdf56a2a370c7157b5ab0fbf9313e1cd&#34;&gt;call+jump+ret - 0100301bfdf56a2a370c7157b5ab0fbf9313e1cd&lt;/h2&gt;

&lt;p&gt;((last) = __switch_to_asm((prev), (next)));                             #=====&amp;gt; call&lt;br /&gt;
jmp     __switch_to                                                     #=====&amp;gt; jmp + ret&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/15019986/why-does-switch-to-use-pushjmpret-to-change-eip-instead-of-jmp-directly/15024312&#34;&gt;Why does switch_to use push+jmp+ret to change EIP, instead of jmp directly?&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;wait-example&#34;&gt;Wait example&lt;/h1&gt;

&lt;p&gt;#6 [ffff883f15637c90] proc_evict_inode at ffffffff812696fd&lt;br /&gt;
 #7 [ffff883f15637ca0] evict at ffffffff8121cded&lt;br /&gt;
 #8 [ffff883f15637cc0] __dentry_kill at ffffffff812194b6&lt;br /&gt;
 #9 [ffff883f15637ce0] shrink_dentry_list at ffffffff8121a0c0&lt;br /&gt;
#10 [ffff883f15637d10] d_invalidate at ffffffff8121a8c8&lt;br /&gt;
#11 [ffff883f15637d50] proc_flush_task at ffffffff8126e609&lt;br /&gt;
#12 [ffff883f15637dc0] release_task at ffffffff81081230&lt;br /&gt;
                        # wait_task_zombie&lt;br /&gt;
#13 [ffff883f15637e18] wait_consider_task at ffffffff81081c19&lt;br /&gt;
#14 [ffff883f15637e80] do_wait at ffffffff8108226d&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
