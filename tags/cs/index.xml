<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Cs on f(x) </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://firoyang.org/tags/cs/</link>
    <language>en-us</language>
    <author>Firo Yang</author>
    
    <updated>Wed, 02 Jan 2019 00:00:00 UTC</updated>
    
    <item>
      <title>Kernel memory bug - SLAB&#39;s 3 lists are corrupted.</title>
      <link>http://firoyang.org/howto/bug_mm_1/</link>
      <pubDate>Wed, 02 Jan 2019 00:00:00 UTC</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/howto/bug_mm_1/</guid>
      <description>

&lt;p&gt;Recently, I was working on a kernel memory bug.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://apibugzilla.suse.com/show_bug.cgi?id=1118875&#34;&gt;https://apibugzilla.suse.com/show_bug.cgi?id=1118875&lt;/a&gt;&lt;br /&gt;
L3: kernel BUG at ../mm/slab.c:2804! bad LRU list and active values in page structs in possible use-after-free&lt;/p&gt;

&lt;p&gt;After digging the binary vmcore file of kdump, I got the following findings.&lt;/p&gt;

&lt;h1 id=&#34;node-0&#34;&gt;Node 0&lt;/h1&gt;

&lt;h2 id=&#34;partial&#34;&gt;Partial&lt;/h2&gt;

&lt;p&gt;list page.lru  -H 0xffff8801a7c01348 -s page.lru,s_mem,active,slab_cache,flags &amp;gt;n0p.log&lt;br /&gt;
n0p -&amp;gt; n0f=0xffff8801a7c01358&lt;/p&gt;

&lt;h2 id=&#34;full&#34;&gt;Full&lt;/h2&gt;

&lt;p&gt;list page.lru  -H 0xffff8801a7c01358 -s page.lru,s_mem,active,slab_cache,flags &amp;gt;n0f.log&lt;br /&gt;
n0f -&amp;gt;&lt;br /&gt;
ffffea0006902380&lt;br /&gt;
    lru = {&lt;br /&gt;
      next = 0xffffea0080ed53e0,&lt;br /&gt;
      prev = 0xffffea00405f8ae0&lt;br /&gt;
    }&lt;br /&gt;
    s_mem = 0xffff8801a408e000&lt;br /&gt;
      active = 16&lt;br /&gt;
    slab_cache = 0xffff8801a7c00400&lt;br /&gt;
  flags = 6755398367314048&lt;br /&gt;
ffffea0080ed53c0&lt;br /&gt;
    lru = {&lt;br /&gt;
      next = 0xffffea00422a34e0,&lt;br /&gt;
      prev = 0xffffea00069023a0&lt;br /&gt;
    }&lt;br /&gt;
    s_mem = 0xffff88203b54f000&lt;br /&gt;
      active = 7&lt;br /&gt;
    slab_cache = 0xffff8801a7c00400&lt;br /&gt;
  flags = 24769796876796032&lt;br /&gt;
&amp;hellip; -&amp;gt; n1f = 0xffff881107c00358&lt;/p&gt;

&lt;h1 id=&#34;node-1&#34;&gt;Node 1&lt;/h1&gt;

&lt;h2 id=&#34;partial-1&#34;&gt;Partial&lt;/h2&gt;

&lt;p&gt;crash&amp;gt; list page.lru  -H 0xffff881107c00348 -s page.lru,s_mem,active,slab_cache,flags &amp;gt;n1p.log&lt;br /&gt;
nip-&amp;gt; SLAB ffffea0043ab74e0 -&amp;gt; 0xffff881107c00348 = n1p&lt;br /&gt;
SLAB ffffea0043ab74e0&amp;rsquo;s prev pointing to 0xffff881107c00358&lt;/p&gt;

&lt;h2 id=&#34;full-1&#34;&gt;Full&lt;/h2&gt;

&lt;p&gt;crash&amp;gt; list page.lru  -H 0xffff881107c00358 -s page.lru,s_mem,active,slab_cache,flags &amp;gt;n1f.log&lt;br /&gt;
n1f-&amp;gt; SLAB ffffea0043ab74e0  -&amp;gt; &amp;hellip; -&amp;gt; 0xffff881107c00348 = n1p&lt;/p&gt;

&lt;p&gt;This issue occured on a NUMA system with 2 memory nodes.&lt;br /&gt;
Both node 0 and node 1&amp;rsquo;s SLAB&amp;rsquo;s partial and full lists were corrupted. After looking into this issue a few days, I talked to Vlastimil Babka.&lt;br /&gt;
He provided a fix for this issue. That is 7810e6781e0fcbca78b91cf65053f895bf59e85f - mm, page_alloc: do not break __ GFP_THISNODE by zonelist reset.&lt;/p&gt;

&lt;p&gt;Now, I have a question: why did I cannot solve this issue?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Memory consistency model</title>
      <link>http://firoyang.org/cs/consistency_model/</link>
      <pubDate>Sat, 16 Dec 2017 15:46:12 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/consistency_model/</guid>
      <description>

&lt;p&gt;When we are talking on memory model, we are refering memory consistency model or memory ordering model.&lt;/p&gt;

&lt;h1 id=&#34;hisotry&#34;&gt;Hisotry&lt;/h1&gt;

&lt;p&gt;1979&lt;br /&gt;
&lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2016/12/How-to-Make-a-Multiprocessor-Computer-That-Correctly-Executes-Multiprocess-Programs.pdf&#34;&gt;How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Progranm&lt;/a&gt;&lt;br /&gt;
1987 ~ 1990&lt;br /&gt;
&lt;a href=&#34;https://cs.brown.edu/~mph/HerlihyW90/p463-herlihy.pdf&#34;&gt;Linearizability: A Correctness Condition for Concurrent Objects&lt;/a&gt;&lt;br /&gt;
1989&lt;br /&gt;
&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.3766&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;processor consistency: CACHE CONSISTENCY AND SEQUENTIAL CONSISTENCY&lt;/a&gt;&lt;br /&gt;
1990&lt;br /&gt;
&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=325102&#34;&gt;Release consistency: Memory consistency and event ordering in scalable shared-memory multiprocessors&lt;/a&gt;&lt;br /&gt;
1991&lt;br /&gt;
&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=113406&#34;&gt;Proving sequential consistency of high-performance shared memories&lt;/a&gt;&lt;br /&gt;
1992&lt;br /&gt;
&lt;a href=&#34;https://www.gaisler.com/doc/sparcv8.pdf&#34;&gt;TSO Sparc v8: A standard memory model called Total Store Ordering (TSO) is defined for SPARC&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-1-4615-3604-8_2&#34;&gt;Formal Specification of Memory Models: and two store ordered models TSO and PSO defined by the Sun Microsystem&amp;rsquo;s SPARC architecture.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2001 ~ Present&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=WUfvvFD5tAA&#34;&gt;IA64 memory ordering&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;purposes&#34;&gt;Purposes&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/lectures/14_relaxedReview.pdf&#34;&gt;Motivation: hiding latency&lt;/a&gt;&lt;br /&gt;
▪ Why are we interested in relaxing ordering requirements?&lt;br /&gt;
- Performance&lt;br /&gt;
- Speci!cally, hiding memory latency: overlap memory accesses with other operations&lt;br /&gt;
- Remember, memory access in a cache coherent system may entail much more then&lt;br /&gt;
simply reading bits from memory (!nding data, sending invalidations, etc.)&lt;/p&gt;

&lt;h2 id=&#34;why-tso-it-s-because-that-write-buffer-or-store-buffer-is-not-invisible-any-more-for-multiprocessor-https-www-cis-upenn-edu-devietti-classes-cis601-spring2016-sc-tso-pdf&#34;&gt;Why TSO? &lt;a href=&#34;https://www.cis.upenn.edu/~devietti/classes/cis601-spring2016/sc_tso.pdf&#34;&gt;It&amp;rsquo;s because that write buffer or Store buffer is not invisible any more for multiprocessor&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;To abandon SC; to Allow use of a FIFO write buffer.&lt;br /&gt;
&lt;a href=&#34;https://www.cs.utexas.edu/~bornholt/post/memory-models.html&#34;&gt;An example: There’s no reason why performing event (2) (a read from B) needs to wait until event (1) (a write to A) completes. They don’t interfere with each other at all, and so should be allowed to run in parallel. See Memory Consistency Models: A Primer&lt;/a&gt;&lt;br /&gt;
Hide the write latency by putting the data in the store buffer.&lt;/p&gt;

&lt;h3 id=&#34;why-not-read-write-reordering&#34;&gt;Why not read-write reordering?&lt;/h3&gt;

&lt;p&gt;reordering read-write is non-sense.&lt;/p&gt;

&lt;h1 id=&#34;formal-cause&#34;&gt;Formal cause&lt;/h1&gt;

&lt;p&gt;Shared memory&lt;br /&gt;
Multiprocessor&lt;br /&gt;
Memory access&lt;br /&gt;
program order&lt;br /&gt;
&lt;a href=&#34;https://www.hpl.hp.com/techreports/Compaq-DEC/WRL-95-7.pdf&#34;&gt;Recommened by CAAQA: Observity in SC, TSO, PC: Paragraph Relaxing the Write to Read Program Order in Shared Memory Consistency Models: A Tutorial&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf&#34;&gt;Memory Barriers: a Hardware View for Software Hackers - must read&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://15418.courses.cs.cmu.edu/spring2013/article/41&#34;&gt;&amp;lsquo;A Summary of Relaxed Consistency&amp;rsquo; CMU&lt;/a&gt;&lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/lectures/14_relaxedReview.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;sc&#34;&gt;SC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2016/12/How-to-Make-a-Multiprocessor-Computer-That-Correctly-Executes-Multiprocess-Programs.pdf&#34;&gt;sequential consistency&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://jepsen.io/consistency/models/sequential#formally&#34;&gt;Formal of Sequential Consistency by Jepsen&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;tso&#34;&gt;TSO&lt;/h2&gt;

&lt;p&gt;Total Store Ordering in Appendix k Sparc v8.&lt;/p&gt;

&lt;h3 id=&#34;tso-in-x86&#34;&gt;TSO in x86&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cl.cam.ac.uk/~pes20/weakmemory/x86tso-paper.tphols.pdf&#34;&gt;A Better x86 Memory Model: x86-TSO&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/27595595/when-are-x86-lfence-sfence-and-mfence-instructions-required&#34;&gt;When are x86 LFENCE, SFENCE and MFENCE instructions required?&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;tso-vs-pc&#34;&gt;TSO vs PC:&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://15418.courses.cs.cmu.edu/spring2013/article/41&#34;&gt;&amp;lsquo;A Summary of Relaxed Consistency&amp;rsquo; CMU&lt;/a&gt;&lt;a href=&#34;https://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/lectures/14_relaxedReview.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;tso-and-peterson-s-algorithm&#34;&gt;TSO and Peterson&amp;rsquo;s algorithm&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://bartoszmilewski.com/2008/11/05/who-ordered-memory-fences-on-an-x86/&#34;&gt;Who ordered memory fences on an x86?&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cnblogs.com/caidi/p/6708789.html&#34;&gt;共同进入与饥饿&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;pc&#34;&gt;PC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.3766&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;processor consistency: CACHE CONSISTENCY AND SEQUENTIAL CONSISTENCY&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;wc&#34;&gt;WC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~kubitron/cs252/handouts/oldquiz/p434-dubois.pdf&#34;&gt;weak consistency: Memory access buffering in multiprocessors&lt;/a&gt;&lt;br /&gt;
They distinguish between ordinary shared accesses and synchronization accesses, where the latter are used to control concurrency&lt;br /&gt;
between several processes and to maintain the integrity of ordinary shared data.&lt;/p&gt;

&lt;h2 id=&#34;rc&#34;&gt;RC&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=325102&#34;&gt;Firo: a must-read: Release consistency: Memory consistency and event ordering in scalable shared-memory multiprocessors&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://docs.microsoft.com/en-us/windows/win32/dxtecharts/lockless-programming?redirectedfrom=MSDN#read-acquire-and-write-release-barriers&#34;&gt;Must-read: Lockless Programming Considerations for Xbox 360 and Microsoft Windows&lt;/a&gt;&lt;br /&gt;
At right top of page 6&lt;br /&gt;
Condition 3.1: Conditions for Release Consistency&lt;br /&gt;
(A) before an ordinary load or store access is allowed to perform with respect to any other processor,&lt;br /&gt;
all previous acquire accesses must be performed, and&lt;br /&gt;
(B) before a release access is allowed to perform with&lt;br /&gt;
respect to any other processor, all previous ordinary&lt;br /&gt;
load and store accesses must be performed, and&lt;br /&gt;
&amp;copy; special accesses are processor consistent with respect to one another.&lt;br /&gt;
&lt;a href=&#34;https://preshing.com/20120913/acquire-and-release-semantics/&#34;&gt;Acquire and Release Semantics&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://marc.info/?l=linux-kernel&amp;amp;m=151844394031510&amp;amp;w=2&#34;&gt;mm/page_ref: use atomic_set_release in page_ref_unfreeze&lt;/a&gt;&lt;br /&gt;
commit 7088efa9137a15d7d21e3abce73e40c9c8a18d68&lt;br /&gt;
Refs: v4.15-rc1-4-g7088efa9137a&lt;br /&gt;
Author:     Paul E. McKenney &lt;a href=&#34;mailto:paulmck@linux.vnet.ibm.com&#34;&gt;paulmck@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
AuthorDate: Mon Oct 9 10:04:27 2017 -0700&lt;br /&gt;
Commit:     Paul E. McKenney &lt;a href=&#34;mailto:paulmck@linux.vnet.ibm.com&#34;&gt;paulmck@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
CommitDate: Mon Dec 4 10:52:52 2017 -0800&lt;br /&gt;
    fs/dcache: Use release-acquire for name/length update&lt;/p&gt;

&lt;h2 id=&#34;kernel&#34;&gt;Kernel&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/memory-barriers.txt&#34;&gt;Why do we need mb for SLEEP AND WAKE-UP FUNCTIONS?&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/718628/&#34;&gt;A formal kernel memory-ordering model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/720550/&#34;&gt;A formal kernel memory-ordering model (part 2)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4374.html&#34;&gt;Linux-Kernel Memory Model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0124r4.html&#34;&gt;Linux-Kernel Memory Model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0124r6.html&#34;&gt;Linux-Kernel Memory Model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://events.linuxfoundation.org/sites/events/files/slides/LinuxMM.2016.09.19a.LCE_.pdf&#34;&gt;Linux-Kernel Memory Ordering: Help Arrives At Last!&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/watch?v=ULFytshTvIY&#34;&gt;Talk on youtube on this!&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;compiler&#34;&gt;Compiler&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://preshing.com/20120625/memory-ordering-at-compile-time/&#34;&gt;Memory Ordering at Compile Time&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://blog.regehr.org/archives/232&#34;&gt;A Guide to Undefined Behavior in C and C++, Part 3&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;other-architectures&#34;&gt;Other architectures&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cl.cam.ac.uk/~pes20/weakmemory/&#34;&gt;Relaxed-Memory Concurrency&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;c11-library-memory-model&#34;&gt;C11(library) memory model&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://en.cppreference.com/w/c/atomic/memory_order&#34;&gt;C memory order&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cl.cam.ac.uk/~pes20/cpp/notes42.html&#34;&gt;Don&amp;rsquo;t read: The Thin-air Problem&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42967.pdf&#34;&gt;Outlawing Ghosts: Avoiding Out-of-Thin-Air Results&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4375.html&#34;&gt;Out-of-Thin-Air Execution is Vacuous&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;material&#34;&gt;Material&lt;/h1&gt;

&lt;h2 id=&#34;practices&#34;&gt;Practices&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://preshing.com/20120515/memory-reordering-caught-in-the-act/&#34;&gt;Memory Reordering Caught in the Act&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;lqo&#34;&gt;LQO&lt;/h2&gt;

&lt;p&gt;134 static void sysrq_handle_crash(int key)&lt;br /&gt;
 135 {&lt;br /&gt;
 136         char &lt;em&gt;killer = NULL;&lt;br /&gt;
 137&lt;br /&gt;
 138         /&lt;/em&gt; we need to release the RCU read lock here,&lt;br /&gt;
 139          * otherwise we get an annoying&lt;br /&gt;
 140          * &amp;lsquo;BUG: sleeping function called from invalid context&amp;rsquo;&lt;br /&gt;
 141          * complaint from the kernel before the panic.&lt;br /&gt;
 142          &lt;em&gt;/&lt;br /&gt;
 143         rcu_read_unlock();&lt;br /&gt;
 144         panic_on_oops = 1;      /&lt;/em&gt; force panic */&lt;br /&gt;
 145         wmb();&lt;br /&gt;
 146         *killer = 1;&lt;br /&gt;
 147 }&lt;/p&gt;

&lt;h1 id=&#34;memory-barrier&#34;&gt;Memory barrier&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/memory-barriers.txt&#34;&gt;https://www.kernel.org/doc/Documentation/memory-barriers.txt&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://en.wikipedia.org/wiki/Memory_barrier&#34;&gt;http://en.wikipedia.org/wiki/Memory_barrier&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://yarchive.net/comp/linux/compiler_barriers.html&#34;&gt;http://yarchive.net/comp/linux/compiler_barriers.html&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://preshing.com/20120710/memory-barriers-are-like-source-control-operations/&#34;&gt;Memory Barriers Are Like Source Control Operations&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/pub/linux/kernel/people/paulmck/Answers/SMP/lwsync.html&#34;&gt;Are All Linux Kernel Memory Barriers Transitive?&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://events.linuxfoundation.org/sites/events/files/slides/dbueso-elc2016-membarriers-final.pdf&#34;&gt;Memory Barriers in the Linux Kernel Semantics and Practices&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When a program runs on a single-CPU machine, the hardware performs the necessary bookkeeping to ensure that the program executes as if all memory operations were performed in the order specified by the programmer (program order), so memory barriers are not necessary. However, when the memory is shared with multiple devices, such as other CPUs in a multiprocessor system, or memory mapped peripherals, out-of-order access may affect program behavior. For example, a second CPU may see memory changes made by the first CPU in a sequence which differs from program order.&lt;br /&gt;
Compiler and cpu do the same optimization: reorder of instructions&lt;/p&gt;

&lt;h2 id=&#34;the-linux-kernel-has-a-variety-of-different-barriers-that-act-at-different-levels&#34;&gt;The Linux kernel has a variety of different barriers that act at different levels:&lt;/h2&gt;

&lt;p&gt;(&lt;em&gt;) Compiler barrier.&lt;br /&gt;
  (&lt;/em&gt;) CPU memory barriers.&lt;br /&gt;
  (*) MMIO write barrier.&lt;/p&gt;

&lt;h1 id=&#34;compiler-1&#34;&gt;Compiler&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/793253/#Load%20Tearing&#34;&gt;Who&amp;rsquo;s afraid of a big bad optimizing compiler?&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/799218/&#34;&gt;Calibrating your fear of big bad optimizing compilers&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;access-once&#34;&gt;ACCESS_ONCE&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Does it work cast a variable to volatile?&lt;br /&gt;
No, there is no efects on cast a variable to volatile.&lt;br /&gt;
Because, access variable is before volatile cast! That means you&lt;br /&gt;
still get a register value. What you do is just conversion a temporary variable&lt;br /&gt;
Rationale for International Standard&amp;ndash;Programming Languages&amp;ndash;C&lt;br /&gt;
&lt;a href=&#34;http://www.geeksforgeeks.org/understanding-volatile-qualifier-in-c/&#34;&gt;Understanding “volatile” qualifier in C&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/508991/&#34;&gt;ACCESS_ONCE()&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Softirq of Linux Kernel</title>
      <link>http://firoyang.org/cs/softirq/</link>
      <pubDate>Mon, 03 Apr 2017 13:09:05 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/softirq/</guid>
      <description>

&lt;h1 id=&#34;the-old-bottom-half&#34;&gt;The old bottom half&lt;/h1&gt;

&lt;p&gt;ULK 1st: 4.6.6 Bottom Half&lt;br /&gt;
History: commit ad09492558ffa7c67f2b58d23d04dce9ffb9b9dd (tag: 0.99)&lt;br /&gt;
Author: Linus Torvalds &lt;a href=&#34;mailto:torvalds@linuxfoundation.org&#34;&gt;torvalds@linuxfoundation.org&lt;/a&gt;&lt;br /&gt;
Date:   Fri Nov 23 15:09:07 2007 -0500&lt;br /&gt;
    [PATCH] Linux-0.99 (December 13, 1992)&lt;br /&gt;
Firo: There isn&amp;rsquo;t to much useful comment. But the code is very simple. Search bh_base.&lt;/p&gt;

&lt;h1 id=&#34;task-queue&#34;&gt;task queue&lt;/h1&gt;

&lt;p&gt;history: commit 98606bddf430f0a60d21fba93806f4e3c736b170 (tag: 1.1.13)&lt;br /&gt;
Author: Linus Torvalds &lt;a href=&#34;mailto:torvalds@linuxfoundation.org&#34;&gt;torvalds@linuxfoundation.org&lt;/a&gt;&lt;br /&gt;
Date:   Fri Nov 23 15:09:30 2007 -0500&lt;br /&gt;
    Import 1.1.13&lt;br /&gt;
+ * New proposed &amp;ldquo;bottom half&amp;rdquo; handlers:&lt;br /&gt;
+ * &amp;copy; 1994 Kai Petzke, wpp@marie.physik.tu-berlin.de&lt;br /&gt;
+ * Advantages:&lt;br /&gt;
+ * - Bottom halfs are implemented as a linked list.  You can have as many&lt;br /&gt;
+ *   of them, as you want.&lt;br /&gt;
+ * - No more scanning of a bit field is required upon call of a bottom half.&lt;br /&gt;
+ * - Support for chained bottom half lists.  The run_task_queue() function can be&lt;br /&gt;
+ *   used as a bottom half handler.  This is for example usefull for bottom&lt;br /&gt;
+ *   halfs, which want to be delayed until the next clock tick.&lt;br /&gt;
+ * Problems:&lt;br /&gt;
+ * - The queue_task_irq() inline function is only atomic with respect to itself.&lt;br /&gt;
+ *   Problems can occur, when queue_task_irq() is called from a normal system&lt;br /&gt;
+ *   call, and an interrupt comes in.  No problems occur, when queue_task_irq()&lt;br /&gt;
+ *   is called from an interrupt or bottom half, and interrupted, as run_task_queue()&lt;br /&gt;
+ *   will not be executed/continued before the last interrupt returns.  If in&lt;br /&gt;
+ *   doubt, use queue_task(), not queue_task_irq().&lt;br /&gt;
+ * - Bottom halfs are called in the reverse order that they were linked into&lt;br /&gt;
+ *   the list.&lt;br /&gt;
+struct tq_struct {&lt;br /&gt;
Check ULK2nd 4.7.3.1 Extending a bottom half for task queues, especially tq_context and keventd&lt;br /&gt;
The Old Task Queue Mechanism in LKD3rd. Cition from it below.&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/11351/&#34;&gt;The end of task queues&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;softirq&#34;&gt;Softirq&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cs.unca.edu/brock/classes/Spring2013/csci331/notes/paper-1130.pdf&#34;&gt;I’ll Do It Later: Softirqs, Tasklets, Bottom Halves, Task Queues, Work Queues and Timers&lt;/a&gt;&lt;br /&gt;
* not allow execute nest but can recusive lock:local_bh_disable&lt;br /&gt;
current-&amp;gt;preemt_count + SOFIRQ_OFFSET also disable preempt current process.&lt;br /&gt;
* hardirq on, can&amp;rsquo;t sleep&lt;br /&gt;
* not percpu&lt;/p&gt;

&lt;h1 id=&#34;occassions-of-softirq&#34;&gt;Occassions of Softirq&lt;/h1&gt;

&lt;p&gt;irq_exit()&lt;br /&gt;
re-enables softirq, local_bh_enable/spin_unlock_bh(); explicity checks executes, netstack/blockIO.&lt;br /&gt;
ksoftirqd&lt;/p&gt;

&lt;h1 id=&#34;tasklet&#34;&gt;Tasklet&lt;/h1&gt;

&lt;p&gt;History: commit 6cc120a8e71a8d124bf6411fc6e730a884b82701 (tag: 2.3.43pre7)&lt;br /&gt;
Author: Linus Torvalds &lt;a href=&#34;mailto:torvalds@linuxfoundation.org&#34;&gt;torvalds@linuxfoundation.org&lt;/a&gt;&lt;br /&gt;
Date:   Fri Nov 23 15:30:52 2007 -0500&lt;br /&gt;
    Import 2.3.43pre7&lt;br /&gt;
+ Tasklets &amp;mdash; multithreaded analogue of BHs.&lt;br /&gt;
+   Main feature differing them of generic softirqs: tasklet&lt;br /&gt;
+   is running only on one CPU simultaneously.&lt;br /&gt;
+   Main feature differing them of BHs: different tasklets&lt;br /&gt;
+   may be run simultaneously on different CPUs.&lt;br /&gt;
+   Properties:&lt;br /&gt;
+   * If tasklet_schedule() is called, then tasklet is guaranteed&lt;br /&gt;
+     to be executed on some cpu at least once after this.&lt;br /&gt;
+   * If the tasklet is already scheduled, but its excecution is still not&lt;br /&gt;
+     started, it will be executed only once.&lt;br /&gt;
+   * If this tasklet is already running on another CPU (or schedule is called&lt;br /&gt;
+     from tasklet itself), it is rescheduled for later.&lt;br /&gt;
+   * Tasklet is strictly serialized wrt itself, but not&lt;br /&gt;
+     wrt another tasklets. If client needs some intertask synchronization,&lt;br /&gt;
+     he makes it with spinlocks.&lt;/p&gt;

&lt;h1 id=&#34;timer&#34;&gt;Timer&lt;/h1&gt;

&lt;h2 id=&#34;irqsafe-timer&#34;&gt;irqsafe timer&lt;/h2&gt;

&lt;p&gt;__run_timers&lt;br /&gt;
irqsafe = timer-&amp;gt;flags &amp;amp; TIMER_IRQSAFE&lt;br /&gt;
check del_timer_sync&lt;br /&gt;
and definition of TIMER_IRQSAFE&lt;br /&gt;
&lt;a href=&#34;https://patchwork.kernel.org/patch/10811995/&#34;&gt;https://patchwork.kernel.org/patch/10811995/&lt;/a&gt;&lt;br /&gt;
Is timer pending&lt;/p&gt;

&lt;h1 id=&#34;lqo&#34;&gt;LQO&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://thread.gmane.org/gmane.linux.kernel/1152658&#34;&gt;Deal PF_MEMALLOC in softirq&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Softirq of Linux Kernel</title>
      <link>http://firoyang.org/dark_ages/softirq/</link>
      <pubDate>Mon, 03 Apr 2017 13:09:05 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/dark_ages/softirq/</guid>
      <description>

&lt;p&gt;##softirq&lt;br /&gt;
同一个softirq可以在不同的CPU上同时运行，softirq必须是可重入的。&lt;br /&gt;
* not allow execute nest but can recusive lock:local_bh_disable&lt;br /&gt;
current-&amp;gt;preemt_count + SOFIRQ_OFFSET also disable preempt current process.&lt;br /&gt;
* hardirq on, can&amp;rsquo;t sleep&lt;br /&gt;
* not percpu&lt;/p&gt;

&lt;h2 id=&#34;tasklet-and-kernel-timer-is-based-on-softirq&#34;&gt;tasklet and kernel timer is based on softirq&lt;/h2&gt;

&lt;p&gt;新增softirq, 是要重新编译内核的, 试试tasklet也不错.&lt;br /&gt;
.不允许两个两个相同类型的tasklet同时执行，即使在不同的处理器上&lt;br /&gt;
* First of all, it&amp;rsquo;s a conglomerate of mostly unrelated jobs,&lt;br /&gt;
 which run in the context of a randomly chosen victim&lt;br /&gt;
 w/o the ability to put any control on them. &amp;ndash;Thomas Gleixner&lt;/p&gt;

&lt;p&gt;tasklet different with other softirq is run  signal cpu core&lt;br /&gt;
spinlock_bh wider then spinlock&lt;/p&gt;

&lt;p&gt;###time of softirq&lt;br /&gt;
* follow hardirq, irq_exit()&lt;br /&gt;
* re-enables softirq, local_bh_enable/spin_unlock_bh(); explicity checks executes, netstack/blockIO.&lt;br /&gt;
* ksoftirqd&lt;/p&gt;

&lt;p&gt;###tasklet&lt;br /&gt;
tasklet like a workqueue, sofirq like kthread. that is wonderful, does it?&lt;br /&gt;
tasklet 被__tasklet_schedule到某个cpu的percu 变量tasklet_vec.tail上保证了&lt;br /&gt;
只有一个cpu执行同一时刻.&lt;/p&gt;

&lt;p&gt;#FAQ&lt;br /&gt;
##When to save irq rather than just disable irq&lt;br /&gt;
local_irq_disable() used in the code path that never disabled interrupts.&lt;br /&gt;
local_irq_save(flags) used in the code path that already disabled interrupts.&lt;/p&gt;

&lt;p&gt;##what about irq nested?&lt;br /&gt;
&lt;a href=&#34;http://lwn.net/Articles/380937/&#34;&gt;http://lwn.net/Articles/380937/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://thread.gmane.org/gmane.linux.kernel/1152658&#34;&gt;Deal PF_MEMALLOC in softirq&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>x86 interrupt and exception</title>
      <link>http://firoyang.org/cs/event/</link>
      <pubDate>Mon, 03 Apr 2017 13:02:12 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/event/</guid>
      <description>

&lt;h1 id=&#34;events&#34;&gt;Events&lt;/h1&gt;

&lt;p&gt;Interrupts: asynonymous(passively received), external&lt;br /&gt;
Exception: synonymous(actively detected), internal&lt;br /&gt;
Software interrupts: is a trap. int/int3, into, bound.&lt;br /&gt;
IPI&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=-pehAzaP1eg&#34;&gt;IRQs: the Hard, the Soft, the Threaded and the Preemptible&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=YE8cRHVIM4E&#34;&gt;How Dealing with Modern Interrupt Architectures can Affect Your Sanity&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;stack-management&#34;&gt;stack management&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/html/latest/x86/kernel-stacks.html&#34;&gt;x86_64 IST Stacks in kernel&lt;/a&gt;&lt;br /&gt;
6.14.4 Stack Switching in IA-32e Mode&lt;br /&gt;
irq_stack_union&lt;/p&gt;

&lt;h2 id=&#34;backtrace&#34;&gt;backtrace&lt;/h2&gt;

&lt;p&gt;commit a2bbe75089d5eb9a3a46d50dd5c215e213790288&lt;br /&gt;
x86: Don&amp;rsquo;t use frame pointer to save old stack on irq entry&lt;br /&gt;
       /* Save previous stack value &lt;em&gt;/&lt;br /&gt;
       movq %rsp, %rsi&lt;br /&gt;
&amp;hellip;&lt;br /&gt;
2:     /&lt;/em&gt; Store previous stack value */&lt;br /&gt;
       pushq %rsi&lt;br /&gt;
&lt;a href=&#34;https://lore.kernel.org/patchwork/patch/736894/&#34;&gt;Firo: end of EOI; x86/dumpstack: make stack name tags more comprehensible&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;concurrency-nested&#34;&gt;Concurrency, nested?&lt;/h1&gt;

&lt;h2 id=&#34;mask-exception&#34;&gt;Mask exception&lt;/h2&gt;

&lt;p&gt;RF in EFLAGS for masking #DB&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/a/1581729/1025001&#34;&gt;Does sti/cli affect software interrupt&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;irq-nested&#34;&gt;irq nested?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://lwn.net/Articles/380937/&#34;&gt;Prevent nested interrupts when the IRQ stack is near overflowing v2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.lenky.info/archives/2013/03/2245&#34;&gt;对Linux x86-64架构上硬中断的重新认识&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;firo-clear-the-flags-for-pf-through-interrupt-gate&#34;&gt;Firo: clear the flags for PF through interrupt gate&lt;/h3&gt;

&lt;p&gt;v3a: 6.12.1 Exception- or Interrupt-Handler Procedures&lt;br /&gt;
6.12.1.2 Flag Usage By Exception- or Interrupt-Handler Procedure&lt;/p&gt;

&lt;h2 id=&#34;synchronization&#34;&gt;synchronization&lt;/h2&gt;

&lt;p&gt;local_irq_disable() used in the code path that never disabled interrupts.&lt;br /&gt;
local_irq_save(flags) used in the code path that already disabled interrupts.&lt;/p&gt;

&lt;h2 id=&#34;in-interrupt&#34;&gt;in_interrupt&lt;/h2&gt;

&lt;p&gt;383 static inline void tick_irq_exit(void)&lt;br /&gt;
384 {&lt;br /&gt;
385 #ifdef CONFIG_NO_HZ_COMMON&lt;br /&gt;
386         int cpu = smp_processor_id();&lt;br /&gt;
387&lt;br /&gt;
388         /* Make sure that timer wheel updates are propagated &lt;em&gt;/&lt;br /&gt;
389         if ((idle_cpu(cpu) &amp;amp;&amp;amp; !need_resched()) || tick_nohz_full_cpu(cpu)) {&lt;br /&gt;
390                 if (!in_interrupt())&lt;br /&gt;
391                         tick_nohz_irq_exit();&lt;br /&gt;
392         }&lt;br /&gt;
393 #endif&lt;br /&gt;
394 }&lt;br /&gt;
395&lt;br /&gt;
396 /&lt;/em&gt;&lt;br /&gt;
397  * Exit an interrupt context. Process softirqs if needed and possible:&lt;br /&gt;
398  */&lt;br /&gt;
399 void irq_exit(void)&lt;br /&gt;
400 {&lt;br /&gt;
401 #ifndef __ARCH_IRQ_EXIT_IRQS_DISABLED&lt;br /&gt;
402         local_irq_disable();&lt;br /&gt;
403 #else&lt;br /&gt;
404         lockdep_assert_irqs_disabled();&lt;br /&gt;
405 #endif&lt;br /&gt;
406         account_irq_exit_time(current);&lt;br /&gt;
407         preempt_count_sub(HARDIRQ_OFFSET);&lt;br /&gt;
408         if (!in_interrupt() &amp;amp;&amp;amp; local_softirq_pending())&lt;br /&gt;
409                 invoke_softirq();&lt;br /&gt;
410&lt;br /&gt;
411         tick_irq_exit();&lt;/p&gt;

&lt;h1 id=&#34;exceptions&#34;&gt;Exceptions&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://wiki.osdev.org/Exceptions&#34;&gt;Exceptions&lt;/a&gt;&lt;br /&gt;
related code:&lt;br /&gt;
do_nmi do_int3 debug_stack_usage_inc, debug_idt_descr, debug_idt_table,&lt;/p&gt;

&lt;h2 id=&#34;faults-a-fault-is-an-exception-that-can-generally-be-corrected-and-that-once-corrected-allows-the-program&#34;&gt;Faults — A fault is an exception that can generally be corrected and that, once corrected, allows the program&lt;/h2&gt;

&lt;p&gt;to be restarted with no loss of continuity. When a fault is reported, the processor restores the machine state to&lt;br /&gt;
the state prior to the beginning of execution of the faulting instruction. The return address (saved contents of&lt;br /&gt;
the CS and EIP registers) for the fault handler points to the faulting instruction, rather than to the instruction&lt;br /&gt;
following the faulting instruction.&lt;/p&gt;

&lt;h2 id=&#34;traps-a-trap-is-an-exception-that-is-reported-immediately-following-the-execution-of-the-trapping-instruction&#34;&gt;Traps — A trap is an exception that is reported immediately following the execution of the trapping instruction.&lt;/h2&gt;

&lt;p&gt;Traps allow execution of a program or task to be continued without loss of program continuity. The return&lt;br /&gt;
address for the trap handler points to the instruction to be executed after the trapping instruction.&lt;/p&gt;

&lt;h2 id=&#34;aborts-an-abort-is-an-exception-that-does-not-always-report-the-precise-location-of-the-instruction-causing&#34;&gt;Aborts — An abort is an exception that does not always report the precise location of the instruction causing&lt;/h2&gt;

&lt;p&gt;the exception and does not allow a restart of the program or task that caused the exception. Aborts are used to&lt;br /&gt;
report severe errors, such as hardware errors and inconsistent or illegal values in system tables.&lt;/p&gt;

&lt;h2 id=&#34;triggering-a-gp-exception&#34;&gt;Triggering a #GP exception&lt;/h2&gt;

&lt;p&gt;exception_GP_trigger.S&lt;/p&gt;

&lt;h2 id=&#34;exeception-init&#34;&gt;Exeception init&lt;/h2&gt;

&lt;p&gt;Rleated code:&lt;br /&gt;
idt_setup_early_traps           #===&amp;gt; idt_table: ist=0; DB, BP&lt;br /&gt;
idt_setup_early_pf              #===&amp;gt; idt_table: PF ist=0;&lt;br /&gt;
trap_init, idt_setup_traps                 #===&amp;gt; idt_table: ist=0; DE, 0x80 &amp;hellip; etc.&lt;br /&gt;
trap_init-&amp;gt;cpu_init, idt_setup_ist_traps             #===&amp;gt; idt_table: ist=1; DB, NMI, BP, DF, MC;&lt;br /&gt;
x86_init.irqs.trap_init         #===&amp;gt; if !KVM, noop&lt;br /&gt;
idt_setup_debugidt_traps        #===&amp;gt; debug_idt_table, check debug stack; INTG; #DB debug; #BP int; check arch/x86/entry/entry_64.S&lt;/p&gt;

&lt;h1 id=&#34;interrupt&#34;&gt;Interrupt&lt;/h1&gt;

&lt;p&gt;If interrupt occured in user mode, then cpu will context swith for potential reschedule.&lt;br /&gt;
The Interrupt Descriptor Table (IDT) is a data structure used by the x86 architecture to implement an interrupt vector table.&lt;/p&gt;

&lt;h2 id=&#34;hardware-interrupts&#34;&gt;Hardware interrupts&lt;/h2&gt;

&lt;p&gt;are used by devices to communicate that they require attention from the operating system.&lt;br /&gt;
more details in init_IRQ() or set_irq() in driver.&lt;/p&gt;

&lt;h2 id=&#34;software-interrupt&#34;&gt;software interrupt&lt;/h2&gt;

&lt;p&gt;more details in trap_init().&lt;br /&gt;
* exception or trap&lt;br /&gt;
is caused either by an exceptional condition in the processor itself,&lt;br /&gt;
divide zero painc?&lt;br /&gt;
* special instruction, for example INT 0x80&lt;br /&gt;
or a special instruction in the instruction set which causes an interrupt when it is executed.&lt;/p&gt;

&lt;h2 id=&#34;irq-line-number-vs-interrupt-vector&#34;&gt;IRQ line number vs interrupt vector&lt;/h2&gt;

&lt;p&gt;cat /proc/interrupts&lt;br /&gt;
            CPU0       CPU1       CPU2       CPU3&lt;br /&gt;
   0:         21          0          0          0  IR-IO-APIC    2-edge      timer&lt;br /&gt;
v3a Chapter 6 and Check ULK3 Chapter 4 Interrupt vectors&lt;br /&gt;
the 0 in /proc/interrupts is a IRQ line number&lt;br /&gt;
The 0 for Divide error is a interrupt vector.&lt;/p&gt;

&lt;h2 id=&#34;interrupt-init&#34;&gt;Interrupt init&lt;/h2&gt;

&lt;p&gt;early_irq_init = alloc NR_IRQS_LEGACY irq_desc; - 16    #===&amp;gt; [    0.000000] NR_IRQS: 65792, nr_irqs: 1024, preallocated irqs: 16&lt;br /&gt;
init_IRQ()-&amp;gt;x86_init.irqs.intr_init=native_init_IRQ     #===&amp;gt; external interrupt init;&lt;br /&gt;
    pre_vector_init = init_ISA_irqs #===&amp;gt; 1) legacy_pic-&amp;gt;init(0); init 8259a; 2) link irq_desc in irq_desc_tree with flow handle and chip.&lt;br /&gt;
    idt_setup_apic_and_irq_gates    #===&amp;gt; apic normal(from 32) and system interrupts;&lt;/p&gt;

&lt;h1 id=&#34;ipi&#34;&gt;IPI&lt;/h1&gt;

&lt;p&gt;commit 52aec3308db85f4e9f5c8b9f5dc4fbd0138c6fa4&lt;br /&gt;
Author: Alex Shi &lt;a href=&#34;mailto:alex.shi@intel.com&#34;&gt;alex.shi@intel.com&lt;/a&gt;&lt;br /&gt;
Date:   Thu Jun 28 09:02:23 2012 +0800&lt;br /&gt;
    x86/tlb: replace INVALIDATE_TLB_VECTOR by CALL_FUNCTION_VECTOR&lt;br /&gt;
ERROR_APIC_VECTOR               0xfe&lt;br /&gt;
RESCHEDULE_VECTOR               0xfd&lt;br /&gt;
CALL_FUNCTION_VECTOR            0xfc&lt;br /&gt;
CALL_FUNCTION_SINGLE_VECTOR     0xfb&lt;br /&gt;
THERMAL_APIC_VECTOR             0xfa&lt;br /&gt;
THRESHOLD_APIC_VECTOR           0xf9&lt;br /&gt;
REBOOT_VECTOR                   0xf8&lt;/p&gt;

&lt;h1 id=&#34;history&#34;&gt;History&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://people.cs.clemson.edu/~mark/interrupts.html&#34;&gt;history of interrupts&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://virtualirfan.com/history-of-interrupts&#34;&gt;Another History of interrupts with video&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scheduling in operating system</title>
      <link>http://firoyang.org/cs/scheduling/</link>
      <pubDate>Wed, 29 Mar 2017 10:49:04 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/scheduling/</guid>
      <description>

&lt;h1 id=&#34;scheduling&#34;&gt;scheduling&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Scheduling_(computing)&#34;&gt;Scheduling (computing)&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;context-switch&#34;&gt;Context switch&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.maizure.org/projects/evolution_x86_context_switch_linux/index.html&#34;&gt;Evolution of the x86 context switch in Linux&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/520227/&#34;&gt;Al Viro&amp;rsquo;s new execve/kernel_thread design&lt;/a&gt;&lt;br /&gt;
commit 0100301bfdf56a2a370c7157b5ab0fbf9313e1cd&lt;br /&gt;
Author: Brian Gerst &lt;a href=&#34;mailto:brgerst@gmail.com&#34;&gt;brgerst@gmail.com&lt;/a&gt;&lt;br /&gt;
Date:   Sat Aug 13 12:38:19 2016 -0400&lt;br /&gt;
    sched/x86: Rewrite the switch_to() code&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/15019986/why-does-switch-to-use-pushjmpret-to-change-eip-instead-of-jmp-directly/15024312&#34;&gt;Why does switch_to use push+jmp+ret to change EIP, instead of jmp directly?&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;Process scheduling in Linux &amp;ndash; Volker Seeker from University of Edinburgh&lt;br /&gt;
&lt;a href=&#34;https://tampub.uta.fi/bitstream/handle/10024/96864/GRADU-1428493916.pdf&#34;&gt;A complete guide to Linux process scheduling&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt&#34;&gt;https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://helix979.github.io/jkoo/post/os-scheduler/&#34;&gt;JINKYU KOO&amp;rsquo;s Linux kernel scheduler&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.joelfernandes.org/linuxinternals/2016/03/20/tif-need-resched-why-is-it-needed.html&#34;&gt;TIF_NEED_RESCHED: why is it needed&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;general-runqueues&#34;&gt;General runqueues&lt;/h1&gt;

&lt;p&gt;static DEFINE_PER_CPU_SHARED_ALIGNED(struct rq, runqueues);&lt;br /&gt;
activate_task - move a task to the runqueue.&lt;br /&gt;
wake_up_new_task&lt;br /&gt;
ttwu_do_activate&lt;/p&gt;

&lt;h1 id=&#34;latency&#34;&gt;Latency&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/404993/&#34;&gt;Improving scheduler latency&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;cfs-runqueues&#34;&gt;CFS runqueues&lt;/h1&gt;

&lt;p&gt;cfa_rq, on_list, sched_entity-&amp;gt;on_rq, check enqueue_entity&lt;/p&gt;

&lt;h2 id=&#34;cfs-runqueue-and-sched-entity&#34;&gt;CFS runqueue and sched entity&lt;/h2&gt;

&lt;p&gt;set_task_rq&lt;/p&gt;

&lt;h2 id=&#34;on-rq&#34;&gt;on_rq&lt;/h2&gt;

&lt;p&gt;on_rq should be same as task-&amp;gt;on_rq. It doesn&amp;rsquo;t mean sched_entity is on cfs_rq, but rq.&lt;br /&gt;
commit fd2f4419b4cbe8fe90796df9617c355762afd6a4&lt;br /&gt;
Author: Peter Zijlstra &lt;a href=&#34;mailto:a.p.zijlstra@chello.nl&#34;&gt;a.p.zijlstra@chello.nl&lt;/a&gt;&lt;br /&gt;
Date:   Tue Apr 5 17:23:44 2011 +0200&lt;br /&gt;
    sched: Provide p-&amp;gt;on_rq&lt;br /&gt;
p-&amp;gt;on_rq on any rq.&lt;br /&gt;
se-&amp;gt;on_rq on specific rq.&lt;/p&gt;

&lt;h2 id=&#34;cfs-runqueue-and-task-group&#34;&gt;CFS runqueue and task group&lt;/h2&gt;

&lt;p&gt;sched_create_group -&amp;gt; alloc_fair_sched_group -&amp;gt; init_tg_cfs_entry&lt;/p&gt;

&lt;h1 id=&#34;cfs-core-codes&#34;&gt;CFS core codes&lt;/h1&gt;

&lt;p&gt;git log 20b8a59f2461e&lt;/p&gt;

&lt;h1 id=&#34;group-scheduling&#34;&gt;Group scheduling&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt&#34;&gt;GROUP SCHEDULER EXTENSIONS TO CFS&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.wowotech.net/process_management/449.html&#34;&gt;CFS调度器（3）-组调度&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://oenhan.com/task-group-sched&#34;&gt;Linux进程组调度机制分析&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;two-trees&#34;&gt;Two trees&lt;/h2&gt;

&lt;p&gt;task_group-&amp;gt;parent; task_group-&amp;gt;css.cgroup&lt;br /&gt;
cgroup-&amp;gt;parent and cgroup_tg: container_of(cgroup_subsys_state(cgrp, cpu_cgroup_subsys_id), struct task_group, css);&lt;/p&gt;

&lt;h2 id=&#34;task-group-and-cgroup-is-1-1&#34;&gt;Task group and cgroup is 1:1&lt;/h2&gt;

&lt;h2 id=&#34;system-bootup&#34;&gt;System bootup&lt;/h2&gt;

&lt;p&gt;struct task_group root_task_group; and cpu_cgroup_create;&lt;/p&gt;

&lt;h2 id=&#34;creating-task-group&#34;&gt;Creating task_group&lt;/h2&gt;

&lt;p&gt;sched_create_group&lt;br /&gt;
task_group 1 : cpu &amp;lsquo;group sched_entity&amp;rsquo;&lt;br /&gt;
group sched_entity 1 : 1 greoup cfs_rq&lt;br /&gt;
gse_CPUx&amp;rsquo;s load = grq_CPUx&amp;rsquo;s all se&amp;rsquo;s load * task_group-&amp;gt;shares / grq_CPU&lt;em&gt;&amp;rsquo;s all se&amp;rsquo;s load&lt;br /&gt;
        /&lt;/em&gt; rq on which this entity is (to be) queued: */&lt;br /&gt;
        struct cfs_rq           &lt;em&gt;cfs_rq;&lt;br /&gt;
        /&lt;/em&gt; rq &amp;ldquo;owned&amp;rdquo; by this entity/group: */&lt;br /&gt;
        struct cfs_rq           *my_q;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/240474/&#34;&gt;CFS group scheduling&lt;/a&gt;&lt;br /&gt;
commit 29f59db3a74b0bdf78a1f5b53ef773caa82692dc&lt;br /&gt;
Author: Srivatsa Vaddagiri &lt;a href=&#34;mailto:vatsa@linux.vnet.ibm.com&#34;&gt;vatsa@linux.vnet.ibm.com&lt;/a&gt;&lt;br /&gt;
Date:   Mon Oct 15 17:00:07 2007 +0200&lt;br /&gt;
    sched: group-scheduler core&lt;/p&gt;

&lt;h2 id=&#34;why-double-for-each-sched-entity&#34;&gt;Why double for_each_sched_entity&lt;/h2&gt;

&lt;p&gt;commit 2069dd75c7d0f49355939e5586daf5a9ab216db7&lt;br /&gt;
Author: Peter Zijlstra &lt;a href=&#34;mailto:a.p.zijlstra@chello.nl&#34;&gt;a.p.zijlstra@chello.nl&lt;/a&gt;&lt;br /&gt;
Date:   Mon Nov 15 15:47:00 2010 -0800&lt;br /&gt;
    sched: Rewrite tg_shares_up)&lt;/p&gt;

&lt;p&gt;371fd7e7a56a5 (Peter Zijlstra       2010-03-24 16:38:48 +0100 1129) enqueue_task_fair(struct rq *rq, struct task_struct *p, int flags)&lt;br /&gt;
bf0f6f24a1ece (Ingo Molnar          2007-07-09 18:51:58 +0200 1134)     for_each_sched_entity(se) {&lt;br /&gt;
62fb185130e4d (Peter Zijlstra       2008-02-25 17:34:02 +0100 1135)             if (se-&amp;gt;on_rq)&lt;br /&gt;
bf0f6f24a1ece (Ingo Molnar          2007-07-09 18:51:58 +0200 1136)                     break;&lt;br /&gt;
bf0f6f24a1ece (Ingo Molnar          2007-07-09 18:51:58 +0200 1137)             cfs_rq = cfs_rq_of(se);&lt;br /&gt;
88ec22d3edb72 (Peter Zijlstra       2009-12-16 18:04:41 +0100 1138)             enqueue_entity(cfs_rq, se, flags);&lt;br /&gt;
88ec22d3edb72 (Peter Zijlstra       2009-12-16 18:04:41 +0100 1139)             flags = ENQUEUE_WAKEUP;&lt;br /&gt;
bf0f6f24a1ece (Ingo Molnar          2007-07-09 18:51:58 +0200 1140)     }&lt;br /&gt;
8f4d37ec073c1 (Peter Zijlstra       2008-01-25 21:08:29 +0100 1141)&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1142)     for_each_sched_entity(se) {&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1143)             struct cfs_rq *cfs_rq = cfs_rq_of(se);&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1144)&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1145)             update_cfs_load(cfs_rq);&lt;br /&gt;
2069dd75c7d0f (Peter Zijlstra       2010-11-15 15:47:00 -0800 1146)             update_cfs_shares(cfs_rq);&lt;/p&gt;

&lt;h1 id=&#34;wake-up&#34;&gt;Wake up&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lkml.org/lkml/2015/4/19/111&#34;&gt;sched: lockless wake-queues&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=-8c47dHuGIY&#34;&gt;Futex Scaling for Multi-core Systems&lt;/a&gt;&lt;a href=&#34;https://www.slideshare.net/davidlohr/futex-scaling-for-multicore-systems&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;program-order-guarantees&#34;&gt;Program-Order guarantees&lt;/h1&gt;

&lt;p&gt;commit 8643cda549ca49a403160892db68504569ac9052&lt;br /&gt;
Author: Peter Zijlstra &lt;a href=&#34;mailto:peterz@infradead.org&#34;&gt;peterz@infradead.org&lt;/a&gt;&lt;br /&gt;
Date:   Tue Nov 17 19:01:11 2015 +0100&lt;br /&gt;
    sched/core, locking: Document Program-Order guarantees&lt;/p&gt;

&lt;h2 id=&#34;lkml-discussions&#34;&gt;LKML discussions&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lkml.org/lkml/2015/11/2/311&#34;&gt;scheduler ordering bits&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lkml.org/lkml/2015/12/3/323&#34;&gt;scheduler ordering bits -v2&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;pi-lock&#34;&gt;pi_lock&lt;/h2&gt;

&lt;p&gt;commit b29739f902ee76a05493fb7d2303490fc75364f4&lt;br /&gt;
Author: Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
Date:   Tue Jun 27 02:54:51 2006 -0700&lt;br /&gt;
    [PATCH] pi-futex: scheduler support for pi&lt;br /&gt;
    Add framework to boost/unboost the priority of RT tasks.&lt;/p&gt;

&lt;h1 id=&#34;rq-lock-in-schedule-and-context-switch&#34;&gt;rq-&amp;gt;lock in schedule() and context_switch()&lt;/h1&gt;

&lt;p&gt;commit 3a5f5e488ceee9e08df3dff3f01b12fafc9e7e68&lt;br /&gt;
Author: Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
Date:   Fri Jul 14 00:24:27 2006 -0700&lt;br /&gt;
    [PATCH] lockdep: core, fix rq-lock handling on __ARCH_WANT_UNLOCKED_CTXSW&lt;br /&gt;
+        * Since the runqueue lock will be released by the next&lt;br /&gt;
+        * task&lt;/p&gt;

&lt;h1 id=&#34;running-time&#34;&gt;Running time&lt;/h1&gt;

&lt;p&gt;proc_sched_show_task&lt;/p&gt;

&lt;h1 id=&#34;problems&#34;&gt;Problems&lt;/h1&gt;

&lt;h2 id=&#34;why-scheduling&#34;&gt;Why scheduling?&lt;/h2&gt;

&lt;p&gt;Customers demand multitasking/concurrent&lt;br /&gt;
Processes are blocked&lt;/p&gt;

&lt;h2 id=&#34;fairness&#34;&gt;Fairness&lt;/h2&gt;

&lt;p&gt;Unit: /proc/sys/kernel/sched_min_granularity_ns&lt;/p&gt;

&lt;h1 id=&#34;conceptions&#34;&gt;Conceptions&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://android.googlesource.com/kernel/msm/+/android-msm-bullhead-3.10-marshmallow-dr/Documentation/scheduler/sched-hmp.txt&#34;&gt;Cpu capacity&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;running-compensator-records-the-running-process&#34;&gt;Running Compensator records the running process&lt;/h1&gt;

&lt;p&gt;scheduler_tick&lt;br /&gt;
{&lt;br /&gt;
    update_rq_clock&lt;br /&gt;
    task_tick_fair -&amp;gt; entity_tick&lt;br /&gt;
    {&lt;br /&gt;
        update_curr&lt;br /&gt;
        {&lt;br /&gt;
            sum_exec_runtime - total runtime&lt;br /&gt;
            cfs_rq-&amp;gt;exec_clock - cfs_rq runtime&lt;br /&gt;
            vruntime    - inverse proportion to the weight or priority&lt;br /&gt;
            update_min_vruntime&lt;br /&gt;
            {&lt;br /&gt;
                cfs_rq-&amp;gt;curr, leftmost, min_vruntime, who is min?&lt;br /&gt;
            }&lt;br /&gt;
            cpuacct - cpu sys/user time&lt;br /&gt;
        }&lt;br /&gt;
    }&lt;br /&gt;
}&lt;/p&gt;

&lt;h1 id=&#34;next-pick-next-task-fair&#34;&gt;Next -&amp;gt; pick_next_task_fair&lt;/h1&gt;

&lt;p&gt;put_prev_entity: update_curr; insert into rb-tree;&lt;br /&gt;
pick_next_entity: left most of rb-tree.&lt;br /&gt;
set_next_entity: remove next from tree since it will disturb inserting and deleting when it is being updated.&lt;/p&gt;

&lt;h1 id=&#34;unrunnable&#34;&gt;Unrunnable&lt;/h1&gt;

&lt;p&gt;dequeue_task&lt;/p&gt;

&lt;h1 id=&#34;resuming&#34;&gt;Resuming&lt;/h1&gt;

&lt;p&gt;try_to_wake_up-&amp;gt;ttwu_queue-&amp;gt;ttwu_do_activate-&amp;gt; or local wakeup: schedule-&amp;gt;try_to_wake_up_local-&amp;gt;&lt;br /&gt;
{&lt;br /&gt;
    ttwu_activate               #=== speical compensation and enqueue rq&lt;br /&gt;
    {&lt;br /&gt;
        activate_task&lt;br /&gt;
        p-&amp;gt;on_rq = TASK_ON_RQ_QUEUED    #=== 1) rq for task; 2)&lt;br /&gt;
    }&lt;br /&gt;
    ttwu_do_wakeup              #=== normal compensation&lt;br /&gt;
    {&lt;br /&gt;
        check_preempt_curr&lt;br /&gt;
        p-&amp;gt;state = TASK_RUNNING;&lt;br /&gt;
    }&lt;br /&gt;
}&lt;/p&gt;

&lt;p&gt;enqueue_task-&amp;gt; place_entity compensation for wakeup process&lt;/p&gt;

&lt;h2 id=&#34;wake-up-a-sleep-task&#34;&gt;wake up a sleep task&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;se-&amp;gt;on_rq &amp;amp; TASK_ON_RQ_QUEUED; deactivate_task set on_rq to 0;
enqueue_task_fair handles group stuff
enqueue_entity deals with sched_entity - uptodate the vruntime, load average, account load numa perfering,
sysctl_sched_latency: the cfs pledge to the pre-existing tasks that they have 6ms to run before new task to run.
try_to_wake_up_local for local task
try_to_wake_up for any task
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;new-task&#34;&gt;New task&lt;/h1&gt;

&lt;p&gt;speical debit compensation: sched_fork-&amp;gt;task_fork_fair-&amp;gt;place_entity - compensation for new process&lt;br /&gt;
normal compensation: wake_up_new_task&lt;br /&gt;
{&lt;br /&gt;
    activate_task               #=== speical compensation&lt;br /&gt;
    check_preempt_curr          #=== normal compensation&lt;br /&gt;
}&lt;/p&gt;

&lt;h1 id=&#34;priority&#34;&gt;Priority&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;weight&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;priority&lt;br /&gt;
DEFAULT_PRIO&lt;br /&gt;
fs/proc/array.c&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;latency-1&#34;&gt;Latency&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;sched_nr_latency= /proc/sys/kernel/sched_latency_ns / /proc/sys/kernel/sched_min_granularity_ns&lt;br /&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;if running process &amp;gt; sched_nr_latency, latency cannot be ensured. just focus on min granularity&lt;/p&gt;

&lt;h2 id=&#34;lqo&#34;&gt;LQO&lt;/h2&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;is the difference of leftmost and rightmost smaller than sched_min_granularity_ns??&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;sched_slice&lt;/p&gt;

&lt;h1 id=&#34;energy&#34;&gt;Energy&lt;/h1&gt;

&lt;p&gt;blocked &amp;amp; schedule&lt;br /&gt;
check preempt &amp;amp; schedule&lt;br /&gt;
check_preempt_tick              # new preempts curr&lt;br /&gt;
{&lt;br /&gt;
curr running time &amp;gt; sched_slice     # enough time to yield.&lt;br /&gt;
curr - leftmost &amp;gt; sched_slice       # nice to others.&lt;br /&gt;
}&lt;br /&gt;
check_preempt_wakeup                # the wakeuped preempts curr&lt;br /&gt;
{&lt;br /&gt;
curr - wakeuped &amp;gt; sysctl_sched_wakeup_granularity;  # pass the wakeup-preempt-delay&lt;br /&gt;
}&lt;/p&gt;

&lt;h1 id=&#34;io-wait&#34;&gt;io wait&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/342378/&#34;&gt;https://lwn.net/Articles/342378/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;load-avg&#34;&gt;Load avg&lt;/h1&gt;

&lt;p&gt;update_load&lt;em&gt;avg&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Load&#34;&gt;https://en.wikipedia.org/wiki/Load&lt;/a&gt;&lt;/em&gt;(computing)&lt;br /&gt;
Check External links&lt;br /&gt;
calc_load_fold_active&lt;br /&gt;
Etymology of avenrun: &lt;a href=&#34;https://elixir.bootlin.com/linux/v4.1/source/arch/s390/appldata/appldata_os.c&#34;&gt;average nr. of running processes during&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;lqo-1&#34;&gt;LQO&lt;/h1&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;h_nr_running and throttled&lt;br /&gt;
sched: Implement hierarchical task accounting for SCHED_OTHER - 953bfcd10e6f3697233e8e5128c611d275da39c1&lt;br /&gt;
&lt;a href=&#34;https://groups.google.com/forum/#!topic/linux.kernel/gRzxHclMy50&#34;&gt;https://groups.google.com/forum/#!topic/linux.kernel/gRzxHclMy50&lt;/a&gt;&lt;br /&gt;
&amp;lsquo;root&amp;rsquo;&lt;br /&gt;
\&lt;br /&gt;
&amp;lsquo;A&amp;rsquo;&lt;br /&gt;
/ \&lt;br /&gt;
t1 t2&lt;br /&gt;
root.nr_running := 2&lt;br /&gt;
root.h_nr_running := 2&lt;br /&gt;
Check enqueue_task_fair()&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;idle&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/scheduler/sched-arch.txt&#34;&gt;https://www.kernel.org/doc/Documentation/scheduler/sched-arch.txt&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/136065/&#34;&gt;improve SMP reschedule and idle routines&lt;/a&gt;&lt;br /&gt;
TIF_POLLING_NRFLAG -&amp;gt; Need-Resched-Flag?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;process migration&lt;br /&gt;
e761b7725234276a802322549cee5255305a0930&lt;br /&gt;
Introduce cpu_active_map and redo sched domain managment&lt;br /&gt;
When to migration&lt;br /&gt;
    sched_setaffinity __set_cpus_allowed_ptr manuly&lt;br /&gt;
    Selecting a new CPU during wak up a sleeper&lt;br /&gt;
    For balancing, selecting CPU during  wake up new process in _do_fork&lt;br /&gt;
    execve&amp;rsquo;s sched_exec&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;shceduler clock&lt;br /&gt;
rq-&amp;gt;clock is nano seconds?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;clock_task and wraps&lt;br /&gt;
fe44d62122829959e960bc699318d58966922a69&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
&lt;li&gt;START_DEBIT&lt;br /&gt;
no standalone commit&lt;br /&gt;
bf0f6f24a1ece8988b243aefe84ee613099a9245&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;why ahead?&lt;br /&gt;
8 /*&lt;br /&gt;
9  * Place new tasks ahead so that they do not starve already running&lt;br /&gt;
10  * tasks&lt;br /&gt;
11  */&lt;br /&gt;
12 SCHED_FEAT(START_DEBIT, true)&lt;br /&gt;
the tree is named timeline&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lwn.net/Articles/404993/&#34;&gt;Improving scheduler latency &lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;skip next last buddy&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;git-log&#34;&gt;Git log&lt;/h1&gt;

&lt;p&gt;e9c8431185d6c406887190519f6dbdd112641686&lt;br /&gt;
TASK_WAKING; see migrate_task_rq_fair and try_to_wake_up&lt;br /&gt;
88ec22d3edb72b261f8628226cd543589a6d5e1b&lt;br /&gt;
In order to remove the cfs_rq dependency from set_task_cpu() we need to ensure the task is cfs_rq invariant for all callsites.&lt;br /&gt;
2f950354e6d535b892f133d20bd6a8b09430424c&lt;br /&gt;
sched/fair: Fix fairness issue on migration&lt;br /&gt;
&lt;a href=&#34;http://linux.kernel.narkive.com/p15Wmn0i/migrated-cfs-task-getting-an-unfair-advantage&#34;&gt;Migrated CFS task getting an unfair advantage&lt;/a&gt;&lt;br /&gt;
30cfdcfc5f180fc21a3dad6ae3b7b2a9ee112186&lt;br /&gt;
curr was not kept in rb-tree&lt;/p&gt;

&lt;h1 id=&#34;load-balancing&#34;&gt;Load balancing&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/80911/&#34;&gt;Scheduling domains&lt;/a&gt;&lt;br /&gt;
set sd&lt;br /&gt;
kernel_init_freeable-&amp;gt;&lt;br /&gt;
sched_init_smp-&amp;gt;&lt;br /&gt;
init_sched_domains-&amp;gt;build_sched_domains:-&amp;gt;&lt;br /&gt;
&lt;strong&gt;visit_domain_allocation_hell()-&amp;gt;&lt;/strong&gt;sdt_alloc() alloc the sdd-&amp;gt;sg which is used by build groups&lt;br /&gt;
and sg = kzalloc_node(sizeof(struct sched_group) + cpumask_size(); it covered the size of cpumask&lt;br /&gt;
/* Build the groups for the domains */&lt;br /&gt;
detach_destroy_domains&lt;br /&gt;
cpu_attach_domain&lt;/p&gt;

&lt;p&gt;CONFIG_SCHED_MC=y&lt;br /&gt;
static noinline struct sched_domain *                                   &lt;br /&gt;
sd&lt;em&gt;init&lt;/em&gt;##type(struct sched_domain_topology_level *tl, int cpu)         &lt;br /&gt;
{                                                                       &lt;br /&gt;
        struct sched_domain *sd = *per_cpu&lt;em&gt;ptr(tl-&amp;gt;data.sd, cpu);       &lt;br /&gt;
        *sd = SD&lt;/em&gt;##type##_INIT;                                         &lt;br /&gt;
        SD_INIT_NAME(sd, type);                                         &lt;br /&gt;
        sd-&amp;gt;private = &amp;amp;tl-&amp;gt;data;                                        &lt;br /&gt;
        return sd;                                                      &lt;br /&gt;
}&lt;br /&gt;
tl-&amp;gt;mask(cpu)&lt;br /&gt;
static struct sched_domain_topology_level default_topology[] = {&lt;br /&gt;
#ifdef CONFIG_SCHED_SMT&lt;br /&gt;
        { sd_init_SIBLING, cpu_smt_mask, },&lt;br /&gt;
#endif&lt;br /&gt;
#ifdef CONFIG_SCHED_MC&lt;br /&gt;
        { sd_init_MC, cpu_coregroup_mask, },&lt;br /&gt;
#endif&lt;br /&gt;
#ifdef CONFIG_SCHED_BOOK&lt;br /&gt;
        { sd_init_BOOK, cpu_book_mask, },&lt;br /&gt;
#endif&lt;br /&gt;
        { sd_init_CPU, cpu_cpu_mask, },&lt;br /&gt;
        { NULL, },&lt;br /&gt;
};&lt;/p&gt;

&lt;h2 id=&#34;leaf-cfs-runqueues-leaf-cfs-rq&#34;&gt;Leaf CFS runqueues leaf_cfs_rq&lt;/h2&gt;

&lt;h3 id=&#34;first&#34;&gt;First&lt;/h3&gt;

&lt;p&gt;commit 6aa645ea5f7a246702e07f29edc7075d487ae4a3&lt;br /&gt;
Refs: v2.6.22-14-g6aa645ea5f7a&lt;br /&gt;
Author:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
AuthorDate: Mon Jul 9 18:51:58 2007 +0200&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
CommitDate: Mon Jul 9 18:51:58 2007 +0200&lt;br /&gt;
    sched: cfs rq data types&lt;br /&gt;
 * leaf cfs_rqs are those that hold tasks (lowest schedulable entity in&lt;br /&gt;
 * a hierarchy). Non-leaf lrqs hold other higher schedulable entities&lt;br /&gt;
 * (like users, containers etc.)&lt;br /&gt;
 * leaf_cfs_rq_list ties together list of leaf cfs_rq&amp;rsquo;s in a cpu. This&lt;br /&gt;
 * list is used during load balance.&lt;br /&gt;
Head of list: rq-&amp;gt;leaf_cfs_rq_list&lt;/p&gt;

&lt;h3 id=&#34;core-load-balance-fair&#34;&gt;Core load_balance_fair&lt;/h3&gt;

&lt;p&gt;commit bf0f6f24a1ece8988b243aefe84ee613099a9245&lt;br /&gt;
Refs: v2.6.22-10-gbf0f6f24a1ec&lt;br /&gt;
Author:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
AuthorDate: Mon Jul 9 18:51:58 2007 +0200&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
CommitDate: Mon Jul 9 18:51:58 2007 +0200&lt;br /&gt;
    sched: cfs core, kernel/sched_fair.c&lt;br /&gt;
    add kernel/sched_fair.c - which implements the bulk of CFS&amp;rsquo;s&lt;br /&gt;
    behavioral changes for SCHED_OTHER tasks.&lt;br /&gt;
+load_balance_fair(struct rq *this_rq, int this_cpu, struct rq *busiest,&lt;br /&gt;
+       for_each_leaf_cfs_rq(busiest, busy_cfs_rq) {&lt;/p&gt;

&lt;h3 id=&#34;make-parent-appear-after-us&#34;&gt;make parent appear after us.&lt;/h3&gt;

&lt;p&gt;commit 67e86250f8ea7b8f7da53ac25ea73c6bd71f5cd9&lt;br /&gt;
Author: Paul Turner &lt;a href=&#34;mailto:pjt@google.com&#34;&gt;pjt@google.com&lt;/a&gt;&lt;br /&gt;
Date:   Mon Nov 15 15:47:05 2010 -0800&lt;br /&gt;
    sched: Introduce hierarchal order on shares update list&lt;br /&gt;
    Avoid duplicate shares update calls by ensuring children always appear before                 # leaf&amp;rsquo;s meaning is changed&lt;br /&gt;
    parents in rq-&amp;gt;leaf_cfs_rq_list.&lt;br /&gt;
    This allows us to do a single in-order traversal for update_shares().&lt;br /&gt;
    Since we always enqueue in bottom-up order this reduces to 2 cases:&lt;br /&gt;
    1) Our parent is already in the list, e.g.&lt;br /&gt;
       root&lt;br /&gt;
         &lt;br /&gt;
          b&lt;br /&gt;
          /&lt;br /&gt;
          c d* (root-&amp;gt;b-&amp;gt;c already enqueued)&lt;br /&gt;
    Since d&amp;rsquo;s parent is enqueued we push it to the head of the list, implicitly ahead of b.&lt;br /&gt;
    2) Our parent does not appear in the list (or we have no parent)&lt;br /&gt;
    In this case we enqueue to the tail of the list, if our parent is subsequently enqueued&lt;br /&gt;
    (bottom-up) it will appear to our right by the same rule.&lt;/p&gt;

&lt;h3 id=&#34;tmp-alone-branch&#34;&gt;tmp_alone_branch&lt;/h3&gt;

&lt;p&gt;commit 9c2791f936ef5fd04a118b5c284f2c9a95f4a647&lt;br /&gt;
Refs: v4.9-rc5-195-g9c2791f936ef&lt;br /&gt;
Author:     Vincent Guittot &lt;a href=&#34;mailto:vincent.guittot@linaro.org&#34;&gt;vincent.guittot@linaro.org&lt;/a&gt;&lt;br /&gt;
AuthorDate: Tue Nov 8 10:53:43 2016 +0100&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@kernel.org&#34;&gt;mingo@kernel.org&lt;/a&gt;&lt;br /&gt;
CommitDate: Wed Nov 16 10:29:08 2016 +0100&lt;br /&gt;
    sched/fair: Fix hierarchical order in rq-&amp;gt;leaf_cfs_rq_list&lt;br /&gt;
    Fix the insertion of cfs_rq in rq-&amp;gt;leaf_cfs_rq_list to ensure that a&lt;br /&gt;
    child will always be called before its parent.&lt;br /&gt;
    The hierarchical order in shares update list has been introduced by&lt;br /&gt;
    commit:&lt;br /&gt;
      67e86250f8ea (&amp;ldquo;sched: Introduce hierarchal order on shares update list&amp;rdquo;)&lt;/p&gt;

&lt;p&gt;commit 5d299eabea5a251fbf66e8277704b874bbba92dc&lt;br /&gt;
Author: Peter Zijlstra &lt;a href=&#34;mailto:peterz@infradead.org&#34;&gt;peterz@infradead.org&lt;/a&gt;&lt;br /&gt;
Date:   Wed Jan 30 14:41:04 2019 +0100&lt;br /&gt;
    sched/fair: Add tmp_alone_branch assertion&lt;br /&gt;
    The magic in list_add_leaf_cfs_rq() requires that at the end of&lt;br /&gt;
    enqueue_task_fair():&lt;br /&gt;
      rq-&amp;gt;tmp_alone_branch == &amp;amp;rq-&amp;gt;lead_cfs_rq_list&lt;/p&gt;

&lt;h3 id=&#34;load-balance-fair-removed&#34;&gt;load_balance_fair - removed&lt;/h3&gt;

&lt;p&gt;commit 9763b67fb9f3050c6da739105888327587c30c4d&lt;br /&gt;
Refs: v3.0-rc7-197-g9763b67fb9f3&lt;br /&gt;
Author:     Peter Zijlstra &lt;a href=&#34;mailto:a.p.zijlstra@chello.nl&#34;&gt;a.p.zijlstra@chello.nl&lt;/a&gt;&lt;br /&gt;
AuthorDate: Wed Jul 13 13:09:25 2011 +0200&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@elte.hu&#34;&gt;mingo@elte.hu&lt;/a&gt;&lt;br /&gt;
CommitDate: Thu Jul 21 18:01:46 2011 +0200&lt;br /&gt;
    sched, cgroup: Optimize load_balance_fair()&lt;br /&gt;
    Use for_each_leaf_cfs_rq() instead of list_for_each_entry_rcu(), this&lt;br /&gt;
    achieves that load_balance_fair() only iterates those task_groups that&lt;br /&gt;
    actually have tasks on busiest, and that we iterate bottom-up, trying to&lt;br /&gt;
    move light groups before the heavier ones.&lt;/p&gt;

&lt;h1 id=&#34;throttling-entities&#34;&gt;Throttling entities&lt;/h1&gt;

&lt;p&gt;commit 85dac906bec3bb41bfaa7ccaa65c4706de5cfdf8&lt;br /&gt;
Author: Paul Turner &lt;a href=&#34;mailto:pjt@google.com&#34;&gt;pjt@google.com&lt;/a&gt;&lt;br /&gt;
Date:   Thu Jul 21 09:43:33 2011 -0700&lt;br /&gt;
    sched: Add support for throttling group entities&lt;br /&gt;
    Now that consumption is tracked (via update_curr()) we add support to throttle&lt;br /&gt;
    group entities (and their corresponding cfs_rqs) in the case where this is no&lt;br /&gt;
    run-time remaining.&lt;/p&gt;

&lt;h1 id=&#34;pelt&#34;&gt;PELT&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/531853/&#34;&gt;Per-entity load tracking&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;commit 5b51f2f80b3b906ce59bd4dce6eca3c7f34cb1b9&lt;br /&gt;
Author: Paul Turner &lt;a href=&#34;mailto:pjt@google.com&#34;&gt;pjt@google.com&lt;/a&gt;&lt;br /&gt;
Date:   Thu Oct 4 13:18:32 2012 +0200&lt;br /&gt;
    sched: Make __update_entity_runnable_avg() fast&lt;br /&gt;
commit a481db34b9beb7a9647c23f2320dd38a2b1d681f&lt;br /&gt;
Refs: v4.11-rc2-229-ga481db34b9be&lt;br /&gt;
Author:     Yuyang Du &lt;a href=&#34;mailto:yuyang.du@intel.com&#34;&gt;yuyang.du@intel.com&lt;/a&gt;&lt;br /&gt;
AuthorDate: Mon Feb 13 05:44:23 2017 +0800&lt;br /&gt;
Commit:     Ingo Molnar &lt;a href=&#34;mailto:mingo@kernel.org&#34;&gt;mingo@kernel.org&lt;/a&gt;&lt;br /&gt;
CommitDate: Thu Mar 30 09:43:41 2017 +0200&lt;br /&gt;
    sched/fair: Optimize ___update_sched_avg()&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>System booting</title>
      <link>http://firoyang.org/cs/boot/</link>
      <pubDate>Thu, 12 Nov 2015 00:00:00 UTC</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/boot/</guid>
      <description>

&lt;h1 id=&#34;smp-boot&#34;&gt;SMP boot&lt;/h1&gt;

&lt;p&gt;Check SDM v3 BSP and AP Processors&lt;br /&gt;
BSP - boot strap processor； AP - application processor&lt;/p&gt;

&lt;h2 id=&#34;core-commit&#34;&gt;Core commit&lt;/h2&gt;

&lt;p&gt;setup_real_mode-&amp;gt; trampoline_header-&amp;gt;start = (u64) secondary_startup_64;&lt;br /&gt;
commit f37240f16bec91f15ce564515f70a6ca9715ce96&lt;br /&gt;
Author: Jarkko Sakkinen &lt;a href=&#34;mailto:jarkko.sakkinen@intel.com&#34;&gt;jarkko.sakkinen@intel.com&lt;/a&gt;&lt;br /&gt;
Date:   Tue May 8 21:22:43 2012 +0300&lt;br /&gt;
    x86, realmode: header for trampoline code&lt;/p&gt;

&lt;h2 id=&#34;bsp&#34;&gt;BSP&lt;/h2&gt;

&lt;h3 id=&#34;build-time-for-real-mode-header-in-arch-x86-realmode-rm-header-s&#34;&gt;Build time for real_mode_header in arch/x86/realmode/rm/header.S&lt;/h3&gt;

&lt;p&gt;In pasyms.h, git gud!&lt;br /&gt;
pa_trampoline_header = trampoline_header;&lt;br /&gt;
pa_trampoline_start = trampoline_start;&lt;br /&gt;
pa_startup_32 = startup_32;&lt;br /&gt;
pa_startup_64 = startup_64;&lt;/p&gt;

&lt;h3 id=&#34;early-init&#34;&gt;Early init&lt;/h3&gt;

&lt;p&gt;setup_real_mode-&amp;gt; trampoline_header-&amp;gt;start = (u64) secondary_startup_64;  # tr_start&lt;/p&gt;

&lt;h3 id=&#34;start-kernel&#34;&gt;start_kernel&lt;/h3&gt;

&lt;p&gt;kernel_init-&amp;gt;smp_init-&amp;gt;cpu_up-&amp;gt;do_cpu_up-&amp;gt;_cpu_up-&amp;gt;&lt;br /&gt;
ap hp threadfn -&amp;gt; bringup_cpu -&amp;gt; __cpu_up -&amp;gt; smp_ops.cpu_up(cpu, tidle) is native_cpu_up&lt;br /&gt;
        do_boot_cpu is the core function. It set up the code for APs to run and check cpu_callin_mask.&lt;br /&gt;
        start_eip = real_mode_header-&amp;gt;trampoline_start;&lt;br /&gt;
        initial_code = (unsigned long)start_secondary                   # initial_code&lt;/p&gt;

&lt;h2 id=&#34;ap&#34;&gt;AP&lt;/h2&gt;

&lt;p&gt;trampoline_start -&amp;gt; &amp;hellip; -&amp;gt; startup_64 -&amp;gt; tr_start(%rip) is secondary_startup_64 -&amp;gt; initial_code(%rip) is start_secondary&lt;br /&gt;
-&amp;gt; cpu_init&lt;/p&gt;

&lt;h1 id=&#34;initrd&#34;&gt;initrd&lt;/h1&gt;

&lt;p&gt;related code:&lt;br /&gt;
reserve_initrd&lt;br /&gt;
subsys_initcall(genhd_device_init);-&amp;gt;kobj_map_init{bdev_map.probe.get = base_probe}&lt;br /&gt;
subsys_initcall(init_scsi);4-&amp;gt;scsi_sysfs_register{autoprobe = 1;}&lt;br /&gt;
rootfs_initcall(populate_rootfs);-&amp;gt;{unpack_to_rootfs; 解压initramfs到rootfs}&lt;br /&gt;
module_initinit_sd;6-&amp;gt;scsi_register_driver -&amp;gt;driver_register-&amp;gt;bus_add_driver -&amp;gt;driver_attach -&amp;gt;driver_probe_device-&amp;gt; drv-&amp;gt;probe(dev)=sd_probe_async-&amp;gt;add_disk -&amp;gt; register_disk -&amp;gt; get_gendisk -&amp;gt; kobj_lookup { bdev_map.probe.get()=base_probe(){request_module}}&lt;/p&gt;

&lt;h1 id=&#34;vs-initramfs&#34;&gt;vs initramfs&lt;/h1&gt;

&lt;p&gt;initrd is image with specific fs type, like ext2, need driver built-in kernel.&lt;br /&gt;
initramfs is a cpio, like tar only simpler, populated to rootfs in kernel, with fs type rootfs&lt;/p&gt;

&lt;h1 id=&#34;root-device&#34;&gt;root device&lt;/h1&gt;

&lt;p&gt;Related code:&lt;br /&gt;
root= name_to_dev_t, mount_root in prepare_namespace&lt;/p&gt;

&lt;h1 id=&#34;kernel-boot-process&#34;&gt;kernel boot process&lt;/h1&gt;

&lt;p&gt;Documentation/x86/boot.txt&lt;br /&gt;
&lt;a href=&#34;https://manybutfinite.com/post/kernel-boot-process/&#34;&gt;The Kernel Boot Process&lt;/a&gt;&lt;br /&gt;
arch/x86/boot/header.S::start_of_setup&lt;br /&gt;
arch/x86/boot/main.c::main()&lt;br /&gt;
    arch/x86/boot/memory.c::detect_memory()&lt;br /&gt;
    arch/x86/boot/memory.c::detect_memory_e820() = boot_params.e820_entries&lt;br /&gt;
    arch/x86/boot/pm.c::go_to_protected_mode()&lt;br /&gt;
arch/x86/boot/pmjump.S::protected_mode_jump&lt;br /&gt;
arch/x86/kernel/compressed/head_64.S::startup_32&lt;br /&gt;
arch/x86/kernel/compressed/head_64.S::startup_64&lt;br /&gt;
arch/x86/kernel/head_64.S::startup_64&lt;br /&gt;
kernel/main.c::start_kernel()&lt;/p&gt;

&lt;h2 id=&#34;reloctaion-for-decompress&#34;&gt;Reloctaion for decompress&lt;/h2&gt;

&lt;p&gt;974f221c84b05b1dc2f5ea50dc16d2a9d1e95eda&lt;br /&gt;
x86/boot: Move compressed kernel to the end of the decompression buffer&lt;/p&gt;

&lt;h2 id=&#34;horrable-commit-description-on-phys-base&#34;&gt;Horrable commit description on phys_base&lt;/h2&gt;

&lt;p&gt;commit 1ab60e0f72f71ec54831e525a3e1154f1c092408&lt;br /&gt;
Author: Vivek Goyal &lt;a href=&#34;mailto:vgoyal@in.ibm.com&#34;&gt;vgoyal@in.ibm.com&lt;/a&gt;&lt;br /&gt;
Date:   Wed May 2 19:27:07 2007 +0200&lt;br /&gt;
    [PATCH] x86-64: Relocatable Kernel Support&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Computer architecture</title>
      <link>http://firoyang.org/cs/arch/</link>
      <pubDate>Tue, 13 Oct 2015 00:00:00 UTC</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/arch/</guid>
      <description>

&lt;h1 id=&#34;computer-architecture&#34;&gt;Computer architecture&lt;/h1&gt;

&lt;p&gt;[Who are the Computer Architects?]&lt;a href=&#34;https://people.cs.clemson.edu/~mark/architects.html&#34;&gt;https://people.cs.clemson.edu/~mark/architects.html&lt;/a&gt;&lt;br /&gt;
The Mathematical Theory of Communication&lt;br /&gt;
Given a symbol level, the architecture is the description of the system in  whatever system-description scheme exists next below the symbol level. - Newell, 1990, p. 81&lt;br /&gt;
Digital Design and Computer Architecture 2nd Edition&lt;br /&gt;
Computer Organization and Design 5th Edition&lt;br /&gt;
Structured Computer Organization 6th Edition&lt;br /&gt;
Write Great Code: Volume 1: Understanding the Machine&lt;/p&gt;

&lt;h2 id=&#34;subfields&#34;&gt;Subfields&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Architectural_state&#34;&gt;Architectural state&lt;/a&gt;&lt;br /&gt;
Microarchitectural state, such as information stored in TLBs and caches&lt;/p&gt;

&lt;h1 id=&#34;circuits&#34;&gt;Circuits&lt;/h1&gt;

&lt;p&gt;A Symbolic Analysis of Relay and Switching Circuits&lt;/p&gt;

&lt;h1 id=&#34;cpu&#34;&gt;CPU&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://youtu.be/cNN_tTXABUA&#34;&gt;How a CPU Works&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;isa&#34;&gt;ISA&lt;/h2&gt;

&lt;p&gt;ISA: memory model, registers, data types, instructions, word size(?).&lt;br /&gt;
Memory model: unit of address resolution, word, aligment, address space, addressing mode, memory barrier/memory order primitive&amp;rsquo;s semantics.&lt;/p&gt;

&lt;h2 id=&#34;data-struct-alignment&#34;&gt;Data struct alignment&lt;/h2&gt;

&lt;p&gt;struct foo { char c; int i;};&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/unaligned-memory-access.txt&#34;&gt;UNALIGNED MEMORY ACCESSES&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://pzemtsov.github.io/2016/11/06/bug-story-alignment-on-x86.html&#34;&gt;A bug story: data alignment on x86&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.catb.org/esr/structure-packing/&#34;&gt;The Lost Art of C Structure Packing&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://en.wikipedia.org/wiki/Data_structure_alignment#Typical_alignment_of_C_structs_on_x86&#34;&gt;Typical alignment of C structs on x86&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;reasons-for-not-alignment&#34;&gt;Reasons for not alignment&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Casting variables to types of different lengths, e.g. char * to int *&lt;br /&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pointer arithmetic followed by access to at least 2 bytes of data , 不太理解.&lt;/p&gt;

&lt;h3 id=&#34;programming-skills&#34;&gt;Programming skills&lt;/h3&gt;

&lt;p&gt;Reorder members of struct;&lt;br /&gt;
get/put_unaligned to avoid analigned access.&lt;br /&gt;
attribute aligned&lt;/p&gt;

&lt;h3 id=&#34;calculate-the-sizeof-of-aligned-c-struct&#34;&gt;Calculate the sizeof of aligned c struct&lt;/h3&gt;

&lt;p&gt;Data alignment means putting the data at a memory address equal to some multiple of the word size, which increases the system&amp;rsquo;s performance due to the way the CPU handles memory.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;find the widest scalar member and attribute( aligned(x)) to determin alignment.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;fill the member to alignement without wrap&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pading to alignment&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;endianess-and-bitfield&#34;&gt;Endianess and bitfield&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gcc.gnu.org/onlinedocs/gcc/Structures-unions-enumerations-and-bit-fields-implementation.html&#34;&gt;The order of allocation of bit-fields within a unit&lt;/a&gt;&lt;br /&gt;
It&amp;rsquo;s Determined by ABI not Gcc. Check comments on &lt;a href=&#34;https://stackoverflow.com/questions/47600584/bitfield-endianness-in-gcc&#34;&gt;Bitfield endianness in gcc&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;how-endianness-effects-bitfield-packing-http-mjfrazer-org-mjfrazer-bitfields&#34;&gt;&lt;a href=&#34;http://mjfrazer.org/mjfrazer/bitfields/&#34;&gt;How Endianness Effects Bitfield Packing&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;if defined(__LITTLE_ENDIAN_BITFIELD)&lt;br /&gt;
    __u8    ihl:4,&lt;br /&gt;
        version:4;  # MSB, check wikipeida ipv4 header&lt;/p&gt;

&lt;h3 id=&#34;gcc-bug-on-bitfield&#34;&gt;GCC bug on bitfield&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/478657/&#34;&gt;Betrayed by a bitfield&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;dma&#34;&gt;DMA&lt;/h1&gt;

&lt;p&gt;Check books COD, COA and ULK 3rd&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Algorithms and data structues</title>
      <link>http://firoyang.org/cs/algorithm/</link>
      <pubDate>Wed, 27 May 2015 12:42:12 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/algorithm/</guid>
      <description>

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://cstheory.stackexchange.com/questions/19759/core-algorithms-deployed#&#34;&gt;Core algorithms deployed&lt;/a&gt;&lt;br /&gt;
Algorithms: Design Techniques and Analysis&lt;br /&gt;
The Algorithm Design Manual 2nd Edition&lt;/p&gt;

&lt;h1 id=&#34;leetcode&#34;&gt;Leetcode&lt;/h1&gt;

&lt;h2 id=&#34;http-joshuablog-herokuapp-com-leetcode-e6-80-bb-e7-bb-93-html-e5-a5-97-e8-b7-af&#34;&gt;&lt;a href=&#34;http://joshuablog.herokuapp.com/Leetcode-%E6%80%BB%E7%BB%93.html#%E5%A5%97%E8%B7%AF&#34;&gt;http://joshuablog.herokuapp.com/Leetcode-%E6%80%BB%E7%BB%93.html#%E5%A5%97%E8%B7%AF&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;如果问最短，最少，BFS&lt;br /&gt;
如果问连通性，静态就是 DFS,BFS，动态就 UF&lt;br /&gt;
如果问依赖性就 topo sort&lt;br /&gt;
DAG 的问题就 dfs+memo&lt;br /&gt;
矩阵和 Array 通常都是 DP&lt;br /&gt;
问数量的通常都是 DP&lt;br /&gt;
问是否可以，也很有可能 DP&lt;br /&gt;
求所有解的，基本 backtracking&lt;br /&gt;
排序总是可以想一想的&lt;br /&gt;
万事总可以想HashMap&lt;br /&gt;
找规律试试Stack&lt;/p&gt;

&lt;h2 id=&#34;漫谈leetcode解题思路-https-sophiesongge-github-io-leetcode-2017-01-19-get-random-html&#34;&gt;&lt;a href=&#34;https://sophiesongge.github.io/leetcode/2017/01/19/get-random.html&#34;&gt;漫谈LeetCode解题思路&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;1p3c&#34;&gt;1p3c&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.1point3acres.com/bbs/thread-270312-1-1.html&#34;&gt;http://www.1point3acres.com/bbs/thread-270312-1-1.html&lt;/a&gt;&lt;br /&gt;
最终我觉得像word search12， word break12，word ladder12，LIS，sort color，LRU，insert &amp;amp; delete in O1，rob house123，234sum这种题要达到闭眼秒杀的程度，min/max heap，bucket sort，topological sort，binary pre/in/post/level 遍历，combination/permutation这种东西要做梦都梦到&lt;br /&gt;
最后祝lz好运，加油~&lt;/p&gt;

&lt;h2 id=&#34;why-do-we-have-to-solve-leetcode-problems&#34;&gt;Why do we have to solve leetcode problems?&lt;/h2&gt;

&lt;p&gt;尤其是在北美，Google，Facebook，Microsoft，Amazon 等等大公司，无一不考刷题，以算法面试为主。而无论是北美留学生，还是工作几年的上班族，想进大公司，唯一的出路就是刷题。&lt;br /&gt;
&lt;a href=&#34;https://cspiration.com/leetcodeClassification&#34;&gt;Leetcode 分类顺序表第二版&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;computational-complexity-theory&#34;&gt;Computational complexity theory&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://bigocheatsheet.com/&#34;&gt;http://bigocheatsheet.com/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;core-conceptions&#34;&gt;Core conceptions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;representations&lt;br /&gt;
&lt;a href=&#34;https://www.geeksforgeeks.org/binary-tree-array-implementation/&#34;&gt;Linked vs sequential&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;ADT vs data structure&lt;br /&gt;
ADT is a data type defined by its behavior.&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Data_type#Abstract_data_types&#34;&gt;Any type that does not specify an implementation is an abstract data type.&lt;/a&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;linked-list&#34;&gt;Linked list&lt;/h1&gt;

&lt;h2 id=&#34;static-linked-list&#34;&gt;Static linked list&lt;/h2&gt;

&lt;p&gt;Reprented in an array.&lt;/p&gt;

&lt;h2 id=&#34;internal-vs-external-liked&#34;&gt;Internal vs external liked&lt;/h2&gt;

&lt;p&gt;Sometimes, SLUB put freelist in object&lt;/p&gt;

&lt;h2 id=&#34;kernel-doubly-linked-list-operations&#34;&gt;kernel doubly linked list operations&lt;/h2&gt;

&lt;h3 id=&#34;add&#34;&gt;add&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;kernel version&lt;br /&gt;
next-&amp;gt;prev = new;&lt;br /&gt;
new-&amp;gt;next = next;&lt;br /&gt;
new-&amp;gt;prev = prev;&lt;br /&gt;
prev-&amp;gt;next = new;&lt;/p&gt;

&lt;h3 id=&#34;delete&#34;&gt;delete&lt;/h3&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kernel version&lt;br /&gt;
next-&amp;gt;prev = prev;&lt;br /&gt;
WRITE_ONCE(prev-&amp;gt;next, next);&lt;br /&gt;
entry-&amp;gt;next = LIST_POISON1;&lt;br /&gt;
entry-&amp;gt;prev = LIST_POISON2;&lt;/p&gt;

&lt;h1 id=&#34;bl-list&#34;&gt;BL list&lt;/h1&gt;

&lt;p&gt;kernel: add bl_list - 4e35e6070b1ceed89c3bba2af4216c286fb1dafd&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;double-linked-list&#34;&gt;Double linked list&lt;/h1&gt;

&lt;h1 id=&#34;associative-array&#34;&gt;Associative array&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=qTZJLJ3Gm6Q&#34;&gt;Essentials: Brian Kernighan on Associative Arrays - Computerphile&lt;/a&gt;&lt;br /&gt;
vs indexed array&lt;/p&gt;

&lt;h2 id=&#34;associativity&#34;&gt;Associativity&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;trade-off&lt;br /&gt;
a) Checking more places takes more power and chip area,&lt;br /&gt;
b) and potentially more time. On the other hand, caches with more associativity suffer fewer misses&lt;br /&gt;
fully associative - the best miss rates, but practical only for a small number of entries&lt;br /&gt;
N-way set associative cache: 8 is a common choice for later implementations&lt;br /&gt;
direct-mapped cache - if two locations map to the same entry, they may continually knock each other out. anti-fragmantion worsens this case.&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;judy-array&#34;&gt;Judy array&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://judy.sourceforge.net/&#34;&gt;http://judy.sourceforge.net/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;hashtable&#34;&gt;Hashtable&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/510202/&#34;&gt;A generic hash table&lt;/a&gt;&lt;br /&gt;
hash function&lt;/p&gt;

&lt;h2 id=&#34;hlist-nulls&#34;&gt;hlist-nulls&lt;/h2&gt;

&lt;p&gt;commit bbaffaca4810de1a25e32ecaf836eeaacc7a3d11&lt;br /&gt;
Refs: v2.6.28-rc4-513-gbbaffaca4810&lt;br /&gt;
Author:     Eric Dumazet &lt;a href=&#34;mailto:dada1@cosmosbay.com&#34;&gt;dada1@cosmosbay.com&lt;/a&gt;&lt;br /&gt;
AuthorDate: Sun Nov 16 19:37:55 2008 -0800&lt;br /&gt;
Commit:     David S. Miller &lt;a href=&#34;mailto:davem@davemloft.net&#34;&gt;davem@davemloft.net&lt;/a&gt;&lt;br /&gt;
CommitDate: Sun Nov 16 19:37:55 2008 -0800&lt;br /&gt;
    rcu: Introduce hlist_nulls variant of hlist&lt;br /&gt;
    hlist uses NULL value to finish a chain.&lt;br /&gt;
    hlist_nulls variant use the low order bit set to 1 to signal an end-of-list marker.&lt;br /&gt;
    This allows to store many different end markers, so that some RCU lockless&lt;br /&gt;
    algos (used in TCP/UDP stack for example) can save some memory barriers in&lt;br /&gt;
    fast paths.&lt;br /&gt;
&lt;a href=&#34;https://www.kernel.org/doc/Documentation/RCU/rculist_nulls.txt&#34;&gt;Usage of hilsit-nulls in kernel doc&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;bst&#34;&gt;BST&lt;/h1&gt;

&lt;p&gt;Pre-order&lt;br /&gt;
In-order traversal&lt;br /&gt;
Post-order&lt;br /&gt;
postfix and prefix and sort&lt;/p&gt;

&lt;h1 id=&#34;graph&#34;&gt;Graph&lt;/h1&gt;

&lt;h1 id=&#34;depth-first-sarch&#34;&gt;Depth first sarch&lt;/h1&gt;

&lt;p&gt;DAG&lt;/p&gt;

&lt;h1 id=&#34;interval-tree-in-kernel&#34;&gt;Interval tree in kernel&lt;/h1&gt;

&lt;p&gt;anonymous page: anon_vma_interval_tree_insert&lt;/p&gt;

&lt;h1 id=&#34;trie&#34;&gt;Trie&lt;/h1&gt;

&lt;p&gt;Trie is prefix tree.&lt;br /&gt;
Trees only store keys.&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=AXjmTQ8LEoI&#34;&gt;Trie Data Structure&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=MC-iQHFdEDI&#34;&gt;Trie with numeric key&lt;/a&gt;&lt;br /&gt;
* terms very confused&lt;br /&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/14708134/what-is-the-difference-between-trie-and-radix-trie-data-structures&#34;&gt;Radix tree vs Trie, check radix meaning&lt;/a&gt;&lt;br /&gt;
Patricia is compact trie or Patricia is radix = 2 trie?&lt;/p&gt;

&lt;h1 id=&#34;search&#34;&gt;Search&lt;/h1&gt;

&lt;p&gt;Data property: unique key, indexed&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Search_data_structure&#34;&gt;Search data structure&lt;/a&gt;&lt;br /&gt;
Sequencial array: binary search&lt;br /&gt;
Associative array&lt;br /&gt;
BST&lt;br /&gt;
Hashtable&lt;/p&gt;

&lt;h2 id=&#34;which-algorithm&#34;&gt;Which algorithm?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.geeksforgeeks.org/advantages-of-bst-over-hash-table/&#34;&gt;Advantages of BST over Hash Table&lt;/a&gt;&lt;br /&gt;
1. Can get all keys in sorted order  by just doing in-order traversal of BST&lt;br /&gt;
2. Doing order statistics, finding closest lower and greater elements, doing range  queries  are easy to do with BSTs.&lt;br /&gt;
3. BSTs are easy to implement compared to hashing.&lt;br /&gt;
4. With Self Balancing BSTs, all operations are guarnateed to work in O(logN) time.&lt;/p&gt;

&lt;h1 id=&#34;replacement-polices&#34;&gt;Replacement polices&lt;/h1&gt;

&lt;p&gt;Pseudo-LRU&lt;/p&gt;

&lt;h1 id=&#34;lru&#34;&gt;LRU&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://leetcode.com/problems/lru-cache/description/&#34;&gt;Leetcode 146 LRU cache&lt;/a&gt;&lt;br /&gt;
Order items by access times&lt;/p&gt;

&lt;h2 id=&#34;pseudo-lru-2-second-chance-and-queue&#34;&gt;Pseudo LRU/2 - Second chance and queue&lt;/h2&gt;

&lt;p&gt;type: Reclaim&lt;br /&gt;
Order items by enqueueing sequence&lt;br /&gt;
dcache&lt;/p&gt;

&lt;h2 id=&#34;second-chance-and-2q-https-pdfs-semanticscholar-org-d62d-e5f995164fff50f5ce61c0113f6bc9f04225-pdf&#34;&gt;Second chance and &lt;a href=&#34;https://pdfs.semanticscholar.org/d62d/e5f995164fff50f5ce61c0113f6bc9f04225.pdf&#34;&gt;2Q&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Page reclaim algorithm&lt;br /&gt;
type: Reclaim&lt;/p&gt;

&lt;h1 id=&#34;ring-buffer-or-circular-buffer&#34;&gt;Ring buffer or Circular buffer&lt;/h1&gt;

&lt;h1 id=&#34;redblack-tree&#34;&gt;Redblack tree&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://tinylab.org/rbtree-part1/&#34;&gt;红黑树 IN Linux part 1, 2, 3&lt;/a&gt;&lt;br /&gt;
gap between linar node can be optimized by argument rb tree. O(n) -&amp;gt; O(log n)&lt;br /&gt;
mm: augment vma rbtree with rb_subtree_gap d37371870ceb1d2165397dc36114725b6dca946c&lt;br /&gt;
&lt;a href=&#34;http://sidsen.azurewebsites.net//papers/rb-trees-talg.pdf&#34;&gt;Rank-Balanced Trees&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://leetcode.com/problems/count-of-smaller-numbers-after-self/description/&#34;&gt;https://leetcode.com/problems/count-of-smaller-numbers-after-self/description/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://yuex.in/post/2017/08/red-black-tree-in-action.html&#34;&gt;http://yuex.in/post/2017/08/red-black-tree-in-action.html&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.cs.princeton.edu/~rs/talks/LLRB/08Dagstuhl/RedBlack.pdf&#34;&gt;Left-Leaning Red-Black Trees&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;history&#34;&gt;History&lt;/h2&gt;

&lt;p&gt;AVL tree, B-tree, symmetric binary B-tree or 2–3–4 tree, red–black tree&lt;br /&gt;
&lt;a href=&#34;https://www.cs.purdue.edu/homes/ayg/CS251/slides/chap13b.pdf&#34;&gt;2-3-4 Trees and RedBlack Trees&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The art of debugging</title>
      <link>http://firoyang.org/cs/debugging/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:14 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/debugging/</guid>
      <description>

&lt;h1 id=&#34;quote&#34;&gt;Quote&lt;/h1&gt;

&lt;p&gt;Everyone knows that debugging is twice as hard as writing a program in the first place. So if you&amp;rsquo;re as clever as you can be when you write it, how will you ever debug it? &amp;ndash; &amp;ldquo;The Elements of Programming Style&amp;rdquo;, 2nd edition, chapter 2. Brian Kernighan&lt;/p&gt;

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;Debug hacks (a Japanese book)&lt;/p&gt;

&lt;h1 id=&#34;debugging&#34;&gt;Debugging&lt;/h1&gt;

&lt;p&gt;Bug or error analysis.&lt;br /&gt;
This world is built on causality, cause and effect.&lt;br /&gt;
Root cause -&amp;gt; series of causes and effects -&amp;gt; bug.&lt;br /&gt;
What is debugging? It&amp;rsquo;s &lt;a href=&#34;https://en.wikipedia.org/wiki/Abductive_reasoning#Logic-based_abduction&#34;&gt;Abductive reasoning&lt;/a&gt;.&lt;br /&gt;
We infer the root cause with observations.&lt;br /&gt;
Observations -&amp;gt; Infer -&amp;gt; Causes -&amp;gt; Increase obsevability -&amp;gt; more observations -&amp;gt; &amp;hellip; -&amp;gt; Root causes&lt;/p&gt;

&lt;h2 id=&#34;performance-issues-vs-error-issues&#34;&gt;Performance issues vs Error issues&lt;/h2&gt;

&lt;p&gt;Performance issues: bottleneck&lt;br /&gt;
Error issues: crash, lockup&lt;/p&gt;

&lt;h2 id=&#34;error-issues-analysis-methodology&#34;&gt;Error issues analysis - methodology&lt;/h2&gt;

&lt;h3 id=&#34;execution-id&#34;&gt;Execution ID&lt;/h3&gt;

&lt;p&gt;Stack backtrace&lt;br /&gt;
PID, TID. Interrupt/execption number or hanlder,&lt;/p&gt;

&lt;h3 id=&#34;structuralism-concurrency-life-cycle-lock&#34;&gt;Structuralism: concurrency, life cycle, lock.&lt;/h3&gt;

&lt;p&gt;Expected/intended behavior vs actual behavior.&lt;/p&gt;

&lt;h3 id=&#34;timeline-put-observations-on-a-timeline&#34;&gt;Timeline - put observations on a timeline&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://bugzilla.suse.com/show_bug.cgi?id=1163735&#34;&gt;IO hang issue at OS layer&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;observations-todo&#34;&gt;Observations #TODO&lt;/h1&gt;

&lt;h1 id=&#34;inference&#34;&gt;Inference&lt;/h1&gt;

&lt;h2 id=&#34;scientific-method-hypothses-narrow-down&#34;&gt;Scientific method: Hypothses, narrow down&lt;/h2&gt;

&lt;h1 id=&#34;causes&#34;&gt;Causes&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.infradead.org/~mchehab/kernel_docs/dev-tools/kcsan.html#data-races&#34;&gt;Data-race from kernel&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/804813/&#34;&gt;Race conditions vs. data races&lt;/a&gt;&lt;br /&gt;
Instruction fetch fault: exception RIP: unknown or invalid address&lt;/p&gt;

&lt;h1 id=&#34;increase-observability-based-on-causes-more-tools-need-to-be-created&#34;&gt;Increase observability based on causes - more tools need to be created.&lt;/h1&gt;

&lt;p&gt;Data-race detector: &lt;a href=&#34;https://lwn.net/Articles/816850/&#34;&gt;Concurrency bugs should fear the big bad data-race detector (part 1)&lt;/a&gt;&lt;br /&gt;
Race condition detector: e.g. &lt;a href=&#34;https://www.redhat.com/archives/crash-utility/2007-September/msg00002.html&#34;&gt;the rb-tree race detector used in bsc#1167133&lt;/a&gt;&lt;br /&gt;
Instruction fetch fault: Prevent page fault handler from overwriting unwound stack frames. See attachment &lt;a href=&#34;http://bugzilla.suse.com/show_bug.cgi?id=1154385&#34;&gt;System crashing daily around midnight with unable to handle kernel paging request&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;bug-classifications&#34;&gt;Bug classifications&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Software_bug#Types&#34;&gt;Software bug types&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://cwe.mitre.org/data/definitions/1000.html&#34;&gt;CWE VIEW: Research Concepts&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://cwe.mitre.org/data/definitions/1003.html&#34;&gt;CWE VIEW: Simplified Mapping&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://cwe.mitre.org/data/definitions/699.html&#34;&gt;CWE VIEW: Development Concepts&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;hardware-bugs&#34;&gt;Hardware Bugs&lt;/h2&gt;

&lt;p&gt;If this has only happened on a single physical machine, I suggest that machine be considered to be faulty.&lt;/p&gt;

&lt;h2 id=&#34;memory-corruption&#34;&gt;Memory corruption&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://cwe.mitre.org/data/definitions/119.html&#34;&gt;The generic term &amp;ldquo;memory corruption&amp;rdquo;&lt;/a&gt;is often used to describe the consequences of writing to memory outside the bounds of a buffer, when the root cause is something other than a sequential copies of excessive data from a fixed starting location(i.e., classic buffer overflows or CWE-120). This may include issues such as incorrect pointer arithmetic, accessing invalid pointers due to incomplete initialization or memory release, etc.]&lt;br /&gt;
&lt;a href=&#34;https://bugzilla.suse.com/show_bug.cgi?id=1155930#c12&#34;&gt;An example by Neil Brown: The corrupted list of inodes could be due to one inode being freed and re-used while still on the list - or it could be due to memory corruption of a forward pointer.&lt;/a&gt;&lt;br /&gt;
Memory corruption is one of the most intractable class of programming errors, for two reasons:&lt;br /&gt;
The source of the memory corruption and its manifestation may be far apart, making it hard to correlate the cause and the effect.&lt;br /&gt;
Symptoms appear under unusual conditions, making it hard to consistently reproduce the error.&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Memory_corruption&#34;&gt;Memory corruption&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Memory_safety&#34;&gt;Memory safety&lt;/a&gt;&lt;br /&gt;
uninitialized memory: &lt;a href=&#34;https://en.wikipedia.org/wiki/Dangling_pointer#Cause_of_wild_pointers&#34;&gt;wild pointer&lt;/a&gt;&lt;br /&gt;
use after free: &lt;a href=&#34;https://en.wikipedia.org/wiki/Dangling_pointer#Cause_of_dangling_pointers&#34;&gt;dangling pointer&lt;/a&gt;&lt;br /&gt;
buffer overflow:&lt;br /&gt;
unknown source memory corruption: The generic &amp;ldquo;memory corruption&amp;rdquo;.&lt;br /&gt;
memory leak:&lt;/p&gt;

&lt;h1 id=&#34;anti-debugging&#34;&gt;Anti-debugging&lt;/h1&gt;

&lt;p&gt;Syntax checking: gcc -Wall, bash -n&lt;br /&gt;
static code analysis: smatch&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The art of programming</title>
      <link>http://firoyang.org/cs/programming/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:14 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/programming/</guid>
      <description>

&lt;h1 id=&#34;computer-programming&#34;&gt;Computer programming&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cs.princeton.edu/~bwk/tpop.webpage/&#34;&gt;The practice of programming&lt;/a&gt;, &lt;a href=&#34;http://www.ccs.neu.edu/home/matthias/HtDP2e/&#34;&gt;How to design programs&lt;/a&gt;, &lt;a href=&#34;http://sarabander.github.io/sicp/&#34;&gt;SICP&lt;/a&gt;, and Elements of programming.&lt;br /&gt;
Reentrancy&lt;/p&gt;

&lt;h1 id=&#34;concurrent-programming&#34;&gt;Concurrent programming&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cs.utexas.edu/users/EWD/transcriptions/EWD01xx/EWD123.html&#34;&gt;Firo: must thinking summary: EW Dijkstra: Cooperating sequential processes&lt;/a&gt;&lt;br /&gt;
CSAPP3e: Chapter 12 concurrent programming&lt;br /&gt;
Parallel and Concurrent Programming in Haskell&lt;br /&gt;
The origin of concurrent programming: from semaphores to remote procedure calls - Per Brinch Hansen&lt;br /&gt;
&lt;a href=&#34;https://www.dcl.hpi.uni-potsdam.de/teaching/pvprog/Slides/C1_concurrency.pdf&#34;&gt;Introduction on history of concurrency: Shared-Memory Concurrency&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=2771951&#34;&gt;Turing lecture: The computer science of concurrency: the early years&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/355700/&#34;&gt;Firo: example: Concurrency-managed workqueues&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://talks.golang.org/2012/concurrency.slide#6&#34;&gt;Rob Pike: Concurrency is the composition of independently executing computations.&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;asynchrony-computer-programming-https-en-wikipedia-org-wiki-asynchrony-computer-programming&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Asynchrony_(computer_programming)&#34;&gt;Asynchrony (computer programming)&lt;/a&gt;&lt;/h2&gt;

&lt;h2 id=&#34;process-vs-event&#34;&gt;process vs event&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://courses.cs.vt.edu/cs5204/fall09-kafura/Presentations/Threads-VS-Events.pdf&#34;&gt;thread vs event&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;lock-free-programming&#34;&gt;Lock-free programming&lt;/h1&gt;

&lt;p&gt;ring buffer, rcu&lt;/p&gt;

&lt;h1 id=&#34;functional-programming&#34;&gt;Functional programming&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://spin.atomicobject.com/2012/11/01/hey-c-is-a-functional-language-too/&#34;&gt;CPS in C&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://en.wikipedia.org/wiki/Direct_style&#34;&gt;Continuation-passing style&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;programming-principles&#34;&gt;programming principles&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Category:Programming_principles&#34;&gt;Programming principles&lt;/a&gt;&lt;br /&gt;
High cohesion low coupling&lt;/p&gt;

&lt;h1 id=&#34;design-pattern&#34;&gt;Design pattern&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://lwn.net/Articles/336224/&#34;&gt;Linux kernel design patterns&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.cs.fsu.edu/~baker/devices/notes/patterns.html#&#34;&gt;Linux Kernel Programming Patterns&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;ipc&#34;&gt;IPC&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cyberiapc.com/os/ipc_whatisit.htm&#34;&gt;Busy waiting vs blocking&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;project-engineering&#34;&gt;Project engineering&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lists.kernelnewbies.org/pipermail/kernelnewbies/2012-March/004986.html&#34;&gt;kernel asm/asm-generic&lt;/a&gt;&lt;br /&gt;
asm stands for arch specific macros(FIXME).&lt;/p&gt;

&lt;h1 id=&#34;coding-style&#34;&gt;Coding style&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.gnu.org/prep/standards/standards.html&#34;&gt;GNU Coding Standards&lt;/a&gt;&lt;br /&gt;
比如GNU coding standards, Linux kernel coding style, Shell coding standard&lt;br /&gt;
* Label&lt;br /&gt;
It is considered to be safer that the label reflect what happens at the&lt;br /&gt;
destination, and not the reason for reaching the label. &amp;ndash;Julia&lt;/p&gt;

&lt;h1 id=&#34;good-taste&#34;&gt;Good taste&lt;/h1&gt;

&lt;p&gt;remove_list_entry(entry)&lt;br /&gt;
{&lt;br /&gt;
  // The &amp;ldquo;indirect&amp;rdquo; pointer points to the&lt;br /&gt;
  // &lt;em&gt;address&lt;/em&gt; of the thing we&amp;rsquo;ll update&lt;br /&gt;
  indirect = &amp;head;&lt;/p&gt;

&lt;p&gt;// Walk the list, looking for the thing that&lt;br /&gt;
  // points to the entry we want to remove&lt;/p&gt;

&lt;p&gt;while ((*indirect) != entry)&lt;br /&gt;
    indirect = &amp;amp;(*indirect)-&amp;gt;next;&lt;/p&gt;

&lt;p&gt;// .. and just remove it&lt;br /&gt;
  *indirect = entry-&amp;gt;next;&lt;br /&gt;
}&lt;/p&gt;

&lt;p&gt;remove_list_entry(entry)&lt;br /&gt;
{&lt;br /&gt;
  prev = NULL;&lt;br /&gt;
  walk = head;&lt;/p&gt;

&lt;p&gt;// Walk the list&lt;/p&gt;

&lt;p&gt;while (walk != entry) {&lt;br /&gt;
    prev = walk;&lt;br /&gt;
    walk = walk-&amp;gt;next;&lt;br /&gt;
  }&lt;/p&gt;

&lt;p&gt;// Remove the entry by updating the&lt;br /&gt;
  // head or the previous entry&lt;/p&gt;

&lt;p&gt;if (!prev)&lt;br /&gt;
    head = entry-&amp;gt;next;&lt;br /&gt;
  else&lt;br /&gt;
    prev-&amp;gt;head = entry-&amp;gt;next;&lt;br /&gt;
}&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The computing process</title>
      <link>http://firoyang.org/cs/task/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:12 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/cs/task/</guid>
      <description>

&lt;h1 id=&#34;timestamp&#34;&gt;Timestamp&lt;/h1&gt;

&lt;p&gt;se.sum_exec_runtime                          :             0.036973&lt;br /&gt;
se.avg.last_update_time                      :           1884199936&lt;/p&gt;

&lt;h1 id=&#34;pid&#34;&gt;Pid&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/531419/&#34;&gt;Namespaces in operation, part 3: PID namespaces&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/606925/&#34;&gt;PID, PGID, SID, PIDTYPE_PID&lt;/a&gt;&lt;br /&gt;
task-&amp;gt;pid: thread id: unique&lt;br /&gt;
task-&amp;gt;tgid: task group id: child thread share parent&amp;rsquo;s tgid&lt;br /&gt;
Check copy_process&lt;/p&gt;

&lt;h1 id=&#34;stack-management&#34;&gt;stack management&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/600644/&#34;&gt;Expanding the kernel stack&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/692208/&#34;&gt;Virtually mapped kernel stacks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Related code:&lt;br /&gt;
task_struct-&amp;gt;stack:task_stack_page&lt;br /&gt;
task_struct-&amp;gt;thread.sp: top of stack&lt;br /&gt;
kernel_stack, cpu_current_top_of_stack&lt;/p&gt;

&lt;h2 id=&#34;x86-tss-and-sp0&#34;&gt;x86 TSS and sp0&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://lore.kernel.org/patchwork/patch/828764/&#34;&gt;x86/entry/64: Remove thread_struct::sp0&lt;/a&gt;:d375cf1530595e33961a8844192cddab913650e3&lt;br /&gt;
GDT -&amp;gt; TSS descriptor -&amp;gt; TSS&lt;br /&gt;
tss_struct cpu_tss, ltr, str&lt;br /&gt;
TSS: x86_hw_tss v3a: 7.7&lt;/p&gt;

&lt;h3 id=&#34;onset&#34;&gt;Onset&lt;/h3&gt;

&lt;p&gt;arch/x86/include/asm/desc.h&lt;br /&gt;
DECLARE_PER_CPU_PAGE_ALIGNED(struct gdt_page, gdt_page);        #===&amp;gt; GDT&lt;br /&gt;
arch/x86/kernel/process.c&lt;br /&gt;
DEFINE_PER_CPU_SHARED_ALIGNED(struct tss_struct, cpu_tss)       #===&amp;gt; tss_struct&lt;br /&gt;
start_kernel &amp;hellip; -&amp;gt;start_secondary and trap_init-&amp;gt;&lt;br /&gt;
cpu_init&lt;br /&gt;
        t-&amp;gt;x86_tss.io_bitmap_base = offsetof(struct tss_struct, io_bitmap);&lt;br /&gt;
        load_sp0(t, &amp;amp;current-&amp;gt;thread);  #===&amp;gt; tss-&amp;gt;x86_tss.sp0 = thread-&amp;gt;sp0&lt;br /&gt;
        set_tss_desc(cpu, t);           #===&amp;gt; set tss descriptor to GDT; tss descriptor.base = tss_struct&lt;br /&gt;
        load_TR_desc();                 #===&amp;gt; ltr&lt;br /&gt;
_do_fork -&amp;gt; copy_process&lt;br /&gt;
        dup_task_struct&lt;br /&gt;
                stack = alloc_thread_stack_node(tsk, node);             # ===&amp;gt; THREAD_SIZE 2 pages.&lt;br /&gt;
                tsk-&amp;gt;stack = stack;&lt;br /&gt;
        copy_thread_tls&lt;br /&gt;
                # arch/x86/include/asm/processor.h&lt;br /&gt;
                # #define task_pt_regs(tsk)       ((struct pt_regs *)(tsk)-&amp;gt;thread.sp0 - 1)&lt;br /&gt;
                p-&amp;gt;thread.sp0 = (unsigned long)task_stack_page(p) + THREAD_SIZE;        # task-&amp;gt;stack; THREAD_SIZE 2 pages;&lt;br /&gt;
                childregs = task_pt_regs(p);&lt;br /&gt;
                # struct fork_frame {&lt;br /&gt;
                #       struct inactive_task_frame frame;&lt;br /&gt;
                #       struct pt_regs regs;&lt;br /&gt;
                # };&lt;br /&gt;
                fork_frame = container_of(childregs, struct fork_frame, regs);&lt;br /&gt;
                p-&amp;gt;thread.sp = (unsigned long) fork_frame;&lt;br /&gt;
                *childregs = *current_pt_regs();&lt;br /&gt;
        # Add child task to run_queue. Then scheded.&lt;br /&gt;
__switch_to -&amp;gt; load_sp0(tss, next);&lt;/p&gt;

&lt;h3 id=&#34;nuclus&#34;&gt;nuclus&lt;/h3&gt;

&lt;p&gt;entry_SYSCALL_64 -&amp;gt; movq    PER_CPU_VAR(cpu_current_top_of_stack), %rsp&lt;/p&gt;

&lt;h2 id=&#34;idle-threads-and-their-kernel-stack&#34;&gt;idle threads and their kernel stack&lt;/h2&gt;

&lt;p&gt;Boot processor&amp;rsquo;s idle thread kernel stack is init/init_task.c:init_thread_union; init_task is pid 0;&lt;br /&gt;
Application processor&amp;rsquo;s idle thread are forked in idle_init; pids are both 0.&lt;/p&gt;

&lt;h1 id=&#34;kthread&#34;&gt;kthread&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.kernel.org/doc/Documentation/vm/active_mm.txt&#34;&gt;active_mm&lt;/a&gt;&lt;br /&gt;
kernel_thead-&amp;gt;kthread-&amp;gt;do_exit&lt;br /&gt;
PF_KTHREAD              0x00200000&lt;br /&gt;
PF_KSWAPD               0x00020000&lt;br /&gt;
PF_IDLE                 0x00000002      /* I am an IDLE thread &lt;em&gt;/&lt;br /&gt;
PF_VCPU                 0x00000010      /&lt;/em&gt; I&amp;rsquo;m a virtual CPU &lt;em&gt;/&lt;br /&gt;
PF_WQ_WORKER            0x00000020      /&lt;/em&gt; I&amp;rsquo;m a workqueue worker */&lt;br /&gt;
PID: 197    TASK: ffff8bc8dd350480  CPU: 0   COMMAND: &amp;ldquo;kswapd0&amp;rdquo;&lt;br /&gt;
  flags = 0xa20840,&lt;br /&gt;
PID: 19     TASK: ffff8bc214160780  CPU: 1   COMMAND: &amp;ldquo;kworker/1:0H&amp;rdquo;&lt;br /&gt;
  flags = 0x4208060,&lt;br /&gt;
crash&amp;gt; task -R flags&lt;br /&gt;
PID: 0      TASK: ffffffff880134c0  CPU: 0   COMMAND: &amp;ldquo;swapper/0&amp;rdquo;&lt;br /&gt;
  flags = 0x200102,&lt;br /&gt;
PID: 0      TASK: ffff8bc21476c500  CPU: 14  COMMAND: &amp;ldquo;swapper/14&amp;rdquo;&lt;br /&gt;
  flags = 0x200042,&lt;/p&gt;

&lt;h2 id=&#34;task-to-kthread&#34;&gt;task to kthread&lt;/h2&gt;

&lt;p&gt;to_kthread and vfork_done&lt;br /&gt;
commit 63706172f332fd3f6e7458ebfb35fa6de9c21dc5&lt;br /&gt;
Author: Oleg Nesterov &lt;a href=&#34;mailto:oleg@redhat.com&#34;&gt;oleg@redhat.com&lt;/a&gt;&lt;br /&gt;
Date:   Wed Jun 17 16:27:45 2009 -0700&lt;br /&gt;
kthreads: rework kthread_stop()&lt;/p&gt;

&lt;h1 id=&#34;exit&#34;&gt;exit&lt;/h1&gt;

&lt;p&gt;Zombie process &lt;defunct&gt;&lt;br /&gt;
forked child not reaped by parent will hooked in process list.&lt;br /&gt;
if parent was killed and exit &lt;defunct&gt; will repaped.&lt;/p&gt;

&lt;h1 id=&#34;wait&#34;&gt;wait&lt;/h1&gt;

&lt;p&gt;proc_evict_inode at ffffffff812696fd&lt;br /&gt;
evict at ffffffff8121cded&lt;br /&gt;
__dentry_kill at ffffffff812194b6&lt;br /&gt;
shrink_dentry_list at ffffffff8121a0c0&lt;br /&gt;
d_invalidate at ffffffff8121a8c8&lt;br /&gt;
proc_flush_task at ffffffff8126e609&lt;br /&gt;
release_task at ffffffff81081230  # wait_task_zombie&lt;br /&gt;
wait_consider_task at ffffffff81081c19&lt;br /&gt;
do_wait at ffffffff8108226d&lt;/p&gt;

&lt;h1 id=&#34;observation&#34;&gt;Observation&lt;/h1&gt;

&lt;p&gt;do_task_stat&lt;br /&gt;
Kernel mapping: tgid_base_stuff show_map_vma&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
