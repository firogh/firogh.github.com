<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Net on f(x) </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://firoyang.org/tags/net/</link>
    <language>en-us</language>
    <author>Firo Yang</author>
    
    <updated>Sun, 10 May 2015 15:46:13 CST</updated>
    
    <item>
      <title>Understanding linux netfilter</title>
      <link>http://firoyang.org/net/netfilter/</link>
      <pubDate>Sun, 10 May 2015 15:46:13 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/net/netfilter/</guid>
      <description>

&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.netfilter.org/documentation/HOWTO//netfilter-hacking-HOWTO.html&#34;&gt;Linux netfilter Hacking HOWTO&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.karlrupp.net/en/computer/nat_tutorial&#34;&gt;NAT - Network Address Translation&lt;/a&gt;&lt;br /&gt;
man iptables and man iptables-extension&lt;/p&gt;

&lt;h1 id=&#34;introduction-to-netfilter&#34;&gt;Introduction to netfilter&lt;/h1&gt;

&lt;p&gt;Netfilter 是Kernel提供在BSD socket API之外进行网络操作的框架.&lt;br /&gt;
Netfilter的本质就是内核协议栈上的Hook的集合.&lt;br /&gt;
对于ipv4 or ipv6分别有5个Hook点.正如Rusty Russell所言&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Firstly, each protocol defines &amp;ldquo;hooks&amp;rdquo; (IPv4 defines 5) which are well-defined points in a packet&amp;rsquo;s traversal of that protocol stack.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;到底什么是well-defined, 我个人理解就是这5个点可以cover住所有协议栈中的packet.&lt;br /&gt;
与Netfilter类似框架, 主要是BSD系的IPFilter, ipfirewall, PF, NPF等.&lt;br /&gt;
Netfilter的历史请查阅wikipedia.&lt;br /&gt;
内核基于netfilter构建了 iptables 和 connection track两套系统.&lt;br /&gt;
从这两个系统, 衍生出了众多的功能, 如防火墙filter, NAT, mangle, kproxy等等.&lt;br /&gt;
netfilter&lt;br /&gt;
ct| |iptables&lt;br /&gt;
nat,filter,mangle,kproxy,smartqos&lt;br /&gt;
当然, 也可能不依赖iptables 和 conntrack, 或者部分依赖.&lt;/p&gt;

&lt;h1 id=&#34;netfilter&#34;&gt;netfilter&lt;/h1&gt;

&lt;h2 id=&#34;source&#34;&gt;source&lt;/h2&gt;

&lt;p&gt;netfilter 公共: net/netfilter&lt;br /&gt;
ipv4协议的netfilter细节在: net/ipv4/netfilter/&lt;/p&gt;

&lt;h2 id=&#34;init&#34;&gt;Init&lt;/h2&gt;

&lt;p&gt;~/linux/net/netfilter/core.c&lt;br /&gt;
netfilter_init()&lt;/p&gt;

&lt;h2 id=&#34;hook-point&#34;&gt;Hook point&lt;/h2&gt;

&lt;p&gt;local_in local_out forward pre_routing post_routing&lt;/p&gt;

&lt;h1 id=&#34;iptables&#34;&gt;Iptables&lt;/h1&gt;

&lt;p&gt;Iptables is a packet selecttion system (包括内核和用户态两部分).&lt;br /&gt;
iptables 的ip是IP(Internet Protocol).&lt;br /&gt;
xtable是内核iptables抽象nat, mangle, filter(防火墙)的得到共有的部分.&lt;br /&gt;
&lt;a href=&#34;http://en.wikipedia.org/wiki/Iptables#Overview&#34;&gt;Overview of xtables in wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;details-of-iptables&#34;&gt;Details of iptables&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;iptables command&lt;br /&gt;
直观上iptables命令最重要的组成部分: table, chain, match 参数, -j target&lt;br /&gt;
如:iptables -t filter -I INPUT -p tcp &amp;ndash;dport 22 -j ACCEPT&lt;br /&gt;
特别: 从-p开始到-j 之前这是一个 match!&lt;br /&gt;
更多的match 和 target, please, man iptables-extension&lt;br /&gt;
一个table的内置chain,就是他所在的hook点.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;kernel code&lt;br /&gt;
ipt_do_table() 就是内核处理nat, filter, mangle的公用函数.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;step-of-exution&#34;&gt;Step of exution&lt;/h2&gt;

&lt;h3 id=&#34;init-1&#34;&gt;Init&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;如mangle表的初始化见iptable_mangle_init&lt;br /&gt;
xt_table: ipt_register_table&lt;br /&gt;
    struct xt_table         *iptable_filter;&lt;br /&gt;
    struct xt_table         *iptable_mangle;&lt;br /&gt;
    struct xt_table         *iptable_raw;&lt;br /&gt;
    struct xt_table         *arptable_filter;&lt;br /&gt;
    struct xt_table         *iptable_security;&lt;br /&gt;
    struct xt_table         *nat_table;&lt;br /&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如mark match的初始化 mark_mt_init&lt;br /&gt;
xt_match: xt_register_match&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如MARK target 的初始化 也在 mark_mt_init&lt;br /&gt;
xt_target: xt_register_target&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;the-mangle-journal&#34;&gt;The mangle journal&lt;/h3&gt;

&lt;p&gt;netfilter hook -&amp;gt;  iptable_mangle_hook -&amp;gt; ipt_do_table -&amp;gt;&amp;hellip;&lt;/p&gt;

&lt;h1 id=&#34;connection-tracking&#34;&gt;Connection tracking&lt;/h1&gt;

&lt;p&gt;Conntrack 的实现不依赖iptables, 很独立.&lt;/p&gt;

&lt;h2 id=&#34;init-2&#34;&gt;init&lt;/h2&gt;

&lt;p&gt;nf_conntrack_standalone_init()&lt;br /&gt;
nf_conntrack_l3proto_ipv4_init()&lt;/p&gt;

&lt;h2 id=&#34;conntrack-user-land-tools&#34;&gt;conntrack &amp;ndash; user-land tools&lt;/h2&gt;

&lt;p&gt;obsolete /proc/net/nf_conntrack&lt;/p&gt;

&lt;h2 id=&#34;tuple-link-a-socket-5-arry-tuple&#34;&gt;tuple &amp;ndash; link a socket 5-arry tuple&lt;/h2&gt;

&lt;p&gt;Each Netfilter connection is uniquely identified by a&lt;br /&gt;
(layer-3 protocol, source address, destination address, layer-4 protocol, layer-4 key) tuple&lt;br /&gt;
nf_conntrack_tuple nf_conn&lt;/p&gt;

&lt;h2 id=&#34;connection-tracking-helper&#34;&gt;Connection tracking helper&lt;/h2&gt;

&lt;p&gt;connection tracking can be given knowledge of application-layer protocols&lt;br /&gt;
ALG&lt;/p&gt;

&lt;h2 id=&#34;template&#34;&gt;template&lt;/h2&gt;

&lt;p&gt;netfilter: nf_conntrack: support conntrack templates&lt;/p&gt;

&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;

&lt;p&gt;以上的工作事实上都很简单，基本思路是：&lt;br /&gt;
一个包来了，转换其tuple，看其在连接跟踪表中没有，有的话，更新其状态，以其做一些与协议相关的工作，如果没有，则分配一个新的连接表项，并与skb_buff关连，但是问题是，这个表项，还没有被加入连接表当中来。其实这样做的理由很简单，因为这个时候，这个包是否有机会活命还是个未知数，例如被其它模块给Drop了……所以，要等到一切安全了，再来将这个表项插入至连接跟踪表。&lt;br /&gt;
这个“一切安全”当然是Netfilter所有的模块处理完了，最完全了。&lt;br /&gt;
徐琛,也这么说!&lt;/p&gt;

&lt;p&gt;#NAT&lt;br /&gt;
&lt;a href=&#34;https://www.ietf.org/rfc/rfc3489.txt&#34;&gt;https://www.ietf.org/rfc/rfc3489.txt&lt;/a&gt;&lt;br /&gt;
symmetric nat, 端口不复用, 访问同一个服务器.&lt;br /&gt;
linux 内核的NAT是基于iptables 和 conntrack实现的.&lt;/p&gt;

&lt;p&gt;##init&lt;br /&gt;
iptable_nat_init&lt;/p&gt;

&lt;h2 id=&#34;nat-helper&#34;&gt;NAT helper&lt;/h2&gt;

&lt;p&gt;Similar to connection tracking helpers, NAT helpers will do a packet inspection&lt;br /&gt;
and substitute original addresses by reply addresses in the payload.&lt;/p&gt;

&lt;h2 id=&#34;drop-icmp-redict-in-nat&#34;&gt;Drop ICMP redict in NAT&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.netfilter.org/documentation/HOWTO/NAT-HOWTO-10.html&#34;&gt;http://www.netfilter.org/documentation/HOWTO/NAT-HOWTO-10.html&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;snat&#34;&gt;SNAT&lt;/h2&gt;

&lt;p&gt;nf_nat_ipv4_out -&amp;gt; nf_nat_ipv4_fn -&amp;gt;&lt;br /&gt;
{&lt;br /&gt;
nf_nat_rule_find -&amp;gt; ipt_do_table -&amp;gt; xt_snat_target_v1 -&amp;gt; nf_nat_setup_info&lt;br /&gt;
    {&lt;br /&gt;
        无论是SNAT, 还是DNAT,改的都是ct的reply. 所以这里先把 orig_rely的对应的orig_original形式弄出来.&lt;br /&gt;
        但是,必须要保证改skb的真实值要保证source 唯一, orig_original -&amp;gt; new_original找到后再revert,成new_reply在改到ct里面去.&lt;br /&gt;
        orig_orignal-&amp;gt;skb&lt;br /&gt;
        nf_ct_invert_tuplepr(inverse, orig_relply)&lt;br /&gt;
        {&lt;br /&gt;
            ipv4_invert_tuple&lt;br /&gt;
            tcp_invert_tuple&lt;br /&gt;
            For example, orig tuple:&lt;br /&gt;
            original: 192.168.199.132 -&amp;gt; google.com&lt;br /&gt;
            reply: google.com -&amp;gt; 192.168.199.132 //this is orig_relpy&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        inverse tuple:
        original(inverse-&amp;gt;dst.dir = !orig-&amp;gt;dst.dir;):
        192.168.199.132 -&amp;gt; google.com (!!!reverse orig_reply in ipv4_inver_tuple())
         这个函数的用途可能是担心, orig被人改了, 不能用了.
        except for prior manipulations
    }       

    get_unique_tuple
    {
        1. 如果snat, 且前后可以一致就直接new=orig, 合理.
        2. find_appropriate_src 费点力... 貌似找到已经用到的, 复用
        3. find_best_ips_proto, 找一个 the least-used IP/proto combination in the given range
        4. nf_nat_used_tuple 保证唯一
    }       

    bysoruce 里面存的应该是new_original, hash -&amp;gt; &amp;amp;net-&amp;gt;ct.nat_bysource[srchash]


}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;//上面ct改完了该改skb了.&lt;br /&gt;
    nf_nat_packet -&amp;gt; nf_nat_ipv4_manip_pkt,&lt;br /&gt;
}&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;SNAT nftables&lt;br /&gt;
nf_nat_prerouting &amp;hellip;-&amp;gt; nft_do_chain&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;One kind of NAT, just set one flag bit in ct-&amp;gt;status (SRC_NAT or DST_NAT), but set both SRC/DST_DONE!&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;De-NAT&lt;br /&gt;
最简单的路由器 在postrouting 做了snat（masquade）那么回来的报文怎么unsnat呢？&lt;br /&gt;
我看了九贱的帖子，一笔带过了。 我不太懂的地方是在nat_packet这个函数里面在发现是rely的报文，要判断ct→status &amp;amp; IPS_DST_NAT 为真 才修改skb里的IP port，我不清楚reply的报文何时给ct→status打的DST_NAT的标记位，看代码好象是prerouting的ip_nat_setup_info这个函数，可是我看到必须改了ct的tuple才能给ct→status打标记位，反复的修改ct，我觉得自己想的不对。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;*答案3.17的代码和原来没多大变化就是函数名字变了&lt;br /&gt;
发包-POSTROUTING -&amp;gt;SNAT -&amp;gt;修改ct: nf_nat_setup_info-&amp;gt;　ct-&amp;gt;status |= IPS_SRC_NAT;-&amp;gt;修改skb:nf_nat_packet&lt;/p&gt;

&lt;p&gt;收报-PREOUTING-&amp;gt; DNAT-&amp;gt;修改skb:nf_nat_packet&lt;br /&gt;
{&lt;br /&gt;
    enum nf_nat_manip_type mtype = HOOK2MANIP(hooknum);&lt;br /&gt;
    //因为是在PREROUTING, 所以是DNAT, 我以前一直以为, de-snat在postrouting中做的.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if (mtype == NF_NAT_MANIP_SRC)          
    statusbit = IPS_SRC_NAT;             
else                                      
    statusbit = IPS_DST_NAT;        //到这里

/* Invert if this is reply dir. */            
if (dir == IP_CT_DIR_REPLY) 
    statusbit ^= IPS_NAT_MASK;        //翻转一下变成SNAT 
/* Non-atomic: these bits don&#39;t change. */                                                                                                    
if (ct-&amp;gt;status &amp;amp; statusbit) {                 
//正好和发包是的   ct-&amp;gt;status |= IPS_SRC_NAT;匹配了, 开始de-snat.                    
    struct nf_conntrack_tuple target;
    ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;#ipset&lt;br /&gt;
salist for iptables&lt;/p&gt;

&lt;p&gt;#SYN proxy&lt;br /&gt;
SYNPROXY target makes handling of large SYN floods possible without&lt;br /&gt;
the large performance penalties imposed by the connection tracking in such cases.&lt;br /&gt;
On 3 November 2013, SYN proxy functionality was merged into the Netfilter,&lt;br /&gt;
with the release of version 3.12 of the Linux kernel mainline&lt;/p&gt;

&lt;p&gt;#nftables&lt;/p&gt;

&lt;p&gt;#FAQ&lt;br /&gt;
* 如何查看某个table 具体在那几个hook点.&lt;br /&gt;
去看内核代码 or iptables -L -t &amp;ldquo;table 名&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data link layer</title>
      <link>http://firoyang.org/net/link/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:13 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/net/link/</guid>
      <description>

&lt;h1 id=&#34;multi-queue&#34;&gt;Multi-queue&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://greenhost.nl/2013/04/10/multi-queue-network-interfaces-with-smp-on-linux/&#34;&gt;Multi-queue network interfaces with SMP on Linux&lt;/a&gt;&lt;br /&gt;
##Common concepts&lt;br /&gt;
* The link layer&lt;br /&gt;
is the group of methods and communications protocols that only operate on the link that a host is physically connected to.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The link&lt;br /&gt;
is the physical and logical network component used to interconnect hosts or nodes in the network&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;a link protocol&lt;br /&gt;
is a suite of methods and standards that operate only between adjacent network nodes of a local area network segment&lt;br /&gt;
or a wide area network connection.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;MTU&lt;br /&gt;
This limits the number of bytes of data to 1500(Ethernet II) and 1492(IEEE 802), respectively.&lt;br /&gt;
This characteristic of the link layer is called the MTU, its maximum transmission unit.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;PMTU&lt;br /&gt;
/proc/sys/net/ipv4/ip_no_pmtu_disc&lt;br /&gt;
0 enable, 1 disable&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;cat /proc/sys/net/core/warnings&lt;/p&gt;

&lt;p&gt;/proc/sys/net/ipv4/tcp_mtu_probing&lt;br /&gt;
!0 enable tcp_mtu_probing()&lt;br /&gt;
If you are using Jumbo Frames, we recommend setting tcp_mtu_probing = 1 to&lt;br /&gt;
help avoid the problem of MTU black holes. Setting it to 2 sometimes causes performance problems.&lt;/p&gt;

&lt;p&gt;net/ipv4/icmp.c&lt;br /&gt;
icmp_unreach(&lt;br /&gt;
type 3, code 4&lt;br /&gt;
icmph-&amp;gt;type == ICMP_DEST_UNREACH //3&lt;br /&gt;
case ICMP_FRAG_NEEDED //4&lt;br /&gt;
icmp_err,&lt;/p&gt;

&lt;h2 id=&#34;frame&#34;&gt;Frame&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.infocellar.com/networks/ethernet/frame.htm&#34;&gt;Ethernet Frame&lt;/a&gt;&lt;br /&gt;
+ 一种不太确定的非严格的真实划分&lt;br /&gt;
TCP/IP -&amp;gt; Ethenet II frame&lt;br /&gt;
IPX/APPLETALK -&amp;gt; 802.3/LLC(802.2), SNAP, mac 发来的包走这条路.&lt;br /&gt;
* jumbo frame?&lt;/p&gt;

&lt;p&gt;#net_device&lt;br /&gt;
link -&amp;gt; net&lt;em&gt;device -&amp;gt; if&lt;br /&gt;
driver -&amp;gt; manipulate dev-&amp;gt;state through netif&lt;/em&gt;*_on/off -&amp;gt; dev-&amp;gt;flags&lt;br /&gt;
+rfc2863&lt;br /&gt;
+ &lt;a href=&#34;https://www.kernel.org/doc/Documentation/networking/operstates.txt&#34;&gt;operational state&lt;/a&gt;&lt;br /&gt;
+ &lt;a href=&#34;https://support.cumulusnetworks.com/hc/en-us/articles/202693826-Monitoring-Interface-Administrative-State-and-Physical-State-on-Cumulus-Linux&#34;&gt;Monitoring Interface Administrative State and Physical State on Cumulus Linux&lt;/a&gt;&lt;br /&gt;
* dev-&amp;gt;operstate&lt;br /&gt;
admin state is if flag&lt;br /&gt;
operate state is link_state&lt;br /&gt;
Administrative state is the result of &amp;ldquo;ip link set dev&lt;br /&gt;
&lt;dev&gt; up or down&amp;rdquo; and reflects whether the administrator wants to use&lt;br /&gt;
the device for traffic.&lt;br /&gt;
enp9s0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc mq state DOWN mode DEFAULT group default qlen 1000&lt;br /&gt;
operate is DOWN, amdin is UP&amp;gt;&lt;br /&gt;
 Operational state&lt;br /&gt;
shows the ability of an interface to transmit this user data.&lt;br /&gt;
    &amp;ldquo;UNKNOWN&amp;rdquo;, &amp;ldquo;NOTPRESENT&amp;rdquo;, &amp;ldquo;DOWN&amp;rdquo;, &amp;ldquo;LOWERLAYERDOWN&amp;rdquo;,&lt;br /&gt;
    &amp;ldquo;TESTING&amp;rdquo;, &amp;ldquo;DORMANT&amp;rdquo;,    &amp;ldquo;UP&amp;rdquo;&lt;br /&gt;
IF_OPER_UNKNOWN,&lt;br /&gt;
see rfc2863&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;dev-&amp;gt;link_mode&lt;br /&gt;
IF_LINK_MODE_DORMANT wifi&lt;br /&gt;
IF_LINK_MODE_DEFAULT wire&lt;br /&gt;
对应dev-&amp;gt;operstate in 转化方法rfc2863_policy()&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;dev-&amp;gt;state&lt;br /&gt;
&lt;strong&gt;LINK_STATE_START,     这是内核自身的标记位&lt;/strong&gt;dev_open init_dummy_netdev __dev_close_many&lt;br /&gt;
__LINK_STATE_PRESENT,         也是内核自己的, 用的比 START早&lt;br /&gt;
__LINK_STATE_NOCARRIER,&lt;br /&gt;
__LINK_STATE_LINKWATCH_PENDING, 也是辅助状态不明, nocarrier和dormant都可接收的&lt;br /&gt;
__LINK_STATE_DORMANT&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;dev-&amp;gt;flags dev_get_flags()&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;if flags form man netdevice or or kernel src codes&lt;br /&gt;
/sys/class/net/&lt;dev&gt;/flags&lt;br /&gt;
          IFF_UP            Interface is running.&lt;br /&gt;
          IFF_BROADCAST     Valid broadcast address set.&lt;br /&gt;
          IFF_DEBUG         Internal debugging flag.&lt;br /&gt;
          IFF_LOOPBACK      Interface is a loopback interface.&lt;br /&gt;
          IFF_POINTOPOINT   Interface is a point-to-point link.&lt;br /&gt;
          IFF_RUNNING       Resources allocated.&lt;br /&gt;
          IFF_NOARP         No arp protocol, L2 destination address not set.&lt;br /&gt;
          IFF_PROMISC       Interface is in promiscuous mode.&lt;br /&gt;
          IFF_NOTRAILERS    Avoid use of trailers.&lt;br /&gt;
          IFF_ALLMULTI      Receive all multicast packets.&lt;br /&gt;
          IFF_MASTER        Master of a load balancing bundle.&lt;br /&gt;
          IFF_SLAVE         Slave of a load balancing bundle.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      IFF_MULTICAST     Supports multicast
      IFF_PORTSEL       Is able to select media type via ifmap.
      IFF_AUTOMEDIA     Auto media selection active.
      IFF_DYNAMIC       The addresses are lost when the interface goes
                        down.
      IFF_LOWER_UP      Driver signals L1 up (since Linux 2.6.17)
      IFF_DORMANT       Driver signals dormant (since Linux 2.6.17)
      IFF_ECHO          Echo sent packets (since Linux 2.6.25)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;netdev_queue-&amp;gt;state&lt;br /&gt;
&lt;a href=&#34;http://thread.gmane.org/gmane.linux.kernel/709444/focus=714632&#34;&gt;Understand __QUEUE_STATE_FROZEN&lt;/a&gt;&lt;br /&gt;
__QUEUE_STATE_DRV_XOFF,     netif_tx_stop_queue&lt;br /&gt;
__QUEUE_STATE_STACK_XOFF,&lt;br /&gt;
__QUEUE_STATE_FROZEN,&lt;br /&gt;
可以确定这个frozen这个标志位就是为了dev_watchdog服务, 从所有内核态代码调用的位置得出的.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;dev_watchdog,&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;#Neighbor&lt;br /&gt;
* ip_output_finish2 -&amp;gt; __neigh_create -&amp;gt; tbl-&amp;gt;constructor -&amp;gt; arp_constructor{&lt;br /&gt;
if !dev-&amp;gt;header_ops   //slip is the case, see sl_setup&lt;br /&gt;
    neigh-&amp;gt;ops = &amp;amp;arp_direct_ops&lt;br /&gt;
    neigh-&amp;gt;output = neigh_direct_output&lt;br /&gt;
else if ARPHRD_ROSE/AX25/NETROM&lt;br /&gt;
    arp_broken_ops&lt;br /&gt;
    neigh-&amp;gt;ops-&amp;gt;output&lt;br /&gt;
else if dev-&amp;gt;header_ops-&amp;gt;cache&lt;br /&gt;
    neigh-&amp;gt;ops = &amp;amp;arp_hh_ops&lt;br /&gt;
else&lt;br /&gt;
    arp_generic_ops&lt;/p&gt;

&lt;p&gt;if (neigh-&amp;gt;nud_state &amp;amp; NUD_VALID)&lt;br /&gt;
    neigh-&amp;gt;output = neigh-&amp;gt;ops-&amp;gt;connected_output;&lt;br /&gt;
else&lt;br /&gt;
    neigh-&amp;gt;output = neigh-&amp;gt;ops-&amp;gt;output;&lt;br /&gt;
}&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ip_output_finish2 -&amp;gt; dst_neigh_output -&amp;gt; neigh_resolve_output&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ipv4 Neighbor output instance of ethernet&lt;br /&gt;
see alloc_etherdev_mqs-&amp;gt; ether_setup{&lt;br /&gt;
dev-&amp;gt;header_ops = &amp;amp;eth_header_ops;&lt;br /&gt;
dev-&amp;gt;type       = ARPHRD_ETHER;&lt;br /&gt;
eth_header_ops.cache = eth_header_cache&lt;br /&gt;
}&lt;br /&gt;
so neigh-&amp;gt;ops = &amp;amp;arp_hh_ops; neigh-&amp;gt;output = neigh_resolve_output in arp_hh_ops&lt;/p&gt;

&lt;p&gt;//tg3_init_one&lt;br /&gt;
dev-&amp;gt;netdev_ops = &amp;amp;tg3_netdev_ops;&lt;br /&gt;
dev-&amp;gt;ethtool_ops = &amp;amp;tg3_ethtool_ops;&lt;br /&gt;
dev-&amp;gt;watchdog_timeo = TG3_TX_TIMEOUT;&lt;/p&gt;

&lt;p&gt;//In ppp&lt;br /&gt;
static void ppp_setup(struct nethernetet_device *dev)&lt;br /&gt;
{&lt;br /&gt;
dev-&amp;gt;netdev_ops = &amp;amp;ppp_netdev_ops;&lt;br /&gt;
dev-&amp;gt;hard_header_len = PPP_HDRLEN;&lt;br /&gt;
dev-&amp;gt;mtu = PPP_MRU;&lt;br /&gt;
dev-&amp;gt;addr_len = 0;&lt;br /&gt;
dev-&amp;gt;tx_queue_len = 3&lt;br /&gt;
dev-&amp;gt;type = ARPHRD_PPP&lt;br /&gt;
}&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;#PPP SLIP&lt;/p&gt;

&lt;p&gt;#Data Framing&lt;br /&gt;
dst_neigh_output-&amp;gt;dev_hard_header -&amp;gt;  eth_header&lt;/p&gt;

&lt;p&gt;#TC Qdisc&lt;br /&gt;
##Bibliography&lt;br /&gt;
&lt;a href=&#34;http://tldp.org/HOWTO/Traffic-Control-HOWTO/intro.html&#34;&gt;http://tldp.org/HOWTO/Traffic-Control-HOWTO/intro.html&lt;/a&gt;&lt;br /&gt;
lartc.rog&lt;br /&gt;
&lt;a href=&#34;http://ace-host.stuart.id.au/russell/files/tc/&#34;&gt;http://ace-host.stuart.id.au/russell/files/tc/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;##Common concepts&lt;br /&gt;
Shaping: Shapers delay packets to meet a desired rate.&lt;br /&gt;
Scheduling: Schedulers arrange and/or rearrange packets for output.&lt;br /&gt;
Classifying: Classifiers sort or separate traffic into queues.&lt;br /&gt;
Policing: Policers measure and limit traffic in a particular queue.&lt;br /&gt;
Dropping: Dropping discards an entire packet, flow or classification.&lt;br /&gt;
Marking: Marking is a mechanism by which the packet is altered.&lt;/p&gt;

&lt;p&gt;##Add new qdisc&lt;br /&gt;
RTM_NEWQDISC -&amp;gt; tc_modify_qdisc&lt;/p&gt;

&lt;p&gt;##The execution of u32 tc rule&lt;/p&gt;

&lt;h3 id=&#34;user-space-tc-qidsc-add&#34;&gt;user space tc qidsc add&lt;/h3&gt;

&lt;p&gt;u32_parse_opt&lt;br /&gt;
{&lt;br /&gt;
    -&amp;gt; parse_selector -&amp;gt;&amp;hellip;-&amp;gt; parse_ip&lt;br /&gt;
    struct nlmsghdr *n&lt;br /&gt;
    rta = NLMSG_TAIL(n)&lt;br /&gt;
    rta-&amp;gt;type = TCA_U32_SEL&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;h3 id=&#34;kernel-space&#34;&gt;kernel space&lt;/h3&gt;

&lt;p&gt;NETLINK_ROUTE -&amp;gt; RTM_NEWTFILTER: see tc_filter_init -&amp;gt; tc_ctl_tfilter-&amp;gt;(tp-&amp;gt;ops-&amp;gt;change = u32_change in net/sched/cls_u32.c)&lt;br /&gt;
tcf_exts_validate: init police and action of this shel tc command,&lt;br /&gt;
put sel in tc_u_knode;&lt;br /&gt;
tc_u_knode insert in tc_u_hnode&lt;br /&gt;
root is tcf_proto 入殓 by prior.&lt;br /&gt;
tcf_proto -&amp;gt; tc_u_hnode -&amp;gt; tc_u_knode -&amp;gt; sel&lt;br /&gt;
也就是用户太的selector没变存到内核中了.&lt;br /&gt;
enqueue -&amp;gt; filter_list -&amp;gt;u32-&amp;gt;classify() this classify is implement by u32!&lt;br /&gt;
tcf_proto_ops-&amp;gt;.kind = &amp;ldquo;u32&amp;rdquo;, .classify   =   u32_classify,&lt;br /&gt;
police and action invoke in tcf_action_exec , act register by tcf_register_action.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TCA_U32_CLASSID in u32_set_parms&lt;br /&gt;
filter classid and flowid is the same meaning in russell tc doc&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;TCA_KIND in filter is u32&amp;hellip;register_tcf_proto_ops&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;##FAQ&lt;br /&gt;
* conflict tc qidsc del with softnet_data-&amp;gt;softnet_data&lt;br /&gt;
 [PATCH] pkt_sched: Destroy gen estimators under rtnl_lock().&lt;br /&gt;
&lt;a href=&#34;http://thread.gmane.org/gmane.linux.network/102444/focus=102592&#34;&gt;http://thread.gmane.org/gmane.linux.network/102444/focus=102592&lt;/a&gt;&lt;br /&gt;
After synchronize_rcu() in dev_deactivate() we are sure any qdisc_run(),&lt;br /&gt;
from dev_queue_xmit() or net_tx_action() can only see and lock noop_qdisc.&lt;br /&gt;
This was happened in dev_deactivate_many()&lt;br /&gt;
* difference between synchronize_net and  synchronize_rcu?&lt;br /&gt;
&lt;a href=&#34;http://article.gmane.org/gmane.linux.network/196309/match=net_device+dismantle&#34;&gt;http://article.gmane.org/gmane.linux.network/196309/match=net_device+dismantle&lt;/a&gt;&lt;br /&gt;
In this patch, we replace synchronize_rcu with synchronize_net().&lt;/p&gt;

&lt;p&gt;#LLC (TCP/IP rarely use this sub layer)&lt;br /&gt;
* ptype MAC layer 之上, 可能是data link(llc) or network layer(ip)&lt;br /&gt;
定义了所有从驱动上来的packet接收函数, 这里有ip_rcv 还有pppoe_rcv,llc_rcv, NO snap_rcv&lt;br /&gt;
dev_add_pack&lt;br /&gt;
llc_rcv{snap_rcv}&lt;br /&gt;
netif_receive_skb -&amp;gt;ip/llc_rcv&lt;/p&gt;

&lt;h1 id=&#34;netpoll&#34;&gt;Netpoll&lt;/h1&gt;

&lt;p&gt;可以说是linker层的netfilter 更raw&lt;br /&gt;
netconsole就是基于他, 屌炸天.&lt;br /&gt;
不走协议栈, 中断完蛋了, 也能用, 纯poll.&lt;/p&gt;

&lt;h1 id=&#34;napi&#34;&gt;NAPI&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.chinaunix.net/uid-24148050-id-464587.html&#34;&gt;网络数据包收发流程(一)：从驱动到协议栈&lt;/a&gt;&lt;br /&gt;
New API (NAPI) is an interface to use interrupt mitigation techniques for networking devices in the Linux kernel.&lt;br /&gt;
Such an approach is intended to reduce the overhead of packet receiving.&lt;br /&gt;
类似机制, Add &lt;a href=&#34;https://lwn.net/Articles/346187/&#34;&gt;blk-iopoll&lt;/a&gt;, a NAPI like approach for block devices&lt;br /&gt;
1. dirver: device-&amp;gt;DMA-&amp;gt;ring&lt;br /&gt;
2. IRQ: disable irq, napi schedule&lt;br /&gt;
do_IRQ-&amp;gt;handler = gfar_receive{&lt;br /&gt;
    disable irq&lt;br /&gt;
    __netif_rx_schedule&lt;br /&gt;
}&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;softirq:driver function, clean ring buffer, netif_receive_skb&lt;br /&gt;
-&amp;gt;net_rx_action {&lt;br /&gt;
n-&amp;gt;poll = gfar_poll&lt;br /&gt;
{&lt;br /&gt;
gfar_clean_rx_ring-&amp;gt;gfar_process_frame&lt;br /&gt;
{&lt;br /&gt;
    skb-&amp;gt;protocol = eth_type_trans(skb, dev);&lt;br /&gt;
    netif_receive_skb&lt;br /&gt;
}&lt;br /&gt;
enable irq&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;rps&#34;&gt;RPS&lt;/h1&gt;

&lt;h1 id=&#34;driver&#34;&gt;Driver&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;skb-&amp;gt;protocol&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;assignment in ip_output by = htons(ETH_P_IP)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;assignment in driver by = eth_type_trans()&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;mac&#34;&gt;MAC&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Addressing,LAN switching&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;relations-of-concept&#34;&gt;relations of concept&lt;/h1&gt;

&lt;p&gt;Qdisc &amp;ndash; NET_XMIT_SUCCESS&lt;br /&gt;
dev &amp;ndash; NETDEV_TX_OK&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux Network Stack</title>
      <link>http://firoyang.org/net/net/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:13 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/net/net/</guid>
      <description>

&lt;p&gt;#Reference&lt;br /&gt;
&lt;a href=&#34;http://www.protocols.com/pbook/tcpip1.htm&#34;&gt;TCP/IP Reference Page&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.securitywizardry.com/index.php/tools/packet-headers.html&#34;&gt;RAW PACKET FORMATS&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://wangcong.org/2012/10/15/-e4-bb-8e-ipv4-e5-88-b0-ipv6/&#34;&gt;从 IPv4 到 IPv6&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.tecmint.com/ipv4-and-ipv6-comparison/&#34;&gt;What’s wrong with IPv4 and Why we are moving to IPv6&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/629155/&#34;&gt;Improving Linux networking performance&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://wiki.linuxfoundation.org/networking/kernel_flow&#34;&gt;Monitoring and Tuning the Linux Networking Stack: Sending Data&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The Feynman map of network, check &lt;a href=&#34;https://www.slideshare.net/ThomasGraf5/devconf-2014-kernel-networking-walkthrough&#34;&gt;Thomas Graf&amp;rsquo;s DevConf 2014 Kernel Networking Walkthrough&lt;/a&gt;&lt;br /&gt;
When we talk about network, what we talk about?&lt;br /&gt;
Transfer; Truely we are talking about transfer including three component:src, dst, channel.&lt;br /&gt;
Address has two properties: relation and scope.&lt;/p&gt;

&lt;h2 id=&#34;什么是internet&#34;&gt;什么是Internet&lt;/h2&gt;

&lt;p&gt;英文&lt;a href=&#34;http://keithbriggs.info/network.html&#34;&gt;network&lt;/a&gt;, 其中work, 构造之意.&lt;br /&gt;
etymonline 给出结缔成网之意, net-like arrangement of threads, wires, etc.&lt;br /&gt;
Network -&amp;gt; Telecommunications network -&amp;gt; Computer network -&amp;gt; Internet&lt;/p&gt;

&lt;p&gt;The Internet is a global system of interconnected computer networks that use&lt;br /&gt;
the standard Internet protocol suite (TCP/IP) to link several billion devices worldwide.&lt;br /&gt;
Internet protocol suite,是结网的策略方法核心.&lt;/p&gt;

&lt;h1 id=&#34;internet-protocol-suite&#34;&gt;Internet protocol suite&lt;/h1&gt;

&lt;p&gt;The Internet protocol suite is the computer networking model and set of&lt;br /&gt;
communications protocols used on the Internet and similar computer networks.&lt;/p&gt;

&lt;p&gt;通常简称&lt;a href=&#34;http://en.wikipedia.org/wiki/Protocol_stack&#34;&gt;protocol stack&lt;/a&gt;, 即协议栈&lt;br /&gt;
The protocol stack is an implementation of a computer networking protocol suite.&lt;br /&gt;
&lt;a href=&#34;http://en.wikipedia.org/wiki/Internet_protocol_suite&#34;&gt;Internet protocol suite &amp;ndash; TCP/IP&lt;/a&gt;就是一种&lt;a href=&#34;http://en.wikipedia.org/wiki/List_of_network_protocol_stacks&#34;&gt;protocol stack.&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;为什么协议要分层-怎么分&#34;&gt;为什么协议要分层? 怎么分?&lt;/h2&gt;

&lt;p&gt;这是非常有深度的问题! 可以说本文价值所在.&lt;br /&gt;
这里讨论的是如何设计一套网络协议.&lt;br /&gt;
抛开TCP/IP, 如果要让我门自己设计一套 network protocol, 有什么思路?&lt;br /&gt;
发送方, 接收方, 信息. 这是所有信息传递的要素, 无论是, 狼烟, 信鸽, 还是书信.&lt;br /&gt;
不同的是, 信息传递的方式.狼烟这种大范围视觉方式, 关心的最少, 敌人来犯点着烟就行了.&lt;br /&gt;
那么信鸽了, 信鸽的英文叫做Homing pigeon, 信鸽的归巢本能, 为我指定了信息的接收房.&lt;br /&gt;
抛开隐私, 我们能把信放大到天空那么大, 收信人抬下头也能收到信息.&lt;br /&gt;
对于书信的方式, 在信息不能广泛的传递给每个人的时候, 我们需要把信送到特定的人手里.&lt;br /&gt;
信的地址就成了必选. 信息传输的方法决定了, 接收者的特征集合.&lt;br /&gt;
protocol暗指communications protocol, protocol词源上便指diplomatic rules of etiquette&lt;br /&gt;
一种合适的交流手段. 而The Internet protocol suite的定义中明确指明了computer networking model.&lt;br /&gt;
也就是源于方法决定对象的经验结论, wikipedia上的定义是非常有见地的.&lt;br /&gt;
所以回到计算机框架下的信息传输设计. 受限于计算机数据的交互方法, 我们必须指明信息的接收方.&lt;br /&gt;
所以我来设计一套network protocol, 第一点, 就是如何表示每个计算机收信方, 也就是地址.&lt;br /&gt;
地址成了网络协议的本体!有了地址后, 如何寻址就是个问题了, 这属于衍生的问题, 没什么意思了.&lt;br /&gt;
我们假装, 已经设计出一套惊天地泣鬼神的寻路方法, 还是叫寻址更好, 寻找目的地址.&lt;br /&gt;
我们只是道出了, 网络协议的基本的要素接收方的本质属性, 也就是model. 那么, 我们怎么定义方法呢?&lt;br /&gt;
传输无外乎, 你有消息, 给我发个信, 再有消息, 再发, 当然我也可以给你发. 结合到实际的计算机领域,&lt;br /&gt;
假如, 我们只有地址和寻址方法的寒酸网络协议, 在一个小函数里搞定了.&lt;br /&gt;
为什么OSI和TCP/IP都搞得那么复杂?&lt;br /&gt;
下面才是为什么要&lt;a href=&#34;http://en.wikipedia.org/wiki/Abstraction_layer&#34;&gt;分层&lt;/a&gt;, 和怎么分的问题.&lt;br /&gt;
是什么导致了分层? 哲学上, 分乃是不同的存在.也就是说存在我们寒酸的网络协议不同的存在.&lt;br /&gt;
我们现在把linux内核的协议栈替换称我们的poor network protocol, (你现在, 应该知道为什么osi中&lt;br /&gt;
network layer的名字来源了, 正因为他代表了整个网络协议的实质, 所以名字逼格才这么高!)&lt;br /&gt;
显然, 还是不能运行, 为什么?我们缺少和应用层以及底层硬件的交互.也就是空中楼阁!&lt;br /&gt;
加一个poor bsd socket,  poor application layer来了.加一个和底层硬件交互, poor linker layer也来了.&lt;br /&gt;
我靠, 我的协议也有3层了, 拿去用吧.&lt;br /&gt;
我现在把传输层也意淫进来. 显然, 传输层不是这么随便的, 他的存在肯定有着合理的理由.&lt;br /&gt;
事物存在的理由不在于自身! 我认为汉语传输层(transport)是一个被严重误读了的名字, 这不同于人的名字,&lt;br /&gt;
人类的名字是一个标示系统, 比如你叫马机霸, 你就一定要长得像马jb. 而学术领域的, 名字则具有&lt;br /&gt;
另外一个重要的属性就是:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;概念性or推理性的认知.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;即从名字中可以推理出相关属性; 在汉语当中, 我第一次看谢希仁《计算机网络第五版》教材时,&lt;br /&gt;
就感觉这个名字好晕啊!他和传输有半毛钱关系, 传输不是链路层网卡网线的事吗?&lt;br /&gt;
记得老师说了句, 这是一种抽象, 问题旧搁置了.当年未能深入问题, 非常遗憾. 今天补上!&lt;br /&gt;
TCP中的T是transmission和transport中的都被翻译成了汉语的传输!&lt;br /&gt;
有很长一段时间, 我都认为传输层,应该叫做传输控制层, 因为他, 看上去真的更像控制啊!&lt;br /&gt;
那么transmission和transport的区别到底事什么呢?&lt;br /&gt;
看wikipedia的解释, 立马明白了, 这分明说的是传输层的本质啊:&lt;br /&gt;
Transport or transportation is the movement of people, animals and goods from one location to another.&lt;br /&gt;
相信不用看etymonline你也知道transport是怎么来的trans + port, 这里的port是名词港口之意.&lt;br /&gt;
现在, 就明白了为什么port端口号, 虽然实质是地址的含义, 却不属于network层.&lt;br /&gt;
传输层有卸货的含义, 干脆就叫转港层吧!&lt;br /&gt;
transport layer 的巨大意义, 就被显示出来了, 他是必须的.&lt;br /&gt;
实质上我们也应该看到无论是port还是ip address都是地址的含义, 这也是协议栈模型的本质.&lt;br /&gt;
下面我们来讨论, 信息发送的方法问题.&lt;br /&gt;
网络协议栈的每一层都有着不同协议, 也就是不同方法.即便是一个协议自身也是众多方法的集合.&lt;br /&gt;
理解这些协议程度, 就成为network 工程师能力差异, 下面我们会逐层意淫, 绝不是什么分析理解.&lt;br /&gt;
回到最初的问题, 实际上我们已经解决了怎么分层的问题了.&lt;br /&gt;
我们现在还差一个, 为什么分层.&lt;br /&gt;
简单说这是个设计问题. 设计的好会影响的设计本身与实现.这里是模块化的设计思路.&lt;br /&gt;
优点如维基所说:&lt;br /&gt;
Because each protocol module usually communicates with two others,&lt;br /&gt;
they are commonly imagined as layers in a stack of protocols.&lt;br /&gt;
&lt;a href=&#34;http://en.wikipedia.org/wiki/Communications_protocol#Layering&#34;&gt;更完整的陈述&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;design-of-communications-protocol-http-en-wikipedia-org-wiki-communications-protocol&#34;&gt;Design of &lt;a href=&#34;http://en.wikipedia.org/wiki/Communications_protocol&#34;&gt;Communications protocol&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://ccr.sigcomm.org/archive/1995/jan95/ccr-9501-clark.pdf&#34;&gt;The Design Philosophy of the DARPA Internet Protocols&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.cs.rice.edu/~eugeneng/teaching/s04/comp629/reviews/Cla88.txt&#34;&gt;Reviews from RICE edu&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://zoo.cs.yale.edu/classes/cs633/Reviews/Cla88.msl38.html&#34;&gt;Reviews of Michael S. Liu Yale&lt;/a&gt;&lt;br /&gt;
Address formate: 有了地址我们就要有地址的具体格式如哪个街道，哪个小区几号楼几室。&lt;br /&gt;
Route: 找到收信人, 计算机网络包括linker, network 和transportlayer&lt;br /&gt;
Data formate: 接下来就是信封格式，对应头部。&lt;br /&gt;
Reliability:发的信可能丢了，要在写一封吗？&lt;br /&gt;
Detection of transmission errors:如信被人篡改了&lt;/p&gt;

&lt;h1 id=&#34;linux-network-stack-workthrough&#34;&gt;Linux network stack workthrough&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.slideshare.net/ThomasGraf5/devconf-2014-kernel-networking-walkthrough&#34;&gt;DevConf 2014 Kernel Networking Walkthrough&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.slideshare.net/minibobo/linux-tcp-ip?related=1&#34;&gt;introduction to linux kernel tcp/ip ptocotol stack&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://wiki.linuxfoundation.org/networking/kernel_flow&#34;&gt;kernel flow&lt;/a&gt;&lt;br /&gt;
[&lt;/p&gt;

&lt;p&gt;taobao的第5也说明了问题.&lt;br /&gt;
这是通常的skb的流向. 就是在socket里面按着协议走, 包括tcp的重传.&lt;br /&gt;
还有一种, 就是想kproxy那种, 人为的干扰skb的走向, netif_receive_skb就是一个点.&lt;br /&gt;
netif_receive_skb之后就是标准的内核协议栈的事情了包括bonding啊, vlan, bridge这些什么的.&lt;br /&gt;
我觉得这么说还是不够深度, 我们确实在探索skb在协议栈中的流转.&lt;br /&gt;
我们都知道协议栈中skb按着协议走的, 如果能指出什么时候我们可以合法地让报文转个向.&lt;br /&gt;
就能打到我们的目的, 多少能提升下对workthrough的理解的深度;)&lt;br /&gt;
* af_packet相关的&lt;br /&gt;
dev_queue_xmit的dev_queue_xmit_nit中clone后deliver_skb送上去.&lt;br /&gt;
netif_receive_skb 的__netif_receive_skb_core 的deliver_skb. 有个问题?&lt;br /&gt;
为什么skb直接送上去了没有skb_get之类的.原来每个deliver_skb都有&lt;br /&gt;
atomic_inc(&amp;amp;skb-&amp;gt;users);为什么不是skb_get&lt;br /&gt;
* 主动调用netif_receive_skb&lt;br /&gt;
很多pptp协议就是这么干的.&lt;br /&gt;
其实最经典还是pskb_copy和clone的那个场景!&lt;br /&gt;
这个应该多积累, 我感觉挺重要的.&lt;br /&gt;
&lt;a href=&#34;http://www.cubrid.org/blog/dev-platform/understanding-tcp-ip-network-stack/&#34;&gt;Understanding TCP/IP Network Stack &amp;amp; Writing Network Apps&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;out&#34;&gt;out&lt;/h2&gt;

&lt;p&gt;inet_stream_ops-&amp;gt;tcp_sendmsg()-&amp;gt;tcp_push()-&amp;gt;&lt;strong&gt;tcp_push_pending_frames()-&amp;gt;tcp_write_xmit()-&amp;gt;tcp_transmit_skb()-&amp;gt;ipv4_specific.ip_queue_xmit()-&amp;gt;&lt;br /&gt;
ip_local_out()-&amp;gt;&lt;/strong&gt;ip_local_out()-&amp;gt;NF_INET_LOCAL_OUT-&amp;gt;dst_output()-&amp;gt;&lt;br /&gt;
ip_output()&lt;br /&gt;
{&lt;br /&gt;
    //set in ip_mkroute_output&lt;br /&gt;
    skb-&amp;gt;dev = dev = skb_dst(skb)-&amp;gt;dev; //!!!&lt;br /&gt;
    skb-&amp;gt;protocol = htons(ETH_P_IP);&lt;br /&gt;
}-&amp;gt;NF_INET_POST_ROUTING-&amp;gt;ip_finish_output()-&amp;gt;&lt;/p&gt;

&lt;p&gt;ip_finish_output2-&amp;gt; dst_neigh_output&lt;br /&gt;
{&lt;br /&gt;
    neigh_hh_output // hh already in below:-)&lt;br /&gt;
    or&lt;br /&gt;
    n-&amp;gt;output = neigh_resolve_output{dev_hard_header}&lt;br /&gt;
}&lt;br /&gt;
-&amp;gt;dev_queue_xmit()&lt;br /&gt;
{&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;__dev_xmit_skb-&amp;gt;__qdisc_run-&amp;gt;qdisc_restart()-&amp;gt;dev_hard_start_xmit()
or 
validate_xmit_skb-&amp;gt;skb_gso_segment-&amp;gt;skb_mac_gso_segment-&amp;gt; ptype-&amp;gt;callbacks.gso_segment=inet_gso_segment-&amp;gt;tcp4_gso_segment,
dev_hard_start_xmit()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;br /&gt;
xmit_one-&amp;gt;&lt;br /&gt;
{&lt;br /&gt;
    dev_queue_xmit_nit is Sun&amp;rsquo;s Network Interface Tap (NIT)&lt;br /&gt;
    netdev_start_xmit-&amp;gt;ops-&amp;gt;ndo_start_xmit{this functions is init in createing device} = e100_xmit_frame&lt;br /&gt;
}&lt;/p&gt;

&lt;p&gt;softirq:net_tx_action()-&amp;gt;qdisc_run()&lt;/p&gt;

&lt;h2 id=&#34;in-forward&#34;&gt;in &amp;amp; forward&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;NAPI poll_list net_device&lt;br /&gt;
driver intr add skb to private queue -&amp;gt; e100_intr()-&amp;gt;&lt;strong&gt;netif_rx_schedule()-&amp;gt;&lt;/strong&gt;napi_schedule(netdev,nic-&amp;gt;napi)-&amp;gt;:&lt;br /&gt;
add napi to poll_list and __raise_softirq_irqoff()&lt;br /&gt;
do_softirq-&amp;gt;net_rx_action()-&amp;gt;&lt;br /&gt;
+netdev-&amp;gt;poll()=e100_poll()private function-&amp;gt;e100_rx_clean()&amp;hellip;-&amp;gt;&lt;br /&gt;
netif_receive_skb()-&amp;gt;deliver_skb-&amp;gt;&lt;br /&gt;
private queue and private function&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Non-NAPI input_pkt_queue skb&lt;br /&gt;
driver intr vortex_rx()-&amp;gt;netif_rx()-&amp;gt;add skb to SD input_pkt_queue-&amp;gt;napi_schedule(backlog)-&amp;gt;add backlog to SD poll_list __raise_softirq_irqoff()&lt;br /&gt;
async:net_rx_action()-&amp;gt;&lt;br /&gt;
+backlog-&amp;gt;poll()=process_backlog()&lt;br /&gt;
-&amp;gt;netif_receive_skb()-&amp;gt;deliver_skb-&amp;gt;&lt;br /&gt;
skb to sd input_pkt_queue process&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;common path&lt;br /&gt;
pt_prev-&amp;gt;func=ip_rcv()-&amp;gt;NF_INET_PRE_ROUTING-&amp;gt;ip_rcv_finish()-&amp;gt;&lt;br /&gt;
ip_route_input()-&amp;gt;ip_route_input_slow()&lt;br /&gt;
{&lt;br /&gt;
local_input dst.input??=ip_local_deliver()&lt;br /&gt;
or&lt;br /&gt;
ip_mkroute_input()-&amp;gt;__mkroute_input():dst.input=ip_forward() 紧接着dst.output??=ip_output()&lt;br /&gt;
}&lt;br /&gt;
dst_input()-&amp;gt;&lt;br /&gt;
{&lt;br /&gt;
ip_local_deliver()-&amp;gt;NF_INET_LOCAL_IN-&amp;gt;ip_local_deliver_finish()-&amp;gt;inet_protos.tcp_v4_rcv()&lt;br /&gt;
or&lt;br /&gt;
ip_forward()-&amp;gt;NF_INET_FORWARD-&amp;gt;ip_forward_finish()-&amp;gt;dst_output()见上。&lt;br /&gt;
}&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Differences&lt;br /&gt;
1 NAPI has not netif_rx():input_pkt_queue.&lt;br /&gt;
2 NAPI and Non-NAPI used different napi-&amp;gt;poll 决定本质上的区别。&lt;br /&gt;
3 vortex_rx() 多，e100_rx_clean()多！这点可以看出不同优势来。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;package-name-in-different-layer&#34;&gt;package name in different layer&lt;/h2&gt;

&lt;p&gt;An individual package of transmitted data is commonly called a frame on the link layer, L2;&lt;br /&gt;
a packet on the network layer; a segment on the transport layer; and a message on the application layer.&lt;/p&gt;

&lt;h2 id=&#34;faq&#34;&gt;FAQ&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Need clean&lt;br /&gt;
net_tx_action-&amp;gt;output_queue/每个设备的qdisc and  clear_bit__QDISC_STATE_SCHED qdisc_run add back&lt;br /&gt;
__QDISC_STATE_SCHED是否加入softdata&lt;br /&gt;
qdisc_restart: 如果队列有数据就返回大于零 继续减小weight_p&lt;br /&gt;
__qdisc_run queue no data __QDISC_STATE_SCHED not set, only in this case!&lt;br /&gt;
driver tx, stack xmit&lt;/p&gt;

&lt;h3 id=&#34;socket-lock&#34;&gt;socket lock&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.spinics.net/lists/netdev/msg136306.html&#34;&gt;lock_sock or sock_hold&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.linuxfoundation.org/collaborate/workgroups/networking/socket_locks&#34;&gt;bh_lock_sock&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;FIXME sock-&amp;gt;pfmemealloc&lt;br /&gt;
Yes, I only wanted to drop the packet if we were under pressure&lt;br /&gt;
when skb was allocated. If we hit pressure between when skb was&lt;br /&gt;
allocated and when __netdev_alloc_page is called,&lt;br /&gt;
&lt;a href=&#34;https://groups.google.com/forum/#!msg/linux_net/-YtWB66adxY/Qqm_y4U09IAJ&#34;&gt;netvm: Allow skb allocation to use PFMEMALLOC reserves&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://thread.gmane.org/gmane.linux.kernel/1152658&#34;&gt;netvm: Allow skb allocation to use PFMEMALLOC reserves - gmane 08/14&lt;/a&gt;&lt;br /&gt;
socket是跟协议族绑定的概念, 所以要用inet_create, netlink_create&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;FIXME inet_timewait_sock&lt;br /&gt;
deal heavily loaded servers without violating the protocol specification&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;sk_set_memalloc&lt;br /&gt;
SOCK_MEMALLOC, sock has feature mem alloc for free memory.&lt;br /&gt;
只有到了sock层才能分辨, sock是否是memalloc的.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;first_device 用途？&lt;br /&gt;
subsys 在前, device在后.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What is bridge?&lt;br /&gt;
linux bridge&lt;br /&gt;
netdev_rx_handler_register(dev, br_handle_frame, p);&lt;br /&gt;
__netif_receive_skb -&amp;gt; rx_handler=br_handle_frame&lt;br /&gt;
and generic concept: hub, switch?&lt;br /&gt;
hub: layer 1, bradcast, exclusive share, 报文可被侦听.&lt;br /&gt;
switch: layer 2,  mac port route, CAM table in linux bridge module!&lt;br /&gt;
switch with vlan: layer 3, 因为vlan之间的报文转发需要路由, 所以是layer层技术.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What is Head-of-line blocking&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Why can I receive ethernet frames bigger than my current MTU size?&lt;br /&gt;
&lt;a href=&#34;http://serverfault.com/questions/749110/why-can-i-receive-ethernet-frames-bigger-than-my-current-mtu-size&#34;&gt;http://serverfault.com/questions/749110/why-can-i-receive-ethernet-frames-bigger-than-my-current-mtu-size&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Network layer</title>
      <link>http://firoyang.org/net/ip/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:13 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/net/ip/</guid>
      <description>

&lt;p&gt;#Network layer&lt;br /&gt;
* Error detection, unreliable&lt;br /&gt;
Best effort service,IP has a simple error handling algorithm:&lt;br /&gt;
throw away the datagram and try to send an ICMP message back to the source&lt;br /&gt;
* Host addressing&lt;/p&gt;

&lt;h1 id=&#34;ipv6-wrl6&#34;&gt;IPv6 wrl6&lt;/h1&gt;

&lt;p&gt;__ipv6_addr_type&lt;br /&gt;
ip6_input or ip6_output&lt;br /&gt;
F1: OK&lt;br /&gt;
F2: OK&lt;/p&gt;

&lt;h1 id=&#34;4-3-ip-address&#34;&gt;4.3 IP address&lt;/h1&gt;

&lt;p&gt;IPv6 wrl6&lt;br /&gt;
__ipv6_addr_type&lt;br /&gt;
ip6addrlbl_init_table&lt;br /&gt;
ip6_input or ip6_output&lt;br /&gt;
ipv6_addr_v4mapped&lt;br /&gt;
* 0:&lt;br /&gt;
1 ok IPV6_ADDR_LOOPBACK ::&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;128&lt;/sub&gt;&lt;br /&gt;
2 ok IPV6_ADDR_ANY ::/128&lt;br /&gt;
3 ok IPV6_ADDR_MAPPED ::ffff:0:0/96&lt;br /&gt;
4 ? IPV6_ADDR_COMPATv4  0000::/96 ipgre_tunnel_xmit ddr_type &amp;amp; IPV6_ADDR_COMPATv4) == 0 ; goto tx_error_icmp;&lt;br /&gt;
5 G?&lt;br /&gt;
* 0100::/64, NG, Used by CISCO&lt;br /&gt;
A Discard Prefix for IPv6&lt;br /&gt;
Discard-Only Address Block&lt;br /&gt;
&lt;a href=&#34;https://tools.ietf.org/html/rfc6666&#34;&gt;https://tools.ietf.org/html/rfc6666&lt;/a&gt;&lt;br /&gt;
 Remote Triggered Black Hole (RTBH)&lt;br /&gt;
&lt;a href=&#34;https://tools.ietf.org/html/rfc5635&#34;&gt;https://tools.ietf.org/html/rfc5635&lt;/a&gt;&lt;br /&gt;
* 0200::/7,  NG, Deprecated&lt;br /&gt;
OSI NSAPs and IPv6&lt;br /&gt;
&lt;a href=&#34;http://tools.ietf.org/html/rfc1888&#34;&gt;http://tools.ietf.org/html/rfc1888&lt;/a&gt;&lt;br /&gt;
Internet Code Point (ICP) Assignments for NSAP Addresses&lt;br /&gt;
&lt;a href=&#34;http://tools.ietf.org/html/rfc4548&#34;&gt;http://tools.ietf.org/html/rfc4548&lt;/a&gt;&lt;br /&gt;
Interfaces between protocol layers&lt;br /&gt;
&lt;a href=&#34;http://www.erg.abdn.ac.uk/users/gorry/course/intro-pages/sap.html&#34;&gt;http://www.erg.abdn.ac.uk/users/gorry/course/intro-pages/sap.html&lt;/a&gt;&lt;br /&gt;
Network Service Access Point (NSAP): v4,v6?&lt;br /&gt;
&lt;a href=&#34;http://searchnetworking.techtarget.com/definition/Network-Service-Access-Point&#34;&gt;http://searchnetworking.techtarget.com/definition/Network-Service-Access-Point&lt;/a&gt;&lt;br /&gt;
* 0400::/6, NG, No information, maybe used as Global address see __ipv6_addr_type&lt;br /&gt;
* 0800::/5, NG, ditto&lt;br /&gt;
* (000, 111)x::/3, OK, unicasts. For more details please reference __ipv6_addr_type&lt;br /&gt;
1000::/4, OK, ditto&lt;br /&gt;
2000::/3, OK, Global Unicast,&lt;br /&gt;
2002::/16, OK, SIT, 6in4&lt;br /&gt;
&lt;a href=&#34;http://tools.ietf.org/html/rfc3056&#34;&gt;http://tools.ietf.org/html/rfc3056&lt;/a&gt;&lt;br /&gt;
2001::/32, OK, used in Default policy table for routing&lt;br /&gt;
2001:10::/28, OK, Ditto&lt;br /&gt;
* e000::/4, NG?, No information in google; but used as GU in and kernel by default.&lt;br /&gt;
* fc00::/7, OK,&lt;br /&gt;
IPV6_ADDR_UNICAST&lt;br /&gt;
* fe80::/10, OK,&lt;br /&gt;
IPV6_ADDR_LINKLOCAL&lt;br /&gt;
* fec0::/10, OK, But deprecated by RFC3879, used in kernel?&lt;br /&gt;
IPV6_ADDR_SITELOCAL&lt;br /&gt;
Deprecating Site Local Addresses&lt;br /&gt;
&lt;a href=&#34;http://tools.ietf.org/html/rfc3879&#34;&gt;http://tools.ietf.org/html/rfc3879&lt;/a&gt;&lt;br /&gt;
* ff00::/8, OK&lt;br /&gt;
IPV6_ADDR_MULTICAST&lt;br /&gt;
&lt;a href=&#34;http://tools.ietf.org/html/rfc4291&#34;&gt;http://tools.ietf.org/html/rfc4291&lt;/a&gt;&lt;br /&gt;
* addr not described in __ipv6_addr_type working as global unicast&lt;/p&gt;

&lt;p&gt;#IP&lt;br /&gt;
* IP Packet Fragmentation/Defragmentation&lt;br /&gt;
* MSS tcp_sock-&amp;gt;mss_cache in tcp_sync_mss not minus SACK option&lt;br /&gt;
    in &lt;em&gt;tcp_current_mss&lt;/em&gt; minus SACK option&lt;br /&gt;
rfc1122&lt;br /&gt;
+ IP option is  fixed in a session icsk-&amp;gt;icsk_ext_hdr_len;&lt;br /&gt;
+ is network header icsk-&amp;gt;icsk_af_ops-&amp;gt;net_header_len&lt;br /&gt;
+ tcp_sock-&amp;gt;tcp_header_len all except SACK option (Not sure)&lt;br /&gt;
##Reference&lt;br /&gt;
&lt;a href=&#34;http://www.tecmint.com/ipv4-and-ipv6-comparison/&#34;&gt;What’s wrong with IPv4 and Why we are moving to IPv6&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;classless-inter-domain-routing&#34;&gt;Classless Inter-Domain Routing&lt;/h2&gt;

&lt;p&gt;CIDR is a method for allocating IP addresses and routing Internet Protocol packets.&lt;br /&gt;
IETF introduced CIDR in 1993 to replace the classful network.&lt;br /&gt;
* prefix/length&lt;br /&gt;
* Prefix aggregation&lt;/p&gt;

&lt;p&gt;##Supernetwork&lt;br /&gt;
prefix/route aggregation&lt;br /&gt;
decrease the memroy and the time of search route table.&lt;/p&gt;

&lt;h2 id=&#34;private-network&#34;&gt;Private network&lt;/h2&gt;

&lt;p&gt;In the Internet addressing architecture, a private network is a network that uses private IP address space.&lt;/p&gt;

&lt;p&gt;##IP fragmention/defragmention&lt;br /&gt;
iphdr-&amp;gt;id, iphdr-&amp;gt;frag_off&lt;br /&gt;
skb_shared_info-&amp;gt;frag_list&lt;br /&gt;
ip_fragment/ip_defrag&lt;br /&gt;
&lt;a href=&#34;http://tools.ietf.org/html/rfc6864&#34;&gt;Updated Specification of the IPv4 ID Field&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;route&#34;&gt;Route&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;state structure&lt;br /&gt;
fib_info:route info&lt;br /&gt;
fib_config:&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;add new rule&lt;br /&gt;
iproute2 &amp;hellip;-&amp;gt;inet_rtm_newroute()-&amp;gt;fib_new_table()-&amp;gt;fib_hash_table()&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Multi-time line&lt;br /&gt;
fib_create_info(): create a fib_info&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;send&#34;&gt;send&lt;/h1&gt;

&lt;p&gt;ip_append_data 和ip_push_pending_frames弄frag_list&lt;br /&gt;
ip_push_pending_frames -&amp;gt; __ip_make_skb &amp;amp; ip_send_skb -&amp;gt;ip_local_out&lt;br /&gt;
把&amp;amp;sk-&amp;gt;sk_write_queue上的数据最后编程skb链表变成了, 还skb pull掉了潜在的ip 头部&lt;br /&gt;
第一个skb-&amp;gt;frag_list的成员. 用的不太多啊.&lt;br /&gt;
ip_append_data中间出了以为如果可以ufo 那么就到frags的碗里去!&lt;br /&gt;
否则就生成一串skb挂到&amp;amp;sk-&amp;gt;sk_write_queue上,&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transport layer</title>
      <link>http://firoyang.org/net/tcp/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:13 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/net/tcp/</guid>
      <description>

&lt;h1 id=&#34;rfc&#34;&gt;RFC&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://tools.ietf.org/html/rfc7414&#34;&gt;A Roadmap for Transmission Control Protocol (TCP) Specification Documents&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://tools.ietf.org/html/rfc1122&#34;&gt;Requirements for Internet Hosts &amp;ndash; Communication Layers&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://tools.ietf.org/html/rfc793&#34;&gt;TRANSMISSION CONTROL PROTOCOL 1981&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.rfc-editor.org/errata_search.php?rfc=1122&amp;amp;rec_status=15&amp;amp;presentation=records&#34;&gt;RFC Errata 一切都有改口的余地&lt;/a&gt;&lt;br /&gt;
793的errata建议阅读1122.&lt;/p&gt;

&lt;h1 id=&#34;latency&#34;&gt;Latency&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.cloudflare.com/the-story-of-one-latency-spike/&#34;&gt;The story of one latency spike&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;reset&#34;&gt;Reset&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://blogs.technet.microsoft.com/networking/2009/08/12/where-do-resets-come-from-no-the-stork-does-not-bring-them/&#34;&gt;Where do resets come from? (No, the stork does not bring them.)&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;backlog&#34;&gt;Backlog&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html&#34;&gt;How TCP backlog works in Linux&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;本文主要关注tcp这一类的可靠的传输层协议.&lt;br /&gt;
在之前的推理过程中, 我们已经能够明白, tcp的核心性质, 远没有想象&lt;br /&gt;
中那么复杂:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;multiplex, 这是传输层的本质, 标志用户地址, 也就是端口
面向连接的, 收到的数据有序, 且存在session也就是握手挥手.
可靠性, 报文一个都不能少.
congestion control, 拥塞控制, 保证网络整体的性能.
flow control, 流控, 保证对端可以良好稳定接收到报文.免得想双11的快递公司被爆仓.
数据校验, 防止传输过程导致数据出错. 我常会想起水浒传中, 戴总送信那段.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对tcp就是围绕这6个核心的性质开始设计, 实现的.&lt;br /&gt;
无论你是看tcp的头部啊, 还是协议栈的代码基本上都逃不出这六点.&lt;br /&gt;
我不建议直接去看内核的tcp实现, 我是吃过苦头的.&lt;br /&gt;
1. 很容易让人掉进去代码里面, 而忘了初衷.&lt;br /&gt;
2. 内核的实现有很多工程性的问题, 这和tcp本身是无关的.比如tcp seq回绕的问题.&lt;/p&gt;

&lt;h1 id=&#34;大话tcp-头部&#34;&gt;大话TCP 头部&lt;/h1&gt;

&lt;p&gt;从上往下, 这也标志了重要性.&lt;br /&gt;
先是, 源目的端口, 属于multiplex.&lt;br /&gt;
接着sequence number, 这是面向连接, 数据有序&lt;br /&gt;
接着是ack, 这是可靠性&lt;br /&gt;
再往下是, offset 处于数据管理需要和tcp无关,&lt;br /&gt;
tcp flags涉及到了多个性质,主要是握手和拥塞&lt;br /&gt;
之后window size, 这是流控.&lt;br /&gt;
之后是checksum, 保证传输过程中不会修改数据.&lt;br /&gt;
你看tcp真的不复杂, 我们只是没有遇到一个好的解读角度, tcp是有鼻子有眼&lt;br /&gt;
很生动的.&lt;/p&gt;

&lt;h1 id=&#34;multiplexing&#34;&gt;Multiplexing&lt;/h1&gt;

&lt;p&gt;Ports can provide multiple endpoints on a single node.&lt;br /&gt;
inet_hash_connect()&lt;/p&gt;

&lt;h1 id=&#34;flow-control&#34;&gt;Flow control&lt;/h1&gt;

&lt;h2 id=&#34;receive-windowsize&#34;&gt;receive windowsize&lt;/h2&gt;

&lt;p&gt;暗含tcp的最大64KB.&lt;/p&gt;

&lt;h2 id=&#34;sliding-window-protocol-滑动窗口协议&#34;&gt;Sliding window protocol 滑动窗口协议&lt;/h2&gt;

&lt;p&gt;首先滑动窗口本身就是一个协议&lt;/p&gt;

&lt;p&gt;Sliding window protocols are used where reliable in-order delivery of packets is required.&lt;br /&gt;
For every ack packet received, the window slides by one packet (logically) to transmit one new packet.&lt;br /&gt;
发送方的发送窗口, 由发送了但没ack和 可用的发送空间,这个通常有对端的receive windowsize指定.&lt;br /&gt;
如果发送了一个可用的发送空间 = receive windowsize - 那个报文大小, 新来报文更新串口.&lt;br /&gt;
接收端的窗口就是最后收到连续到不连续的位置.&lt;/p&gt;

&lt;h1 id=&#34;detection-of-transmission-errors&#34;&gt;Detection of transmission errors&lt;/h1&gt;

&lt;p&gt;Error &amp;ndash;  checksum, the transport protocol may check that the data is not corrupted&lt;/p&gt;

&lt;h1 id=&#34;connection-oriented-communications&#34;&gt;Connection-oriented communications&lt;/h1&gt;

&lt;p&gt;到底什么是面向连接的网上只有wikipedia给的解释最合理, 其他的扯到了别的性质.&lt;br /&gt;
两点: session and in order.&lt;br /&gt;
* Session&lt;br /&gt;
In computer science, in particular networking, a session is a semi-permanent&lt;br /&gt;
interactive information interchange.&lt;br /&gt;
&lt;a href=&#34;http://www.scottklement.com/rpg/socktut/overview.html&#34;&gt;Instance of tcp session in BSD socket&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.dummies.com/how-to/content/network-basics-tcp-session-establishment-handshaki.html&#34;&gt;TCP Session - Handshaking in protocol&lt;/a&gt;&lt;br /&gt;
这个对应tcp的三次握手, 4次挥手,&lt;br /&gt;
* in order&lt;br /&gt;
涉及到的另外一个概念Virtul circuit&lt;br /&gt;
A virtual circuit (VC) is a means of transporting data over a packet switched&lt;br /&gt;
 computer network in such a way that it appears as though there is a dedicated&lt;br /&gt;
physical layer link between the source and destination end systems of this data.&lt;br /&gt;
对应tcp 的接收队列, seq number&lt;/p&gt;

&lt;h2 id=&#34;handshak&#34;&gt;Handshak&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;kproxy reorder&lt;br /&gt;
chome -&amp;gt;syn(kproxy reocrd syn) -&amp;gt; firoyang.org&lt;br /&gt;
firoyang.org -&amp;gt;sync ack -&amp;gt; chrome&lt;br /&gt;
chrome -&amp;gt; ack -&amp;gt; firoyang.org&lt;br /&gt;
chrome -&amp;gt; GET(firoyang.org) kproxy match then send record syn then setup natinfo -&amp;gt;nginx&lt;br /&gt;
nginx -&amp;gt; tcp send fake syn ack-&amp;gt;chrome&lt;br /&gt;
chrome -&amp;gt; ack -&amp;gt; nginx(then -&amp;gt; firoyang.org)&lt;br /&gt;
tcp_v4_do_rcv{&lt;br /&gt;
sk-&amp;gt;sk_state == TCP_ESTABLISHED&lt;br /&gt;
tcp_rcv_established{&lt;br /&gt;
len &amp;lt;= tcp_header_len =&amp;gt;&lt;br /&gt;
tcp_ack -&amp;gt; tcp_fastretrans_alert{retrans ack and GET(firoyang) -&amp;gt; nginx&lt;br /&gt;
}&lt;br /&gt;
}&lt;br /&gt;
nginx-&amp;gt;GET -&amp;gt;firoyang.org&lt;br /&gt;
firoyang.org-&amp;gt;nginx-&amp;gt;chrome&lt;/p&gt;

&lt;h2 id=&#34;syn-flood&#34;&gt;syn flood&lt;/h2&gt;

&lt;p&gt;首先syn 也有超时5次指数1 2 4 8 16 32(第五次超时), 如果client发了一个syn就没了,&lt;br /&gt;
会被黑客利用. 解决办法是tcp_syncookies, 在syn队列满了的时候, 构造一个特别isn,&lt;br /&gt;
丢掉syn entry, 等待ack,校验合法直接accpet.好像incomplete队列无限大一般.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;深入理解seq-和ack&#34;&gt;深入理解seq 和ack&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://serverfault.com/questions/593037/tcp-sequence-acknowledgment-numbers&#34;&gt;TCP Sequence &amp;amp; Acknowledgment numbers&lt;/a&gt;&lt;br /&gt;
这种问题就是咬住定义就完了.&lt;br /&gt;
The sequence number of the first data octet in this segment (except&lt;br /&gt;
    when SYN is present). If SYN is present the sequence number is the&lt;br /&gt;
    initial sequence number (ISN) and the first data octet is ISN+1.&lt;br /&gt;
If the ACK control bit is set this field contains the value of the&lt;br /&gt;
    next sequence number the sender of the segment is expecting to&lt;br /&gt;
    receive.  Once a connection is established this is always sent.&lt;br /&gt;
ACK最简单了, 整个tcp session只有一个segement没有ack number就是第一个syn.&lt;br /&gt;
其他情况, ack都是对面发来的seq + len + 1. (排除reorder包问题)&lt;br /&gt;
这里的问题是第三次握手的时候, 单独一个ack, 没有数据, 这时候segement的seq&lt;br /&gt;
应该是多少呢?RFC给出的是ISN + 1.但这个ack segment是个空数据.&lt;br /&gt;
也就出现了下面发一个GET的时seq 和ack number和这个ack segement一致.&lt;br /&gt;
那么如果交互过程中出现了空的ack呢?原理和这里是一样的. 空的ack 的seq也是&lt;br /&gt;
标志下一个segement的byte序号, 但是如果no data, 下一个segment的seq还是这个.&lt;br /&gt;
知道有数据了.&lt;br /&gt;
这里想说的是, seq确实是标注segment的data, 知识偶尔因为空ack导致了假象, 会&lt;br /&gt;
被后面的有数据的segement还原真相.&lt;br /&gt;
总结:&lt;br /&gt;
    syn 和 ack, 还有fin这种都不是数据, 不计算在seq里面.&lt;br /&gt;
    seq的计算只和实际的数据有关.&lt;br /&gt;
    小心处理no data这种情况, 就OK了.&lt;/p&gt;

&lt;h2 id=&#34;time-wait&#34;&gt;Time wait&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/dog250/article/details/13760985&#34;&gt;TCP的TIME_WAIT快速回收与重用&lt;/a&gt;&lt;br /&gt;
双工, 被动关闭收到ack就%100圆满了.而clinet就不能确认被动关闭是否收到ack,&lt;br /&gt;
显然被动关闭方不能在ack了, 如果下去, 还有个完, 所以两害相权, 取其轻.clinet来吧.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;为了server考虑, server的session 链接必须别正常正确的关闭!&lt;br /&gt;
如果没有time wait, 而且client的ack丢了, server 重传fin ack, clinet的linux&lt;br /&gt;
发现这个fin对应的sock不存在, 直接RST, server异常关闭, 应用程序会检测到错误.&lt;br /&gt;
不友好.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;为了clinet, 不受旧server 干扰.&lt;br /&gt;
这也是为什么要等2MSL&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;tcp_timestamps tcp_tw_recycle&lt;br /&gt;
tcp_time_wait&lt;br /&gt;
一起用如果recycle 不ok就是time wait就是TCP_TIMEWAIT_LEN（60s）&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;两种方法可以进入time wait 状态 tw_substate做区分.&lt;br /&gt;
FIN_WAIT_2 收到fin 见tcp_fin()这个函数&lt;br /&gt;
这个, time wait 如果没有设置recycle就是TCP_TIMEWAIT_LEN,设置了就是rto&lt;br /&gt;
可以说rto的值真的要比TCP_TIMEWAIT_LEN要小.&lt;/p&gt;

&lt;p&gt;FIN_WAIT_2 超时假的time wait状态.貌似tcp_keepalive_timer()&lt;br /&gt;
没有遵从协议但是没有break协议,是个优化.&lt;br /&gt;
tcp_sock结构占用的资源要比tcp_timewait_sock结构占用的资源多, tcp_done干掉sock.&lt;br /&gt;
在TIME_WAIT下也可以处理连接的关闭。&lt;br /&gt;
这个,还一样time_wait是和rto TCP_TIMEWAIT_LEN有关.&lt;br /&gt;
inet_twsk_schedule设置等的时间.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;tcp_tw_reuse&lt;br /&gt;
貌似很激进.&lt;br /&gt;
FIXME&lt;br /&gt;
server 端玩蛋去, 本身像80, 自带重用技能&amp;hellip;&lt;br /&gt;
用在clinet段inet_hash_connect检查是否可以重用TIME_WAIT状态的套接字的端口.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;tcp_fin_timeout&lt;br /&gt;
这个参数是FIN_WAIT_2 转到TIME_WAIT的时间.&lt;br /&gt;
跟time wait时间, 没有直接联系! 好多blog都直接说成time wait的时间.&lt;br /&gt;
这里是间接作用.&lt;br /&gt;
FIXME&amp;hellip;&lt;br /&gt;
而time wait的时间看代码, 要不然是rto 要不然就是TCP_TIMEWAIT_LEN(60s)&lt;br /&gt;
tcp_time_wait&lt;br /&gt;
            if (recycle_ok) {&lt;br /&gt;
                    tw-&amp;gt;tw_timeout = rto;&lt;br /&gt;
            } else {&lt;br /&gt;
                    tw-&amp;gt;tw_timeout = TCP_TIMEWAIT_LEN;&lt;br /&gt;
                    if (state == TCP_TIME_WAIT)&lt;br /&gt;
                            timeo = TCP_TIMEWAIT_LEN;&lt;br /&gt;
            }&lt;br /&gt;
如果启用recycle 就是rto, 这个rto是const int rto = (icsk-&amp;gt;icsk_rto &amp;lt;&amp;lt; 2) - (icsk-&amp;gt;icsk_rto &amp;gt;&amp;gt; 1);&lt;br /&gt;
3.5倍的icsk_rto&lt;br /&gt;
在FIN_WAIT_2状态下没有接收到FIN包就进入TIME_WAIT的情况下，如果tcp_fin_timeout的值设置的太小，可能会导致TIME_WAIT套接字（子状态为FIN_WAIT_2）过早地被释放，这样对端发送的FIN（短暂地延迟或者本来就是正常的时间到达）到达时就没有办法处理，导致连接不正常关闭，所以tcp_fin_timeout参数的值并不是越小越好，通常设置为30S比较合适。&lt;/p&gt;

&lt;h1 id=&#34;reliability&#34;&gt;Reliability&lt;/h1&gt;

&lt;h2 id=&#34;rtt&#34;&gt;RTT&lt;/h2&gt;

&lt;p&gt;计算发送和返回ack的时间差.&lt;br /&gt;
tcp_rtt_estimator()&lt;/p&gt;

&lt;h2 id=&#34;arq&#34;&gt;ARQ&lt;/h2&gt;

&lt;p&gt;ack and timeout&lt;br /&gt;
Sliding window protocol is based on automatic repeat request/ARQ&lt;br /&gt;
My conclusion: in practice TCP is a mixture between both GBN and SR.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Go-Back-N&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Selective repeat&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;#FAQ&lt;br /&gt;
* What about TCP sequence number warp around&lt;br /&gt;
PAWS use timestamp and RTT to solve this problem.&lt;br /&gt;
##Timer&lt;br /&gt;
*sk_timer&lt;br /&gt;
listen: synack&lt;br /&gt;
estblished: keepalive&lt;br /&gt;
timewait:&lt;/p&gt;

&lt;h1 id=&#34;optimization&#34;&gt;optimization&lt;/h1&gt;

&lt;h2 id=&#34;nagle&#34;&gt;Nagle&lt;/h2&gt;

&lt;p&gt;Nagle算法并没有阻止发送小包，它只是阻止了发送大量的小包！&lt;br /&gt;
Nagle算法的初衷：避免发送大量的小包，防止小包泛滥于网络，理想情况下，&lt;br /&gt;
对于一个TCP连接而言，网络上每次只能一个小包存在。它更多的是端到端意义上的优化。&lt;br /&gt;
正是交互式应用引入了大量的小包，Nagle算法所作用的正是交互式应用！&lt;/p&gt;

&lt;h2 id=&#34;cork&#34;&gt;Cork&lt;/h2&gt;

&lt;p&gt;CORK算法的初衷：提高网络利用率，理想情况下，完全避免发送小包，仅仅发送满包以及不得不发的小包。&lt;br /&gt;
CORK的真正初衷是提高载荷率，提高网络利用率&lt;/p&gt;

&lt;h2 id=&#34;fixme&#34;&gt;FIXME&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Create TCP options&lt;br /&gt;
tcp_syn_build_options()&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Receive ack&lt;br /&gt;
tcp_ack()&lt;br /&gt;
记录ack的数据大小mss or tcp abc&lt;br /&gt;
update snd_wl1 and snd_una&lt;br /&gt;
slow path update mtu mss tcp_skb_cb.sacked&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Active send data&lt;br /&gt;
tcp_sendpage()/tcp_sendmsg()-&amp;gt;tcp_write_xmit()/tcp_push_one()-&amp;gt;tcp_transmit_skb&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Timer expiring retransmiter&lt;br /&gt;
tcp_retransmiter_timer()&amp;hellip;-&amp;gt;tcp_transmit_skb()&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;reponse for receiving an ACK&lt;br /&gt;
tcp_data_snd_check()-&amp;gt;tcp_write_xmit()&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;tcp_v4_rcv&lt;br /&gt;
&lt;a href=&#34;http://thread.gmane.org/gmane.linux.network/85613/focus=85614&#34;&gt;skb-&amp;gt;dev = NULL;&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;tcp的核心发包函数tcp_write_xmit and tcp_transmit_skb&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
