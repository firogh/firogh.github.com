<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Net on f(x) </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://firoyang.org/tags/net/</link>
    <language>en-us</language>
    <author>Firo Yang</author>
    
    <updated>Sun, 10 May 2015 15:46:13 CST</updated>
    
    <item>
      <title>Understanding linux netfilter</title>
      <link>http://firoyang.org/net/netfilter/</link>
      <pubDate>Sun, 10 May 2015 15:46:13 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/net/netfilter/</guid>
      <description>

&lt;h1 id=&#34;netfilter&#34;&gt;Netfilter&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.netfilter.org/documentation/HOWTO//netfilter-hacking-HOWTO.html&#34;&gt;Linux netfilter Hacking HOWTO&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.karlrupp.net/en/computer/nat_tutorial&#34;&gt;NAT - Network Address Translation&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://drive.google.com/open?id=1F-qJiqahUPgknv8EHnnYGUf6n6mQfPe-&#34;&gt; Netfilter traversal&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;hooks&#34;&gt;Hooks&lt;/h2&gt;

&lt;p&gt;NF_INET_PRE_ROUTING: ip_rcv&lt;br /&gt;
NF_INET_LOCAL_IN: ip_local_deliver&lt;br /&gt;
NF_INET_FORWARD: ip_forward&lt;br /&gt;
NF_INET_LOCAL_OUT: __ip_local_out&lt;br /&gt;
NF_INET_POST_ROUTING: ip_output&lt;/p&gt;

&lt;h2 id=&#34;priority&#34;&gt;Priority&lt;/h2&gt;

&lt;p&gt;enum nf_ip_hook_priorities {&lt;br /&gt;
        NF_IP_PRI_FIRST = INT_MIN,&lt;br /&gt;
        NF_IP_PRI_RAW_BEFORE_DEFRAG = -450,&lt;br /&gt;
        NF_IP_PRI_CONNTRACK_DEFRAG = -400,&lt;br /&gt;
        NF_IP_PRI_RAW = -300,&lt;br /&gt;
        NF_IP_PRI_SELINUX_FIRST = -225,&lt;br /&gt;
        NF_IP_PRI_CONNTRACK = -200,&lt;br /&gt;
        NF_IP_PRI_MANGLE = -150,&lt;br /&gt;
        NF_IP_PRI_NAT_DST = -100,&lt;br /&gt;
        NF_IP_PRI_FILTER = 0,&lt;br /&gt;
        NF_IP_PRI_SECURITY = 50,&lt;br /&gt;
        NF_IP_PRI_NAT_SRC = 100,&lt;br /&gt;
        NF_IP_PRI_SELINUX_LAST = 225,&lt;br /&gt;
        NF_IP_PRI_CONNTRACK_HELPER = 300,&lt;br /&gt;
        NF_IP_PRI_CONNTRACK_CONFIRM = INT_MAX,&lt;br /&gt;
        NF_IP_PRI_LAST = INT_MAX,};&lt;/p&gt;

&lt;h2 id=&#34;xtables&#34;&gt;xtables&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Iptables#Overview&#34;&gt;Overview of xtables in wikipedia&lt;/a&gt;&lt;br /&gt;
xt_table: ipt_register_table&lt;br /&gt;
struct xt_table         *iptable_filter;&lt;br /&gt;
struct xt_table         *iptable_mangle;&lt;br /&gt;
struct xt_table         *iptable_raw;&lt;br /&gt;
struct xt_table         *arptable_filter;&lt;br /&gt;
struct xt_table         *iptable_security;&lt;br /&gt;
struct xt_table         *nat_table;&lt;br /&gt;
xt_target: xt_register_target&lt;br /&gt;
xt_match: xt_register_match&lt;/p&gt;

&lt;h2 id=&#34;nftables&#34;&gt;nftables&lt;/h2&gt;

&lt;h2 id=&#34;onset&#34;&gt;Onset&lt;/h2&gt;

&lt;p&gt;netfilter_init(), mark_mt_init&lt;/p&gt;

&lt;h2 id=&#34;nuclus&#34;&gt;Nuclus&lt;/h2&gt;

&lt;p&gt;nf_hooks -&amp;gt; iptable_mangle_hook -&amp;gt; ipt_do_table -&amp;gt;&amp;hellip;&lt;br /&gt;
ipt_do_table() nat, filter, mangle.&lt;/p&gt;

&lt;h1 id=&#34;connection-tracking&#34;&gt;Connection tracking&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://people.netfilter.org/pablo/docs/login.pdf&#34;&gt;Netfilter’s connection tracking system&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.netdevconf.org/2.1/session.html?westphal&#34;&gt;netfilters connection tracking subsystem&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.linuxjournal.com/article/4234&#34;&gt;Network Probes Explained: Understanding Port Scans and Ping Sweeps&lt;/a&gt;&lt;br /&gt;
Each Netfilter connection is uniquely identified by a 5-arry (layer-3 protocol, source address, destination address, layer-4 protocol, layer-4 key) tuple&lt;br /&gt;
Connection tracking helper: connection tracking can be given knowledge of application-layer protocols&lt;br /&gt;
nf_conntrack: support conntrack templates&lt;/p&gt;

&lt;h2 id=&#34;onset-1&#34;&gt;Onset&lt;/h2&gt;

&lt;p&gt;nf_conntrack_standalone_init, nf_conntrack_l3proto_ipv4_init&lt;/p&gt;

&lt;h2 id=&#34;nuclus-1&#34;&gt;Nuclus&lt;/h2&gt;

&lt;p&gt;conntrack &amp;ndash; user-land tools&lt;br /&gt;
obsolete /proc/net/nf_conntrack&lt;/p&gt;

&lt;h3 id=&#34;details&#34;&gt;Details&lt;/h3&gt;

&lt;p&gt;基本思路是：一个包来了，转换其tuple，看其在连接跟踪表中没有，有的话，更新其状态，以其做一些与协议相关的工作，如果没有，则分配一个新的连接表项，并与skb_buff关连，但是问题是，这个表项，还没有被加入连接表当中来。其实这样做的理由很简单，因为这个时候，这个包是否有机会活命还是个未知数，例如被其它模块给Drop了……所以，要等到一切安全了，再来将这个表项插入至连接跟踪表。&lt;br /&gt;
这个“一切安全”当然是Netfilter所有的模块处理完了，最完全了。 徐琛,也这么说!&lt;/p&gt;

&lt;h1 id=&#34;mangle&#34;&gt;Mangle&lt;/h1&gt;

&lt;h2 id=&#34;onset-2&#34;&gt;Onset&lt;/h2&gt;

&lt;p&gt;iptable_mangle_init&lt;/p&gt;

&lt;h1 id=&#34;nat&#34;&gt;NAT&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ietf.org/rfc/rfc3489.txt&#34;&gt;https://www.ietf.org/rfc/rfc3489.txt&lt;/a&gt;&lt;br /&gt;
symmetric nat, 端口不复用, 访问同一个服务器.&lt;br /&gt;
Drop ICMP redict in NAT:&lt;a href=&#34;http://www.netfilter.org/documentation/HOWTO/NAT-HOWTO-10.html&#34;&gt;http://www.netfilter.org/documentation/HOWTO/NAT-HOWTO-10.html&lt;/a&gt;&lt;br /&gt;
static const struct nf_hook_ops nf_nat_ipv4_ops[] = {&lt;br /&gt;
        {&lt;br /&gt;
                .hook           = iptable_nat_do_chain,&lt;br /&gt;
                .pf             = NFPROTO_IPV4,&lt;br /&gt;
                .hooknum        = NF_INET_PRE_ROUTING,&lt;br /&gt;
                .priority       = NF_IP_PRI_NAT_DST,&lt;br /&gt;
        },&lt;br /&gt;
        {&lt;br /&gt;
                .hook           = iptable_nat_do_chain,&lt;br /&gt;
                .pf             = NFPROTO_IPV4,&lt;br /&gt;
                .hooknum        = NF_INET_POST_ROUTING,&lt;br /&gt;
                .priority       = NF_IP_PRI_NAT_SRC,&lt;br /&gt;
        },&lt;br /&gt;
        {&lt;br /&gt;
                .hook           = iptable_nat_do_chain,&lt;br /&gt;
                .pf             = NFPROTO_IPV4,&lt;br /&gt;
                .hooknum        = NF_INET_LOCAL_OUT,&lt;br /&gt;
                .priority       = NF_IP_PRI_NAT_DST,&lt;br /&gt;
        },&lt;br /&gt;
        {&lt;br /&gt;
                .hook           = iptable_nat_do_chain,&lt;br /&gt;
                .pf             = NFPROTO_IPV4,&lt;br /&gt;
                .hooknum        = NF_INET_LOCAL_IN,&lt;br /&gt;
                .priority       = NF_IP_PRI_NAT_SRC,&lt;br /&gt;
        },};&lt;/p&gt;

&lt;h2 id=&#34;onset-3&#34;&gt;Onset&lt;/h2&gt;

&lt;p&gt;iptable_nat_init&lt;/p&gt;

&lt;h2 id=&#34;nuclus-2&#34;&gt;Nuclus&lt;/h2&gt;

&lt;p&gt;NAT helper: Similar to connection tracking helpers, NAT helpers will do a packet inspection and substitute original addresses by reply addresses in the payload.&lt;/p&gt;

&lt;h3 id=&#34;snat&#34;&gt;SNAT&lt;/h3&gt;

&lt;p&gt;nf_nat_ipv4_out -&amp;gt; nf_nat_ipv4_fn -&amp;gt;&lt;br /&gt;
{&lt;br /&gt;
    nf_nat_rule_find -&amp;gt; ipt_do_table -&amp;gt; xt_snat_target_v1 -&amp;gt; nf_nat_setup_info&lt;br /&gt;
    {&lt;br /&gt;
        无论是SNAT, 还是DNAT,改的都是ct的reply. 所以这里先把 orig_rely的对应的orig_original形式弄出来.&lt;br /&gt;
        但是,必须要保证改skb的真实值要保证source 唯一, orig_original -&amp;gt; new_original找到后再revert,成new_reply在改到ct里面去.&lt;br /&gt;
        orig_orignal-&amp;gt;skb&lt;br /&gt;
        nf_ct_invert_tuplepr(inverse, orig_relply)&lt;br /&gt;
        {&lt;br /&gt;
            ipv4_invert_tuple&lt;br /&gt;
            tcp_invert_tuple&lt;br /&gt;
            For example, orig tuple:&lt;br /&gt;
            original: 192.168.199.132 -&amp;gt; google.com&lt;br /&gt;
            reply: google.com -&amp;gt; 192.168.199.132 //this is orig_relpy&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        inverse tuple:
        original(inverse-&amp;gt;dst.dir = !orig-&amp;gt;dst.dir;):
        192.168.199.132 -&amp;gt; google.com (!!!reverse orig_reply in ipv4_inver_tuple())
         这个函数的用途可能是担心, orig被人改了, 不能用了.
        except for prior manipulations
    }       
    get_unique_tuple
    {
        1. 如果snat, 且前后可以一致就直接new=orig, 合理.
        2. find_appropriate_src 费点力... 貌似找到已经用到的, 复用
        3. find_best_ips_proto, 找一个 the least-used IP/proto combination in the given range
        4. nf_nat_used_tuple 保证唯一
    }       
    bysoruce 里面存的应该是new_original, hash -&amp;gt; &amp;amp;net-&amp;gt;ct.nat_bysource[srchash]
}
//上面ct改完了该改skb了.
nf_nat_packet -&amp;gt; nf_nat_ipv4_manip_pkt,
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SNAT nftables&lt;br /&gt;
nf_nat_prerouting &amp;hellip;-&amp;gt; nft_do_chain&lt;br /&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;One kind of NAT, just set one flag bit in ct-&amp;gt;status (SRC_NAT or DST_NAT), but set both SRC/DST_DONE!&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;De-NAT&lt;br /&gt;
最简单的路由器 在postrouting 做了snat（masquade）那么回来的报文怎么unsnat呢？&lt;br /&gt;
我看了九贱的帖子，一笔带过了。 我不太懂的地方是在nat_packet这个函数里面在发现是rely的报文，要判断ct→status &amp;amp; IPS_DST_NAT 为真 才修改skb里的IP port，我不清楚reply的报文何时给ct→status打的DST_NAT的标记位，看代码好象是prerouting的ip_nat_setup_info这个函数，可是我看到必须改了ct的tuple才能给ct→status打标记位，反复的修改ct，我觉得自己想的不对。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;*答案3.17的代码和原来没多大变化就是函数名字变了&lt;br /&gt;
发包-POSTROUTING -&amp;gt;SNAT -&amp;gt;修改ct: nf_nat_setup_info-&amp;gt;　ct-&amp;gt;status |= IPS_SRC_NAT;-&amp;gt;修改skb:nf_nat_packet&lt;/p&gt;

&lt;p&gt;收报-PREOUTING-&amp;gt; DNAT-&amp;gt;修改skb:nf_nat_packet&lt;br /&gt;
{&lt;br /&gt;
    enum nf_nat_manip_type mtype = HOOK2MANIP(hooknum);&lt;br /&gt;
    //因为是在PREROUTING, 所以是DNAT, 我以前一直以为, de-snat在postrouting中做的.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if (mtype == NF_NAT_MANIP_SRC)          
    statusbit = IPS_SRC_NAT;             
else                                      
    statusbit = IPS_DST_NAT;        //到这里

/* Invert if this is reply dir. */            
if (dir == IP_CT_DIR_REPLY) 
    statusbit ^= IPS_NAT_MASK;        //翻转一下变成SNAT 
/* Non-atomic: these bits don&#39;t change. */                                                                                                    
if (ct-&amp;gt;status &amp;amp; statusbit) {                 
//正好和发包是的   ct-&amp;gt;status |= IPS_SRC_NAT;匹配了, 开始de-snat.                    
    struct nf_conntrack_tuple target;
    ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;h1 id=&#34;ipset&#34;&gt;ipset&lt;/h1&gt;

&lt;p&gt;salist for iptables&lt;/p&gt;

&lt;h1 id=&#34;syn-proxy&#34;&gt;SYN proxy&lt;/h1&gt;

&lt;p&gt;SYNPROXY target makes handling of large SYN floods possible without the large performance penalties imposed by the connection tracking in such cases. On 3 November 2013, SYN proxy functionality was merged into the Netfilter, with the release of version 3.12 of the Linux kernel mainline&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data link layer</title>
      <link>http://firoyang.org/net/link/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:13 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/net/link/</guid>
      <description>

&lt;h1 id=&#34;multi-queue&#34;&gt;Multi-queue&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://greenhost.nl/2013/04/10/multi-queue-network-interfaces-with-smp-on-linux/&#34;&gt;Multi-queue network interfaces with SMP on Linux&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;common-concepts&#34;&gt;Common concepts&lt;/h1&gt;

&lt;p&gt;The link layer is the group of methods and communications protocols that only operate on the link that a host is physically connected to.&lt;br /&gt;
The link is the physical and logical network component used to interconnect hosts or nodes in the network&lt;br /&gt;
A link protocol is a suite of methods and standards that operate only between adjacent network nodes of a local area network segment or a wide area network connection.&lt;/p&gt;

&lt;h1 id=&#34;frame&#34;&gt;Frame&lt;/h1&gt;

&lt;p&gt;ULNI page 283: Figure 13-8. Differences between Ethernet and 802.3 frames&lt;/p&gt;

&lt;h1 id=&#34;l2-header&#34;&gt;L2 header&lt;/h1&gt;

&lt;p&gt;dst_neigh_output-&amp;gt;dev_hard_header -&amp;gt;  eth_header&lt;/p&gt;

&lt;h1 id=&#34;neighbor&#34;&gt;Neighbor&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;ip_output_finish2 -&amp;gt; __neigh_create -&amp;gt; tbl-&amp;gt;constructor -&amp;gt; arp_constructor{&lt;br /&gt;
if !dev-&amp;gt;header_ops   //slip is the case, see sl_setup&lt;br /&gt;
neigh-&amp;gt;ops = &amp;amp;arp_direct_ops&lt;br /&gt;
neigh-&amp;gt;output = neigh_direct_output&lt;br /&gt;
else if ARPHRD_ROSE/AX25/NETROM&lt;br /&gt;
arp_broken_ops&lt;br /&gt;
neigh-&amp;gt;ops-&amp;gt;output&lt;br /&gt;
else if dev-&amp;gt;header_ops-&amp;gt;cache&lt;br /&gt;
neigh-&amp;gt;ops = &amp;amp;arp_hh_ops&lt;br /&gt;
else&lt;br /&gt;
arp_generic_ops&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;if (neigh-&amp;gt;nud_state &amp;amp; NUD_VALID)&lt;br /&gt;
    neigh-&amp;gt;output = neigh-&amp;gt;ops-&amp;gt;connected_output;&lt;br /&gt;
else&lt;br /&gt;
    neigh-&amp;gt;output = neigh-&amp;gt;ops-&amp;gt;output;&lt;br /&gt;
}&lt;br /&gt;
* ip_output_finish2 -&amp;gt; dst_neigh_output -&amp;gt; neigh_resolve_output&lt;br /&gt;
*  ipv4 Neighbor output instance of ethernet&lt;br /&gt;
see alloc_etherdev_mqs-&amp;gt; ether_setup{&lt;br /&gt;
dev-&amp;gt;header_ops = &amp;amp;eth_header_ops;&lt;br /&gt;
dev-&amp;gt;type       = ARPHRD_ETHER;&lt;br /&gt;
eth_header_ops.cache = eth_header_cache&lt;br /&gt;
}&lt;br /&gt;
so neigh-&amp;gt;ops = &amp;amp;arp_hh_ops; neigh-&amp;gt;output = neigh_resolve_output in arp_hh_ops&lt;br /&gt;
    //tg3_init_one&lt;br /&gt;
    dev-&amp;gt;netdev_ops = &amp;amp;tg3_netdev_ops;&lt;br /&gt;
    dev-&amp;gt;ethtool_ops = &amp;amp;tg3_ethtool_ops;&lt;br /&gt;
    dev-&amp;gt;watchdog_timeo = TG3_TX_TIMEOUT;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//In ppp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;static void ppp_setup(struct nethernetet_device *dev)&lt;br /&gt;
{&lt;br /&gt;
    dev-&amp;gt;netdev_ops = &amp;amp;ppp_netdev_ops;&lt;br /&gt;
    dev-&amp;gt;hard_header_len = PPP_HDRLEN;&lt;br /&gt;
    dev-&amp;gt;mtu = PPP_MRU;&lt;br /&gt;
    dev-&amp;gt;addr_len = 0;&lt;br /&gt;
    dev-&amp;gt;tx_queue_len = 3&lt;br /&gt;
    dev-&amp;gt;type = ARPHRD_PPP&lt;br /&gt;
}&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux Network Stack - an obselete article for warning myself that never think or learn in this way</title>
      <link>http://firoyang.org/net/obselete_net/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:13 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/net/obselete_net/</guid>
      <description>

&lt;p&gt;#Reference&lt;br /&gt;
&lt;a href=&#34;http://www.securitywizardry.com/index.php/tools/packet-headers.html&#34;&gt;RAW PACKET FORMATS&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://wangcong.org/2012/10/15/-e4-bb-8e-ipv4-e5-88-b0-ipv6/&#34;&gt;从 IPv4 到 IPv6&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.tecmint.com/ipv4-and-ipv6-comparison/&#34;&gt;What’s wrong with IPv4 and Why we are moving to IPv6&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://lwn.net/Articles/629155/&#34;&gt;Improving Linux networking performance&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://wiki.linuxfoundation.org/networking/kernel_flow&#34;&gt;Monitoring and Tuning the Linux Networking Stack: Sending Data&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The Feynman map of network, check &lt;a href=&#34;https://www.slideshare.net/ThomasGraf5/devconf-2014-kernel-networking-walkthrough&#34;&gt;Thomas Graf&amp;rsquo;s DevConf 2014 Kernel Networking Walkthrough&lt;/a&gt;&lt;br /&gt;
When we talk about network, what we talk about?&lt;br /&gt;
Transfer; Truely we are talking about transfer including three component:src, dst, channel.&lt;br /&gt;
Address has two properties: relation and scope.&lt;/p&gt;

&lt;h2 id=&#34;什么是internet&#34;&gt;什么是Internet&lt;/h2&gt;

&lt;p&gt;英文&lt;a href=&#34;http://keithbriggs.info/network.html&#34;&gt;network&lt;/a&gt;, 其中work, 构造之意.&lt;br /&gt;
etymonline 给出结缔成网之意, net-like arrangement of threads, wires, etc.&lt;br /&gt;
Network -&amp;gt; Telecommunications network -&amp;gt; Computer network -&amp;gt; Internet&lt;/p&gt;

&lt;p&gt;The Internet is a global system of interconnected computer networks that use&lt;br /&gt;
the standard Internet protocol suite (TCP/IP) to link several billion devices worldwide.&lt;br /&gt;
Internet protocol suite,是结网的策略方法核心.&lt;/p&gt;

&lt;h1 id=&#34;internet-protocol-suite&#34;&gt;Internet protocol suite&lt;/h1&gt;

&lt;p&gt;The Internet protocol suite is the computer networking model and set of&lt;br /&gt;
communications protocols used on the Internet and similar computer networks.&lt;/p&gt;

&lt;p&gt;通常简称&lt;a href=&#34;http://en.wikipedia.org/wiki/Protocol_stack&#34;&gt;protocol stack&lt;/a&gt;, 即协议栈&lt;br /&gt;
The protocol stack is an implementation of a computer networking protocol suite.&lt;br /&gt;
&lt;a href=&#34;http://en.wikipedia.org/wiki/Internet_protocol_suite&#34;&gt;Internet protocol suite &amp;ndash; TCP/IP&lt;/a&gt;就是一种&lt;a href=&#34;http://en.wikipedia.org/wiki/List_of_network_protocol_stacks&#34;&gt;protocol stack.&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;为什么协议要分层-怎么分&#34;&gt;为什么协议要分层? 怎么分?&lt;/h2&gt;

&lt;p&gt;这是非常有深度的问题! 可以说本文价值所在.&lt;br /&gt;
这里讨论的是如何设计一套网络协议.&lt;br /&gt;
抛开TCP/IP, 如果要让我门自己设计一套 network protocol, 有什么思路?&lt;br /&gt;
发送方, 接收方, 信息. 这是所有信息传递的要素, 无论是, 狼烟, 信鸽, 还是书信.&lt;br /&gt;
不同的是, 信息传递的方式.狼烟这种大范围视觉方式, 关心的最少, 敌人来犯点着烟就行了.&lt;br /&gt;
那么信鸽了, 信鸽的英文叫做Homing pigeon, 信鸽的归巢本能, 为我指定了信息的接收房.&lt;br /&gt;
抛开隐私, 我们能把信放大到天空那么大, 收信人抬下头也能收到信息.&lt;br /&gt;
对于书信的方式, 在信息不能广泛的传递给每个人的时候, 我们需要把信送到特定的人手里.&lt;br /&gt;
信的地址就成了必选. 信息传输的方法决定了, 接收者的特征集合.&lt;br /&gt;
protocol暗指communications protocol, protocol词源上便指diplomatic rules of etiquette&lt;br /&gt;
一种合适的交流手段. 而The Internet protocol suite的定义中明确指明了computer networking model.&lt;br /&gt;
也就是源于方法决定对象的经验结论, wikipedia上的定义是非常有见地的.&lt;br /&gt;
所以回到计算机框架下的信息传输设计. 受限于计算机数据的交互方法, 我们必须指明信息的接收方.&lt;br /&gt;
所以我来设计一套network protocol, 第一点, 就是如何表示每个计算机收信方, 也就是地址.&lt;br /&gt;
地址成了网络协议的本体!有了地址后, 如何寻址就是个问题了, 这属于衍生的问题, 没什么意思了.&lt;br /&gt;
我们假装, 已经设计出一套惊天地泣鬼神的寻路方法, 还是叫寻址更好, 寻找目的地址.&lt;br /&gt;
我们只是道出了, 网络协议的基本的要素接收方的本质属性, 也就是model. 那么, 我们怎么定义方法呢?&lt;br /&gt;
传输无外乎, 你有消息, 给我发个信, 再有消息, 再发, 当然我也可以给你发. 结合到实际的计算机领域,&lt;br /&gt;
假如, 我们只有地址和寻址方法的寒酸网络协议, 在一个小函数里搞定了.&lt;br /&gt;
为什么OSI和TCP/IP都搞得那么复杂?&lt;br /&gt;
下面才是为什么要&lt;a href=&#34;http://en.wikipedia.org/wiki/Abstraction_layer&#34;&gt;分层&lt;/a&gt;, 和怎么分的问题.&lt;br /&gt;
是什么导致了分层? 哲学上, 分乃是不同的存在.也就是说存在我们寒酸的网络协议不同的存在.&lt;br /&gt;
我们现在把linux内核的协议栈替换称我们的poor network protocol, (你现在, 应该知道为什么osi中&lt;br /&gt;
network layer的名字来源了, 正因为他代表了整个网络协议的实质, 所以名字逼格才这么高!)&lt;br /&gt;
显然, 还是不能运行, 为什么?我们缺少和应用层以及底层硬件的交互.也就是空中楼阁!&lt;br /&gt;
加一个poor bsd socket,  poor application layer来了.加一个和底层硬件交互, poor linker layer也来了.&lt;br /&gt;
我靠, 我的协议也有3层了, 拿去用吧.&lt;br /&gt;
我现在把传输层也意淫进来. 显然, 传输层不是这么随便的, 他的存在肯定有着合理的理由.&lt;br /&gt;
事物存在的理由不在于自身! 我认为汉语传输层(transport)是一个被严重误读了的名字, 这不同于人的名字,&lt;br /&gt;
人类的名字是一个标示系统, 比如你叫马机霸, 你就一定要长得像马jb. 而学术领域的, 名字则具有&lt;br /&gt;
另外一个重要的属性就是:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;概念性or推理性的认知.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;即从名字中可以推理出相关属性; 在汉语当中, 我第一次看谢希仁《计算机网络第五版》教材时,&lt;br /&gt;
就感觉这个名字好晕啊!他和传输有半毛钱关系, 传输不是链路层网卡网线的事吗?&lt;br /&gt;
记得老师说了句, 这是一种抽象, 问题旧搁置了.当年未能深入问题, 非常遗憾. 今天补上!&lt;br /&gt;
TCP中的T是transmission和transport中的都被翻译成了汉语的传输!&lt;br /&gt;
有很长一段时间, 我都认为传输层,应该叫做传输控制层, 因为他, 看上去真的更像控制啊!&lt;br /&gt;
那么transmission和transport的区别到底事什么呢?&lt;br /&gt;
看wikipedia的解释, 立马明白了, 这分明说的是传输层的本质啊:&lt;br /&gt;
Transport or transportation is the movement of people, animals and goods from one location to another.&lt;br /&gt;
相信不用看etymonline你也知道transport是怎么来的trans + port, 这里的port是名词港口之意.&lt;br /&gt;
现在, 就明白了为什么port端口号, 虽然实质是地址的含义, 却不属于network层.&lt;br /&gt;
传输层有卸货的含义, 干脆就叫转港层吧!&lt;br /&gt;
transport layer 的巨大意义, 就被显示出来了, 他是必须的.&lt;br /&gt;
实质上我们也应该看到无论是port还是ip address都是地址的含义, 这也是协议栈模型的本质.&lt;br /&gt;
下面我们来讨论, 信息发送的方法问题.&lt;br /&gt;
网络协议栈的每一层都有着不同协议, 也就是不同方法.即便是一个协议自身也是众多方法的集合.&lt;br /&gt;
理解这些协议程度, 就成为network 工程师能力差异, 下面我们会逐层意淫, 绝不是什么分析理解.&lt;br /&gt;
回到最初的问题, 实际上我们已经解决了怎么分层的问题了.&lt;br /&gt;
我们现在还差一个, 为什么分层.&lt;br /&gt;
简单说这是个设计问题. 设计的好会影响的设计本身与实现.这里是模块化的设计思路.&lt;br /&gt;
优点如维基所说:&lt;br /&gt;
Because each protocol module usually communicates with two others,&lt;br /&gt;
they are commonly imagined as layers in a stack of protocols.&lt;br /&gt;
&lt;a href=&#34;http://en.wikipedia.org/wiki/Communications_protocol#Layering&#34;&gt;更完整的陈述&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;design-of-communications-protocol-http-en-wikipedia-org-wiki-communications-protocol&#34;&gt;Design of &lt;a href=&#34;http://en.wikipedia.org/wiki/Communications_protocol&#34;&gt;Communications protocol&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://ccr.sigcomm.org/archive/1995/jan95/ccr-9501-clark.pdf&#34;&gt;The Design Philosophy of the DARPA Internet Protocols&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.cs.rice.edu/~eugeneng/teaching/s04/comp629/reviews/Cla88.txt&#34;&gt;Reviews from RICE edu&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://zoo.cs.yale.edu/classes/cs633/Reviews/Cla88.msl38.html&#34;&gt;Reviews of Michael S. Liu Yale&lt;/a&gt;&lt;br /&gt;
Address formate: 有了地址我们就要有地址的具体格式如哪个街道，哪个小区几号楼几室。&lt;br /&gt;
Route: 找到收信人, 计算机网络包括linker, network 和transportlayer&lt;br /&gt;
Data format: 接下来就是信封格式，对应头部。&lt;br /&gt;
Reliability:发的信可能丢了，要在写一封吗？&lt;br /&gt;
Detection of transmission errors:如信被人篡改了&lt;/p&gt;

&lt;h1 id=&#34;linux-network-stack-workthrough&#34;&gt;Linux network stack workthrough&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.slideshare.net/ThomasGraf5/devconf-2014-kernel-networking-walkthrough&#34;&gt;DevConf 2014 Kernel Networking Walkthrough&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.slideshare.net/minibobo/linux-tcp-ip?related=1&#34;&gt;introduction to linux kernel tcp/ip ptocotol stack&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://wiki.linuxfoundation.org/networking/kernel_flow&#34;&gt;kernel flow&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;taobao的第5也说明了问题.&lt;br /&gt;
这是通常的skb的流向. 就是在socket里面按着协议走, 包括tcp的重传.&lt;br /&gt;
还有一种, 就是想kproxy那种, 人为的干扰skb的走向, netif_receive_skb就是一个点.&lt;br /&gt;
netif_receive_skb之后就是标准的内核协议栈的事情了包括bonding啊, vlan, bridge这些什么的.&lt;br /&gt;
我觉得这么说还是不够深度, 我们确实在探索skb在协议栈中的流转.&lt;br /&gt;
我们都知道协议栈中skb按着协议走的, 如果能指出什么时候我们可以合法地让报文转个向.&lt;br /&gt;
就能打到我们的目的, 多少能提升下对workthrough的理解的深度;)&lt;br /&gt;
* af_packet相关的&lt;br /&gt;
dev_queue_xmit的dev_queue_xmit_nit中clone后deliver_skb送上去.&lt;br /&gt;
netif_receive_skb 的__netif_receive_skb_core 的deliver_skb. 有个问题?&lt;br /&gt;
为什么skb直接送上去了没有skb_get之类的.原来每个deliver_skb都有&lt;br /&gt;
atomic_inc(&amp;amp;skb-&amp;gt;users);为什么不是skb_get&lt;br /&gt;
* 主动调用netif_receive_skb&lt;br /&gt;
很多pptp协议就是这么干的.&lt;br /&gt;
其实最经典还是pskb_copy和clone的那个场景!&lt;br /&gt;
这个应该多积累, 我感觉挺重要的.&lt;br /&gt;
&lt;a href=&#34;http://www.cubrid.org/blog/dev-platform/understanding-tcp-ip-network-stack/&#34;&gt;Understanding TCP/IP Network Stack &amp;amp; Writing Network Apps&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;out&#34;&gt;out&lt;/h2&gt;

&lt;p&gt;inet_stream_ops-&amp;gt;tcp_sendmsg()-&amp;gt;tcp_push()-&amp;gt;&lt;strong&gt;tcp_push_pending_frames()-&amp;gt;tcp_write_xmit()-&amp;gt;tcp_transmit_skb()-&amp;gt;ipv4_specific.ip_queue_xmit()-&amp;gt;&lt;br /&gt;
ip_local_out()-&amp;gt;&lt;/strong&gt;ip_local_out()-&amp;gt;NF_INET_LOCAL_OUT-&amp;gt;dst_output()-&amp;gt;&lt;br /&gt;
ip_output()&lt;br /&gt;
{&lt;br /&gt;
    //set in ip_mkroute_output&lt;br /&gt;
    skb-&amp;gt;dev = dev = skb_dst(skb)-&amp;gt;dev; //!!!&lt;br /&gt;
    skb-&amp;gt;protocol = htons(ETH_P_IP);&lt;br /&gt;
}-&amp;gt;NF_INET_POST_ROUTING-&amp;gt;ip_finish_output()-&amp;gt;&lt;/p&gt;

&lt;p&gt;ip_finish_output2-&amp;gt; dst_neigh_output&lt;br /&gt;
{&lt;br /&gt;
    neigh_hh_output // hh already in below:-)&lt;br /&gt;
    or&lt;br /&gt;
    n-&amp;gt;output = neigh_resolve_output{dev_hard_header}&lt;br /&gt;
}&lt;br /&gt;
-&amp;gt;dev_queue_xmit()&lt;br /&gt;
{&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;__dev_xmit_skb-&amp;gt;__qdisc_run-&amp;gt;qdisc_restart()-&amp;gt;dev_hard_start_xmit()
or 
validate_xmit_skb-&amp;gt;skb_gso_segment-&amp;gt;skb_mac_gso_segment-&amp;gt; ptype-&amp;gt;callbacks.gso_segment=inet_gso_segment-&amp;gt;tcp4_gso_segment,
dev_hard_start_xmit()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;br /&gt;
xmit_one-&amp;gt;&lt;br /&gt;
{&lt;br /&gt;
    dev_queue_xmit_nit is Sun&amp;rsquo;s Network Interface Tap (NIT)&lt;br /&gt;
    netdev_start_xmit-&amp;gt;ops-&amp;gt;ndo_start_xmit{this functions is init in createing device} = e100_xmit_frame&lt;br /&gt;
}&lt;/p&gt;

&lt;p&gt;softirq:net_tx_action()-&amp;gt;qdisc_run()&lt;/p&gt;

&lt;h2 id=&#34;in-forward&#34;&gt;in &amp;amp; forward&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;NAPI poll_list net_device&lt;br /&gt;
driver intr add skb to private queue -&amp;gt; e100_intr()-&amp;gt;&lt;strong&gt;netif_rx_schedule()-&amp;gt;&lt;/strong&gt;napi_schedule(netdev,nic-&amp;gt;napi)-&amp;gt;:&lt;br /&gt;
add napi to poll_list and __raise_softirq_irqoff()&lt;br /&gt;
do_softirq-&amp;gt;net_rx_action()-&amp;gt;&lt;br /&gt;
+netdev-&amp;gt;poll()=e100_poll()private function-&amp;gt;e100_rx_clean()&amp;hellip;-&amp;gt;&lt;br /&gt;
netif_receive_skb()-&amp;gt;deliver_skb-&amp;gt;&lt;br /&gt;
private queue and private function&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Non-NAPI input_pkt_queue skb&lt;br /&gt;
driver intr vortex_rx()-&amp;gt;netif_rx()-&amp;gt;add skb to SD input_pkt_queue-&amp;gt;napi_schedule(backlog)-&amp;gt;add backlog to SD poll_list __raise_softirq_irqoff()&lt;br /&gt;
async:net_rx_action()-&amp;gt;&lt;br /&gt;
+backlog-&amp;gt;poll()=process_backlog()&lt;br /&gt;
-&amp;gt;netif_receive_skb()-&amp;gt;deliver_skb-&amp;gt;&lt;br /&gt;
skb to sd input_pkt_queue process&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;common path&lt;br /&gt;
pt_prev-&amp;gt;func=ip_rcv()-&amp;gt;NF_INET_PRE_ROUTING-&amp;gt;ip_rcv_finish()-&amp;gt;&lt;br /&gt;
ip_route_input()-&amp;gt;ip_route_input_slow()&lt;br /&gt;
{&lt;br /&gt;
local_input dst.input??=ip_local_deliver()&lt;br /&gt;
or&lt;br /&gt;
ip_mkroute_input()-&amp;gt;__mkroute_input():dst.input=ip_forward() 紧接着dst.output??=ip_output()&lt;br /&gt;
}&lt;br /&gt;
dst_input()-&amp;gt;&lt;br /&gt;
{&lt;br /&gt;
ip_local_deliver()-&amp;gt;NF_INET_LOCAL_IN-&amp;gt;ip_local_deliver_finish()-&amp;gt;inet_protos.tcp_v4_rcv()&lt;br /&gt;
or&lt;br /&gt;
ip_forward()-&amp;gt;NF_INET_FORWARD-&amp;gt;ip_forward_finish()-&amp;gt;dst_output()见上。&lt;br /&gt;
}&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Differences&lt;br /&gt;
1 NAPI has not netif_rx():input_pkt_queue.&lt;br /&gt;
2 NAPI and Non-NAPI used different napi-&amp;gt;poll 决定本质上的区别。&lt;br /&gt;
3 vortex_rx() 多，e100_rx_clean()多！这点可以看出不同优势来。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;faq&#34;&gt;FAQ&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Need clean&lt;br /&gt;
net_tx_action-&amp;gt;output_queue/每个设备的qdisc and  clear_bit__QDISC_STATE_SCHED qdisc_run add back&lt;br /&gt;
__QDISC_STATE_SCHED是否加入softdata&lt;br /&gt;
qdisc_restart: 如果队列有数据就返回大于零 继续减小weight_p&lt;br /&gt;
__qdisc_run queue no data __QDISC_STATE_SCHED not set, only in this case!&lt;br /&gt;
driver tx, stack xmit&lt;/p&gt;

&lt;h3 id=&#34;socket-lock&#34;&gt;socket lock&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.spinics.net/lists/netdev/msg136306.html&#34;&gt;lock_sock or sock_hold&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.linuxfoundation.org/collaborate/workgroups/networking/socket_locks&#34;&gt;bh_lock_sock&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;FIXME sock-&amp;gt;pfmemealloc&lt;br /&gt;
Yes, I only wanted to drop the packet if we were under pressure&lt;br /&gt;
when skb was allocated. If we hit pressure between when skb was&lt;br /&gt;
allocated and when __netdev_alloc_page is called,&lt;br /&gt;
&lt;a href=&#34;https://groups.google.com/forum/#!msg/linux_net/-YtWB66adxY/Qqm_y4U09IAJ&#34;&gt;netvm: Allow skb allocation to use PFMEMALLOC reserves&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://thread.gmane.org/gmane.linux.kernel/1152658&#34;&gt;netvm: Allow skb allocation to use PFMEMALLOC reserves - gmane 08/14&lt;/a&gt;&lt;br /&gt;
socket是跟协议族绑定的概念, 所以要用inet_create, netlink_create&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;FIXME inet_timewait_sock&lt;br /&gt;
deal heavily loaded servers without violating the protocol specification&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;sk_set_memalloc&lt;br /&gt;
SOCK_MEMALLOC, sock has feature mem alloc for free memory.&lt;br /&gt;
只有到了sock层才能分辨, sock是否是memalloc的.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;first_device 用途？&lt;br /&gt;
subsys 在前, device在后.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What is bridge?&lt;br /&gt;
linux bridge&lt;br /&gt;
netdev_rx_handler_register(dev, br_handle_frame, p);&lt;br /&gt;
__netif_receive_skb -&amp;gt; rx_handler=br_handle_frame&lt;br /&gt;
and generic concept: hub, switch?&lt;br /&gt;
hub: layer 1, bradcast, exclusive share, 报文可被侦听.&lt;br /&gt;
switch: layer 2,  mac port route, CAM table in linux bridge module!&lt;br /&gt;
switch with vlan: layer 3, 因为vlan之间的报文转发需要路由, 所以是layer层技术.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What is Head-of-line blocking&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Why can I receive ethernet frames bigger than my current MTU size?&lt;br /&gt;
&lt;a href=&#34;http://serverfault.com/questions/749110/why-can-i-receive-ethernet-frames-bigger-than-my-current-mtu-size&#34;&gt;http://serverfault.com/questions/749110/why-can-i-receive-ethernet-frames-bigger-than-my-current-mtu-size&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Network layer</title>
      <link>http://firoyang.org/net/ip/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:13 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/net/ip/</guid>
      <description>

&lt;h1 id=&#34;fragmentation&#34;&gt;Fragmentation&lt;/h1&gt;

&lt;p&gt;ip_defrag -&amp;gt; ip_frag_queue -&amp;gt; ip_frag_reasm&lt;br /&gt;
ip_fragment&lt;br /&gt;
iphdr-&amp;gt;id, iphdr-&amp;gt;frag_off&lt;/p&gt;

&lt;h1 id=&#34;route&#34;&gt;Route&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://vincent.bernat.im/en/blog/2017-ipv4-route-lookup-linux&#34;&gt;IPv4 route lookup on Linux&lt;/a&gt;&lt;br /&gt;
* state structure&lt;br /&gt;
fib_info:route info&lt;br /&gt;
fib_config:&lt;br /&gt;
* add new rule&lt;br /&gt;
iproute2 &amp;hellip;-&amp;gt;inet_rtm_newroute()-&amp;gt;fib_new_table()-&amp;gt;fib_hash_table()&lt;br /&gt;
* Multi-time line&lt;br /&gt;
fib_create_info(): create a fib_info&lt;/p&gt;

&lt;h1 id=&#34;dst&#34;&gt;dst&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://lore.kernel.org/netdev/20170617174244.132862-1-tracywwnj@gmail.com/&#34;&gt;remove dst garbage collector logic&lt;/a&gt;&lt;br /&gt;
commit 222d7dbd258dad4cd5241c43ef818141fad5a87a&lt;br /&gt;
Author: Eric Dumazet &lt;a href=&#34;mailto:edumazet@google.com&#34;&gt;edumazet@google.com&lt;/a&gt;&lt;br /&gt;
Date:   Thu Sep 21 09:15:46 2017 -0700&lt;br /&gt;
    net: prevent dst uses after free&lt;br /&gt;
    In linux-4.13, Wei worked hard to convert dst to a traditional&lt;br /&gt;
    refcounted model, removing GC.&lt;br /&gt;
commit 9e1437937807b0122e8da1ca8765be2adca9aee6&lt;br /&gt;
Author: Steffen Klassert &lt;a href=&#34;mailto:steffen.klassert@secunet.com&#34;&gt;steffen.klassert@secunet.com&lt;/a&gt;&lt;br /&gt;
Date:   Tue Sep 11 10:31:15 2018 +0200&lt;br /&gt;
    xfrm: Fix NULL pointer dereference when skb_dst_force clears the dst_entry.&lt;/p&gt;

&lt;h1 id=&#34;ip-header&#34;&gt;IP header&lt;/h1&gt;

&lt;p&gt;rfc1122&lt;br /&gt;
IP option is fixed in a session icsk-&amp;gt;icsk_ext_hdr_len;&lt;br /&gt;
is network header icsk-&amp;gt;icsk_af_ops-&amp;gt;net_header_len&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transport layer</title>
      <link>http://firoyang.org/net/tcp/</link>
      <pubDate>Fri, 27 Feb 2015 15:46:13 CST</pubDate>
      <author>Firo Yang</author>
      <guid>http://firoyang.org/net/tcp/</guid>
      <description>

&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://vger.kernel.org/~davem/tcp_output.html&#34;&gt;Dave S Miller tpc output&lt;/a&gt;&lt;br /&gt;
man tcp&lt;br /&gt;
&lt;a href=&#34;http://tools.ietf.org/html/rfc7414&#34;&gt;A Roadmap for Transmission Control Protocol (TCP) Specification Documents&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://tools.ietf.org/html/rfc1122&#34;&gt;Requirements for Internet Hosts &amp;ndash; Communication Layers&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://tools.ietf.org/html/rfc793&#34;&gt;TRANSMISSION CONTROL PROTOCOL 1981&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;send-tcp-message&#34;&gt;Send tcp message&lt;/h1&gt;

&lt;p&gt;server:&lt;br /&gt;
nc -l -p 2046&lt;br /&gt;
nc  127.0.0.1 2046&lt;/p&gt;

&lt;h1 id=&#34;syn-queue-and-listen-queue&#34;&gt;Syn queue and listen queue&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html&#34;&gt;How TCP backlog works in Linux&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;syn-flood&#34;&gt;Syn flood&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://githubengineering.com/syn-flood-mitigation-with-synsanity/&#34;&gt;SYN Flood Mitigation with synsanity&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;ucopy&#34;&gt;ucopy&lt;/h1&gt;

&lt;p&gt;ucopy.task was temporarily enabled in tcp_recvmsg in order to read more data after processing receive queue.&lt;br /&gt;
It will be disabled in the same fuction. So go back to tcp_prequeue, we know if user need more data, then we queue new skb in ucopy.preueue otherwise not.&lt;br /&gt;
In tcp_rcv_established(), the tp-&amp;gt;ucopy.task == current indicats we are in process context.&lt;/p&gt;

&lt;h1 id=&#34;multiplexing&#34;&gt;Multiplexing&lt;/h1&gt;

&lt;p&gt;Ports can provide multiple endpoints on a single node.&lt;br /&gt;
inet_hash_connect()&lt;br /&gt;
inet_sock: dport, sport&lt;/p&gt;

&lt;h1 id=&#34;mss&#34;&gt;MSS&lt;/h1&gt;

&lt;p&gt;MSS tcp_sock-&amp;gt;mss_cache in tcp_sync_mss not minus SACK option&lt;br /&gt;
        in &lt;em&gt;tcp_current_mss&lt;/em&gt; minus SACK option&lt;br /&gt;
sudo tcpdump -s0 -p -ni enp0s31f6 &amp;lsquo;(ip and ip[20+13] &amp;amp; tcp-syn != 0)&amp;rsquo;&lt;br /&gt;
send: tcp_advertise_mss&lt;br /&gt;
tcp_current_mss&lt;br /&gt;
&lt;a href=&#34;https://medium.com/fcamels-notes/%E7%94%A8-systemtap-%E6%89%BE%E5%87%BA-tcp-%E5%A6%82%E4%BD%95%E6%B1%BA%E5%AE%9A-mss-%E7%9A%84%E5%80%BC-4b6b7a969d04&#34;&gt;用 SystemTap 找出 TCP 如何決定 MSS 的值&lt;/a&gt;&lt;br /&gt;
mss derives from MTU; see rfc6691&lt;br /&gt;
When TCP is used in a situation where either the IP or TCP headers are not minimum, the sender must reduce the amount of TCP data in any given packet by the number of octets used by the IP and TCP options.&lt;/p&gt;

&lt;h1 id=&#34;sack&#34;&gt;Sack&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.tecyle.com/2019/06/22/sack-%E5%88%86%E6%9E%90/&#34;&gt;SACK 分析&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;time-wait&#34;&gt;Time-wait&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux&#34;&gt;Coping with the TCP TIME-WAIT state on busy Linux servers&lt;/a&gt;&lt;br /&gt;
tcp: remove tcp_tw_recycle - 4396e46187ca5070219b81773c4e65088dac50cc&lt;/p&gt;

&lt;p&gt;双工, 1. 被动关闭收到ack就%100圆满了.而clinet就不能确认被动关闭是否收到ack,&lt;br /&gt;
显然被动关闭方不能在ack了, 如果下去, 还有个完, 所以两害相权, 取其轻.clinet来吧.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;为了server考虑, server的session 链接必须别正常正确的关闭!&lt;br /&gt;
如果没有time wait, 而且client的ack丢了, server 重传fin ack, clinet的linux&lt;br /&gt;
发现这个fin对应的sock不存在, 直接RST, server异常关闭, 应用程序会检测到错误.&lt;br /&gt;
不友好.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;为了clinet, 不受旧server 干扰.&lt;br /&gt;
这也是为什么要等2MSL&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;tcp_timestamps tcp_tw_recycle&lt;br /&gt;
tcp_time_wait&lt;br /&gt;
一起用如果recycle 不ok就是time wait就是TCP_TIMEWAIT_LEN（60s）&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;两种方法可以进入time wait 状态 tw_substate做区分.&lt;br /&gt;
FIN_WAIT_2 收到fin 见tcp_fin()这个函数&lt;br /&gt;
这个, time wait 如果没有设置recycle就是TCP_TIMEWAIT_LEN,设置了就是rto&lt;br /&gt;
可以说rto的值真的要比TCP_TIMEWAIT_LEN要小.&lt;/p&gt;

&lt;p&gt;FIN_WAIT_2 超时假的time wait状态.貌似tcp_keepalive_timer()&lt;br /&gt;
没有遵从协议但是没有break协议,是个优化.&lt;br /&gt;
tcp_sock结构占用的资源要比tcp_timewait_sock结构占用的资源多, tcp_done干掉sock.&lt;br /&gt;
在TIME_WAIT下也可以处理连接的关闭。&lt;br /&gt;
这个,还一样time_wait是和rto TCP_TIMEWAIT_LEN有关.&lt;br /&gt;
inet_twsk_schedule设置等的时间.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;tcp_tw_reuse&lt;br /&gt;
server 端玩蛋去, 本身像80, 自带重用技能&amp;hellip;&lt;br /&gt;
用在clinet段inet_hash_connect检查是否可以重用TIME_WAIT状态的套接字的端口.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;tcp_fin_timeout&lt;br /&gt;
这个参数是FIN_WAIT_2 转到TIME_WAIT的时间.&lt;br /&gt;
跟time wait时间, 没有直接联系! 好多blog都直接说成time wait的时间.&lt;br /&gt;
这里是间接作用.&lt;br /&gt;
FIXME&amp;hellip;&lt;br /&gt;
而time wait的时间看代码, 要不然是rto 要不然就是TCP_TIMEWAIT_LEN(60s)&lt;br /&gt;
tcp_time_wait&lt;br /&gt;
            if (recycle_ok) {&lt;br /&gt;
                    tw-&amp;gt;tw_timeout = rto;&lt;br /&gt;
            } else {&lt;br /&gt;
                    tw-&amp;gt;tw_timeout = TCP_TIMEWAIT_LEN;&lt;br /&gt;
                    if (state == TCP_TIME_WAIT)&lt;br /&gt;
                            timeo = TCP_TIMEWAIT_LEN;&lt;br /&gt;
            }&lt;br /&gt;
如果启用recycle 就是rto, 这个rto是const int rto = (icsk-&amp;gt;icsk_rto &amp;lt;&amp;lt; 2) - (icsk-&amp;gt;icsk_rto &amp;gt;&amp;gt; 1); 3.5倍的icsk_rto&lt;br /&gt;
在FIN_WAIT_2状态下没有接收到FIN包就进入TIME_WAIT的情况下，如果tcp_fin_timeout的值设置的太小，可能会导致TIME_WAIT套接字（子状态为FIN_WAIT_2）过早地被释放，这样对端发送的FIN（短暂地延迟或者本来就是正常的时间到达）到达时就没有办法处理，导致连接不正常关闭，所以tcp_fin_timeout参数的值并不是越小越好，通常设置为30S比较合适。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;tcp-receive&#34;&gt;TCP receive&lt;/h1&gt;

&lt;h1 id=&#34;established-socket-receive-window&#34;&gt;Established socket receive window&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://tools.ietf.org/html/rfc793&#34;&gt;https://tools.ietf.org/html/rfc793&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://tools.ietf.org/html/rfc1122&#34;&gt;https://tools.ietf.org/html/rfc1122&lt;/a&gt;&lt;br /&gt;
tcp_transmit_skb&lt;br /&gt;
th-&amp;gt;ack_seq     = htonl(tp-&amp;gt;rcv_nxt);&lt;br /&gt;
tcp_data_queue&lt;/p&gt;

&lt;h2 id=&#34;tp-rcv-nxt-tcp-skb-cb-skb-end-seq&#34;&gt;tp-&amp;gt;rcv_nxt = TCP_SKB_CB(skb)-&amp;gt;end_seq;&lt;/h2&gt;

&lt;h1 id=&#34;connection-oriented-communications&#34;&gt;Connection-oriented communications&lt;/h1&gt;

&lt;h2 id=&#34;handshak-of-kproxy&#34;&gt;Handshak of kproxy&lt;/h2&gt;

&lt;p&gt;chome -&amp;gt; syn(kproxy reocrd syn) -&amp;gt; firoyang.org&lt;br /&gt;
firoyang.org -&amp;gt; sync ack -&amp;gt; chrome&lt;br /&gt;
chrome -&amp;gt; ack -&amp;gt; firoyang.org&lt;br /&gt;
chrome -&amp;gt; GET(firoyang.org) kproxy match then send record syn then setup natinfo -&amp;gt; nginx&lt;br /&gt;
nginx -&amp;gt; tcp send fake syn ack-&amp;gt; chrome&lt;br /&gt;
chrome -&amp;gt; ack -&amp;gt; nginx(then -&amp;gt; firoyang.org)&lt;br /&gt;
tcp_v4_do_rcv{&lt;br /&gt;
    sk-&amp;gt;sk_state == TCP_ESTABLISHED&lt;br /&gt;
    tcp_rcv_established{&lt;br /&gt;
    len &amp;lt;= tcp_header_len =&amp;gt;&lt;br /&gt;
    tcp_ack -&amp;gt; tcp_fastretrans_alert{retrans ack and GET(firoyang) -&amp;gt; nginx&lt;br /&gt;
    }&lt;br /&gt;
}&lt;br /&gt;
nginx-&amp;gt; GET -&amp;gt; firoyang.org&lt;br /&gt;
firoyang.org-&amp;gt; nginx-&amp;gt; chrome&lt;/p&gt;

&lt;h1 id=&#34;reliability&#34;&gt;Reliability&lt;/h1&gt;

&lt;h2 id=&#34;rtt&#34;&gt;RTT&lt;/h2&gt;

&lt;p&gt;计算发送和返回ack的时间差.&lt;br /&gt;
tcp_rtt_estimator()&lt;/p&gt;

&lt;h2 id=&#34;arq&#34;&gt;ARQ&lt;/h2&gt;

&lt;p&gt;ack and timeout&lt;br /&gt;
Sliding window protocol is based on automatic repeat request/ARQ&lt;br /&gt;
My conclusion: in practice TCP is a mixture between both GBN and SR.&lt;br /&gt;
* Go-Back-N&lt;br /&gt;
* Selective repeat&lt;/p&gt;

&lt;h2 id=&#34;timer-expiring-retransmiter&#34;&gt;Timer expiring retransmiter&lt;/h2&gt;

&lt;p&gt;tcp_retransmiter_timer()&amp;hellip;-&amp;gt;tcp_transmit_skb()&lt;/p&gt;

&lt;h2 id=&#34;reponse-for-receiving-an-ack&#34;&gt;reponse for receiving an ACK&lt;/h2&gt;

&lt;p&gt;tcp_data_snd_check()-&amp;gt;tcp_write_xmit()&lt;/p&gt;

&lt;h2 id=&#34;timer&#34;&gt;Timer&lt;/h2&gt;

&lt;p&gt;sk_timer&lt;br /&gt;
listen: synack&lt;br /&gt;
estblished: keepalive&lt;br /&gt;
timewait:&lt;/p&gt;

&lt;h1 id=&#34;close&#34;&gt;close&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://my.oschina.net/alchemystar/blog/1821680&#34;&gt;从linux源码看socket的close&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
